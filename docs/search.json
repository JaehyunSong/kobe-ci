[
  {
    "objectID": "material/iv.html",
    "href": "material/iv.html",
    "title": "操作変数法",
    "section": "",
    "text": "新しいタブで開く"
  },
  {
    "objectID": "material/iv.html#スライド",
    "href": "material/iv.html#スライド",
    "title": "操作変数法",
    "section": "",
    "text": "新しいタブで開く"
  },
  {
    "objectID": "material/intro_rct.html",
    "href": "material/intro_rct.html",
    "title": "因果推論の考え方とランダム化比較試験",
    "section": "",
    "text": "新しいタブで開く",
    "crumbs": [
      "因果推論の考え方とランダム化比較試験"
    ]
  },
  {
    "objectID": "material/intro_rct.html#スライド",
    "href": "material/intro_rct.html#スライド",
    "title": "因果推論の考え方とランダム化比較試験",
    "section": "",
    "text": "新しいタブで開く",
    "crumbs": [
      "因果推論の考え方とランダム化比較試験"
    ]
  },
  {
    "objectID": "material/intro_rct.html#パッケージ",
    "href": "material/intro_rct.html#パッケージ",
    "title": "因果推論の考え方とランダム化比較試験",
    "section": "パッケージ",
    "text": "パッケージ\n　通常、Rでのパッケージのインストールとアップデートはinstall.packages()関数、読み込みはlibrary()、またはrequire()関数を使う。一つ注意すべき点はinstall.packages()の場合、R公式レポジトリであるCRANに登録されているパッケージのみが対象となっている点だ。しかし、今はCRANでなくGitHub上で公開されているパッケージも非常に多い。これらパッケージは{devtools}か{remote}パッケージを使う。これらの関数を使い分けることは面倒なので、本講義ではこれらの処理を統合した{pacman}パッケージを使用する。まずは、{pacman}パッケージをインストールする。\n\ninstall.packages(\"pacman\")\n\n　まず、CRANに登録されているパッケージを読み込む際は、pacman::p_load(読み込むパッケージ名)を入力する1。インストールされていない場合は、自動的にCRANからダウンロード&インストールした上で読み込んでくれるので便利だ2。以下では本講義で使用するパッケージとして{tidyverse}、{summarytools}、{fastDummies}、{modelsummary}、{broom}を読み込む。\n\n# pacman::p_load(tidyverse, summarytools, fastDummies, modelsummary, broom) もOK\npacman::p_load(tidyverse, \n               summarytools, \n               fastDummies,\n               modelsummary,\n               broom)\n\n　CRANでなく、GitHub上で公開されているパッケージを使う場合はpacman::p_load_gh()を使用する。()の中には\"ユーザー名/リポジトリ名\"を入力する。たとえば、{BalanceR}の作成者のGitHubアカウント名はJaehyunSongであり、{BalanceR}のリポジトリ名はBalanceRだから、以下のように入力する。p_load()とは違って、文字列は\"で囲む必要があることに注意しよう。\n\npacman::p_load_gh(\"JaehyunSong/BalanceR\")",
    "crumbs": [
      "因果推論の考え方とランダム化比較試験"
    ]
  },
  {
    "objectID": "material/intro_rct.html#データの読み込み",
    "href": "material/intro_rct.html#データの読み込み",
    "title": "因果推論の考え方とランダム化比較試験",
    "section": "データの読み込み",
    "text": "データの読み込み\n　.csv形式のデータを読み込むにはread_csv()関数を使用する3。()内には読み込むファイルのパスを\"で囲んで記入する。read_csv()関数はファイルの読み込みのみの機能しか持たない。現在の作業環境内に読み込んだデータを格納するためには代入演算子&lt;-を使う。ここではdataフォルダー内のintro_data3.csvを読み込み、raw_dfという名のオブジェクトとしてく格納する。作業環境内のオブジェクトはRを再起動すると削除されるため、改めてパッケージ・データの読み込みが必要だ。\n\nraw_df &lt;- read_csv(\"data/intro_data3.csv\")\n\n　オブジェクトの中身を出力するためにはオブジェクト名を入力する。\n\nraw_df\n\n# A tibble: 344,084 × 8\n   treatment  gender   yob hh_size voted2000 voted2002 voted2004 voted2006\n   &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;    \n 1 Civic Duty male    1941       2 no        yes       no        no       \n 2 Civic Duty female  1947       2 no        yes       no        no       \n 3 Hawthorne  male    1951       3 no        yes       no        yes      \n 4 Hawthorne  female  1950       3 no        yes       no        yes      \n 5 Hawthorne  female  1982       3 no        yes       no        yes      \n 6 Control    male    1981       3 no        no        no        no       \n 7 Control    female  1959       3 no        yes       no        yes      \n 8 Control    male    1956       3 no        yes       no        yes      \n 9 Control    female  1968       2 no        yes       no        no       \n10 Control    male    1967       2 no        yes       no        no       \n# ℹ 344,074 more rows\n\n\n　表形式データの大きさ（行の列の数）の確認にはdim()関数を使う。長さ2のnumeric（数値）型ベクトルが返され、それぞれデータセットの行と列の数を意味する。\n\ndim(raw_df)\n\n[1] 344084      8\n\n\n　表形式データの場合、各列には名前が付いており、それぞれが一つの変数に該当する。これら変数名のみの出力にはnames()関数を使う。今回のデータだと、列の数が少ないこともあり、一画面に全列が表示されるが、数百列のデータとなると画面に収まらないので、変数名を確認しておくことを推奨する。\n\nnames(raw_df)\n\n[1] \"treatment\" \"gender\"    \"yob\"       \"hh_size\"   \"voted2000\" \"voted2002\"\n[7] \"voted2004\" \"voted2006\"",
    "crumbs": [
      "因果推論の考え方とランダム化比較試験"
    ]
  },
  {
    "objectID": "material/intro_rct.html#データハンドリング",
    "href": "material/intro_rct.html#データハンドリング",
    "title": "因果推論の考え方とランダム化比較試験",
    "section": "データハンドリング",
    "text": "データハンドリング\n　パイプ演算子には{magrittr}パッケージが提供する%&gt;%とR 4.1から提供されるネイティブパイプ演算子の|&gt;がある。現在の主流は古くから使われてきた%&gt;%であるが、今後、|&gt;が主流になると考えられるため、本講義では|&gt;を使用する。しかし、多くの場合、|&gt;の代わりに%&gt;%を使っても同じ結果が得られる。\n\n\n\n\n\n\nパイプ演算子のショートカットキー\n\n\n\n　Rのnativeパイプ演算子（|&gt;）は意外と打ちにくい。ショートカットキーを活用しよう。\n\nmacOS：Cmd（⌘） + Shift + m\nWindows：Ctrl（Control） + Shift + m\n\n\n\n　パイプ演算子はパイプ前のオブジェクトを、パイプ後の関数の第一引数として渡す単純な演算子だ。たとえば、列名を変更する関数はrename()であるが、使い方はrenames(データ名, 新しい列名 = 既存の列名, ...)である。raw_dfのgender列の名前をfemaleに変更する場合は以下のように書く。\n\nrename(raw_df, female = gender)\n\n# A tibble: 344,084 × 8\n   treatment  female   yob hh_size voted2000 voted2002 voted2004 voted2006\n   &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;    \n 1 Civic Duty male    1941       2 no        yes       no        no       \n 2 Civic Duty female  1947       2 no        yes       no        no       \n 3 Hawthorne  male    1951       3 no        yes       no        yes      \n 4 Hawthorne  female  1950       3 no        yes       no        yes      \n 5 Hawthorne  female  1982       3 no        yes       no        yes      \n 6 Control    male    1981       3 no        no        no        no       \n 7 Control    female  1959       3 no        yes       no        yes      \n 8 Control    male    1956       3 no        yes       no        yes      \n 9 Control    female  1968       2 no        yes       no        no       \n10 Control    male    1967       2 no        yes       no        no       \n# ℹ 344,074 more rows\n\n\n　ここで第1引数がraw_dfだが、パイプ演算子を使うと以下のようになり、人間にとって読みやすいコードになる。\n\nraw_df |&gt;\n  rename(female = gender)\n\n# A tibble: 344,084 × 8\n   treatment  female   yob hh_size voted2000 voted2002 voted2004 voted2006\n   &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;    \n 1 Civic Duty male    1941       2 no        yes       no        no       \n 2 Civic Duty female  1947       2 no        yes       no        no       \n 3 Hawthorne  male    1951       3 no        yes       no        yes      \n 4 Hawthorne  female  1950       3 no        yes       no        yes      \n 5 Hawthorne  female  1982       3 no        yes       no        yes      \n 6 Control    male    1981       3 no        no        no        no       \n 7 Control    female  1959       3 no        yes       no        yes      \n 8 Control    male    1956       3 no        yes       no        yes      \n 9 Control    female  1968       2 no        yes       no        no       \n10 Control    male    1967       2 no        yes       no        no       \n# ℹ 344,074 more rows\n\n\n　要するに、X |&gt; Yは「X（の結果）を使ってYを行う」ことを意味する。より詳しいパイプ演算子の解説は『私たちのR』の「データハンドリング [抽出]」を参照されたい。\n　続いて、変数のリコーディングをしてみよう。xの値が\"A\"なら1、それ以外は0のように、戻り値が2種類の場合、if_else()関数でリコーディングする。書き方は以下の通りだ。\n\nif_else(条件式, 条件が満たされる場合の戻り値, 条件が満たされない場合の戻り値)\n\n　たとえば、raw_dfのgender列の値が\"female\"なら1、それ以外なら0とし、その結果をfemale列として追加するコードは以下の通り。同値を意味する演算子が=でなく、==であることに注意すること（=は&lt;-と同じ代入演算子であるが、Rでは代入演算子として=より&lt;-の使用を推奨している）。\n\nmutate(raw_df, \n       female = if_else(gender == \"female\", 1, 0))\n\n# A tibble: 344,084 × 9\n   treatment gender   yob hh_size voted2000 voted2002 voted2004 voted2006 female\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;\n 1 Civic Du… male    1941       2 no        yes       no        no             0\n 2 Civic Du… female  1947       2 no        yes       no        no             1\n 3 Hawthorne male    1951       3 no        yes       no        yes            0\n 4 Hawthorne female  1950       3 no        yes       no        yes            1\n 5 Hawthorne female  1982       3 no        yes       no        yes            1\n 6 Control   male    1981       3 no        no        no        no             0\n 7 Control   female  1959       3 no        yes       no        yes            1\n 8 Control   male    1956       3 no        yes       no        yes            0\n 9 Control   female  1968       2 no        yes       no        no             1\n10 Control   male    1967       2 no        yes       no        no             0\n# ℹ 344,074 more rows\n\n\n　mutate()は指定された列に対して何らかの処理を行い、その結果を新しい列として追加するか、上書きする関数である。このmutate()関数の第1引数もデータであるため、以下のようにパイプ演算子を使うこともできる。\n\nraw_df |&gt;\n  mutate(female = if_else(gender == \"female\", 1, 0))\n\n# A tibble: 344,084 × 9\n   treatment gender   yob hh_size voted2000 voted2002 voted2004 voted2006 female\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;\n 1 Civic Du… male    1941       2 no        yes       no        no             0\n 2 Civic Du… female  1947       2 no        yes       no        no             1\n 3 Hawthorne male    1951       3 no        yes       no        yes            0\n 4 Hawthorne female  1950       3 no        yes       no        yes            1\n 5 Hawthorne female  1982       3 no        yes       no        yes            1\n 6 Control   male    1981       3 no        no        no        no             0\n 7 Control   female  1959       3 no        yes       no        yes            1\n 8 Control   male    1956       3 no        yes       no        yes            0\n 9 Control   female  1968       2 no        yes       no        no             1\n10 Control   male    1967       2 no        yes       no        no             0\n# ℹ 344,074 more rows\n\n\n　また、mutate()内には複数のコードを書くこともできる。voted2000列からvoted2006列までそれぞれの値が\"yes\"であれば、1を、それ以外の場合は0にリコーディングしてみよう。\n\nraw_df |&gt;\n  mutate(female    = if_else(gender    == \"female\", 1, 0),\n         voted2000 = if_else(voted2000 == \"yes\", 1, 0),\n         voted2002 = if_else(voted2002 == \"yes\", 1, 0),\n         voted2004 = if_else(voted2004 == \"yes\", 1, 0),\n         voted2006 = if_else(voted2006 == \"yes\", 1, 0))\n\n# A tibble: 344,084 × 9\n   treatment gender   yob hh_size voted2000 voted2002 voted2004 voted2006 female\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1 Civic Du… male    1941       2         0         1         0         0      0\n 2 Civic Du… female  1947       2         0         1         0         0      1\n 3 Hawthorne male    1951       3         0         1         0         1      0\n 4 Hawthorne female  1950       3         0         1         0         1      1\n 5 Hawthorne female  1982       3         0         1         0         1      1\n 6 Control   male    1981       3         0         0         0         0      0\n 7 Control   female  1959       3         0         1         0         1      1\n 8 Control   male    1956       3         0         1         0         1      0\n 9 Control   female  1968       2         0         1         0         0      1\n10 Control   male    1967       2         0         1         0         0      0\n# ℹ 344,074 more rows\n\n\n　また、パイプ演算子は2つ以上使うこともできる。たとえば、rename()を使ってgender列をfemaleに変更し、mutate()でリコーディングを行う場合、以下のように書く。これはraw_dfを使ってrename()の処理を行い、その結果をmutate()関数のデータとして渡すことを意味する。\n\nraw_df |&gt;\n  rename(female = gender) |&gt;\n  mutate(female    = if_else(female    == \"female\", 1, 0),\n         voted2000 = if_else(voted2000 == \"yes\", 1, 0),\n         voted2002 = if_else(voted2002 == \"yes\", 1, 0),\n         voted2004 = if_else(voted2004 == \"yes\", 1, 0),\n         voted2006 = if_else(voted2006 == \"yes\", 1, 0))\n\n# A tibble: 344,084 × 8\n   treatment  female   yob hh_size voted2000 voted2002 voted2004 voted2006\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 Civic Duty      0  1941       2         0         1         0         0\n 2 Civic Duty      1  1947       2         0         1         0         0\n 3 Hawthorne       0  1951       3         0         1         0         1\n 4 Hawthorne       1  1950       3         0         1         0         1\n 5 Hawthorne       1  1982       3         0         1         0         1\n 6 Control         0  1981       3         0         0         0         0\n 7 Control         1  1959       3         0         1         0         1\n 8 Control         0  1956       3         0         1         0         1\n 9 Control         1  1968       2         0         1         0         0\n10 Control         0  1967       2         0         1         0         0\n# ℹ 344,074 more rows\n\n\n　以上のコードはデータを加工し、その結果を出力するだけであって、その結果を保存しない。もう一度raw_dfを出力してみても、これまでのデータ加工内容は反映されていないことが分かる。\n\nraw_df\n\n# A tibble: 344,084 × 8\n   treatment  gender   yob hh_size voted2000 voted2002 voted2004 voted2006\n   &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;    \n 1 Civic Duty male    1941       2 no        yes       no        no       \n 2 Civic Duty female  1947       2 no        yes       no        no       \n 3 Hawthorne  male    1951       3 no        yes       no        yes      \n 4 Hawthorne  female  1950       3 no        yes       no        yes      \n 5 Hawthorne  female  1982       3 no        yes       no        yes      \n 6 Control    male    1981       3 no        no        no        no       \n 7 Control    female  1959       3 no        yes       no        yes      \n 8 Control    male    1956       3 no        yes       no        yes      \n 9 Control    female  1968       2 no        yes       no        no       \n10 Control    male    1967       2 no        yes       no        no       \n# ℹ 344,074 more rows\n\n\n　このように頑張ってデータを加工したもののその結果が全く反映されていない。加工したデータを引き続き使っていくためには、加工結果を作業環境内に保存する必要がある。作業環境内にオブジェクトを保存するためには代入演算子（&lt;-）を使い、名前を付けて作業空間内に保存する（ファイルとして保存されるわけではない）必要がある。今回は加工の結果をdfという名で保存する。raw_dfに上書きしても問題はないが、生データはとりあえず作業空間内に残しておくことを推奨する（Rに慣れれば上書きしても良い）。\n\ndf &lt;- raw_df |&gt;\n  rename(female = gender) |&gt;\n  mutate(female    = if_else(female    == \"female\", 1, 0),\n         voted2000 = if_else(voted2000 == \"yes\", 1, 0),\n         voted2002 = if_else(voted2002 == \"yes\", 1, 0),\n         voted2004 = if_else(voted2004 == \"yes\", 1, 0),\n         voted2006 = if_else(voted2006 == \"yes\", 1, 0))\n\ndf\n\n# A tibble: 344,084 × 8\n   treatment  female   yob hh_size voted2000 voted2002 voted2004 voted2006\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 Civic Duty      0  1941       2         0         1         0         0\n 2 Civic Duty      1  1947       2         0         1         0         0\n 3 Hawthorne       0  1951       3         0         1         0         1\n 4 Hawthorne       1  1950       3         0         1         0         1\n 5 Hawthorne       1  1982       3         0         1         0         1\n 6 Control         0  1981       3         0         0         0         0\n 7 Control         1  1959       3         0         1         0         1\n 8 Control         0  1956       3         0         1         0         1\n 9 Control         1  1968       2         0         1         0         0\n10 Control         0  1967       2         0         1         0         0\n# ℹ 344,074 more rows\n\n\n　ちなみに、across()関数とラムダ式（無名関数）を組み合わせると以上のコードをより効率的に書くこともできる。across()は強力な関数だが、初心者にはやや難しいかも知れない。詳細は『私たちのR』の第13.1章を参照されたい。\n\ndf &lt;- raw_df |&gt;\n  rename(female = gender) |&gt;\n  mutate(female = if_else(female == \"female\", 1, 0),\n         # 第1引数: votedで始まる変数を対象に処理を行う\n         # 第2引数: 当該変数の値が\"yes\"なら1、それ以外なら0を割り当てる無名関数\n         #          無名関数は「~」で始まり、変数が入る箇所は.xと表記する\n         #          引数が当該変数のみであれば、「~」を付けずに関数のみでもOK\n         across(starts_with(\"voted\"), ~if_else(.x == \"yes\", 1, 0)))",
    "crumbs": [
      "因果推論の考え方とランダム化比較試験"
    ]
  },
  {
    "objectID": "material/intro_rct.html#記述統計量",
    "href": "material/intro_rct.html#記述統計量",
    "title": "因果推論の考え方とランダム化比較試験",
    "section": "記述統計量",
    "text": "記述統計量\n　記述統計量の計算には{summarytools}のdescr()関数が便利だ。descr(データ名)を入力するだけで各変数の記述統計量が出力される。実際にやってみると分かるが、情報量がかなり多い。しかし、実際の論文では各変数の歪度や尖度まで報告することはあまりないだろう。ここではstats引数を追加して、論文などでよく使う平均値（\"mean\"）、標準偏差（\"sd\"）、最小値（\"min\"）、最大値（\"max\"）、有効ケース数（\"n.valid\"）のみ出力する。\n\ndf |&gt;\n  descr(stats = c(\"mean\", \"sd\", \"min\", \"max\", \"n.valid\"))\n\nDescriptive Statistics  \ndf  \nN: 344084  \n\n                   female     hh_size   voted2000   voted2002   voted2004   voted2006         yob\n------------- ----------- ----------- ----------- ----------- ----------- ----------- -----------\n         Mean        0.50        2.18        0.25        0.39        0.40        0.32     1956.21\n      Std.Dev        0.50        0.79        0.43        0.49        0.49        0.46       14.45\n          Min        0.00        1.00        0.00        0.00        0.00        0.00     1900.00\n          Max        1.00        8.00        1.00        1.00        1.00        1.00     1986.00\n      N.Valid   344084.00   344084.00   344084.00   344084.00   344084.00   344084.00   344084.00\n\n\n　ただし、descr()を使うと数値型（numeric）変数の記述統計量のみ表示される。dfだと、treatment列は文字型（character）であるため、表示されない4。各グループがサンプルの何割かを計算するためには、treatment変数をダミー変数へ変換する必要がある。ダミー変数の作成は面倒な作業であるが、{fastDummies}パッケージのdummy_cols()を使えば簡単にできる。dummy_cols()の中にはselect_columns = \"ダミー化する列名\"を入れれば、当該変数をダミー変数へ変換し、新しい列として追加してくれる。それではtreatment列をダミー化&追加し、その結果をdfに上書きしてみよう。\n\ndf &lt;- df |&gt;\n  dummy_cols(select_columns = \"treatment\")\n\ndf\n\n# A tibble: 344,084 × 13\n   treatment  female   yob hh_size voted2000 voted2002 voted2004 voted2006\n   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 Civic Duty      0  1941       2         0         1         0         0\n 2 Civic Duty      1  1947       2         0         1         0         0\n 3 Hawthorne       0  1951       3         0         1         0         1\n 4 Hawthorne       1  1950       3         0         1         0         1\n 5 Hawthorne       1  1982       3         0         1         0         1\n 6 Control         0  1981       3         0         0         0         0\n 7 Control         1  1959       3         0         1         0         1\n 8 Control         0  1956       3         0         1         0         1\n 9 Control         1  1968       2         0         1         0         0\n10 Control         0  1967       2         0         1         0         0\n# ℹ 344,074 more rows\n# ℹ 5 more variables: `treatment_Civic Duty` &lt;int&gt;, treatment_Control &lt;int&gt;,\n#   treatment_Hawthorne &lt;int&gt;, treatment_Neighbors &lt;int&gt;, treatment_Self &lt;int&gt;\n\n\n　画面には表示されないが、出力結果の下段を見るとtreatment_で始まるいくつかの変数が追加されたことが分かる。ここでは\"tretmant\"で始まる列のみを抽出つして確認してみよう。\n\ndf |&gt;\n  select(starts_with(\"treatment\"))\n\n# A tibble: 344,084 × 6\n   treatment  `treatment_Civic Duty` treatment_Control treatment_Hawthorne\n   &lt;chr&gt;                       &lt;int&gt;             &lt;int&gt;               &lt;int&gt;\n 1 Civic Duty                      1                 0                   0\n 2 Civic Duty                      1                 0                   0\n 3 Hawthorne                       0                 0                   1\n 4 Hawthorne                       0                 0                   1\n 5 Hawthorne                       0                 0                   1\n 6 Control                         0                 1                   0\n 7 Control                         0                 1                   0\n 8 Control                         0                 1                   0\n 9 Control                         0                 1                   0\n10 Control                         0                 1                   0\n# ℹ 344,074 more rows\n# ℹ 2 more variables: treatment_Neighbors &lt;int&gt;, treatment_Self &lt;int&gt;\n\n\n　select()関数内には抽出する列名を入力するだけで良い。たとえば、femaleとyob列を抽出するならselect(female, yob)である。また、femaleからvoted2006までの意味でfemale:voted2006のような書き方もできる。他にも上の例のようにstarts_with()やends_with()、contain()を使って特定の文字列で始まる（で終わる、を含む）列を指定することもできる。一部の列を除外する場合は変数名の前に!か-を付ける。\n　とにかく、問題なくダミー化されていることが分かる。もう一度記述統計量を出してみよう。descr()は仕様上、出力される変数の順番はアルファベット順になるが、ここでは元の順番を維持するためにorder = \"p\"を追加する。また、通常の記述統計表が、先ほど見たものとは違って、各行が変数を、列は記述統計量を表す場合が多い。このように行と列を交換するためにはtranspose = TRUEを追加する5。\n\ndf |&gt;\n  descr(stats = c(\"mean\", \"sd\", \"min\", \"max\", \"n.valid\"),\n        order = \"p\", transpose = TRUE, headings = FALSE)\n\n\n\n\nMean\nStd.Dev\nMin\nMax\nN.Valid\n\n\n\n\nfemale\n0.50\n0.50\n0.00\n1.00\n344084.00\n\n\nyob\n1956.21\n14.45\n1900.00\n1986.00\n344084.00\n\n\nhh_size\n2.18\n0.79\n1.00\n8.00\n344084.00\n\n\nvoted2000\n0.25\n0.43\n0.00\n1.00\n344084.00\n\n\nvoted2002\n0.39\n0.49\n0.00\n1.00\n344084.00\n\n\nvoted2004\n0.40\n0.49\n0.00\n1.00\n344084.00\n\n\nvoted2006\n0.32\n0.46\n0.00\n1.00\n344084.00\n\n\ntreatment_Civic Duty\n0.11\n0.31\n0.00\n1.00\n344084.00\n\n\ntreatment_Control\n0.56\n0.50\n0.00\n1.00\n344084.00\n\n\ntreatment_Hawthorne\n0.11\n0.31\n0.00\n1.00\n344084.00\n\n\ntreatment_Neighbors\n0.11\n0.31\n0.00\n1.00\n344084.00\n\n\ntreatment_Self\n0.11\n0.31\n0.00\n1.00\n344084.00\n\n\n\n\n　他にも以下のようにdfSummary()関数を使えば、綺麗な表としてまとめてくれる。しかも文字型、factor型変数の場合も度数分布表を作成してくれるので非常に便利だ。これも{summarytools}パッケージに含まれた機能なので、別途、パッケージを読み込む必要はない。\n\ndf |&gt;\n  select(-starts_with(\"treatment_\")) |&gt;\n  dfSummary(headings = FALSE) |&gt; \n  print(method = \"render\", round.digits = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\ntreatment [character]\n\n\n\n1. Civic Duty\n\n\n2. Control\n\n\n3. Hawthorne\n\n\n4. Neighbors\n\n\n5. Self\n\n\n\n\n\n\n38218\n(\n11.1%\n)\n\n\n191243\n(\n55.6%\n)\n\n\n38204\n(\n11.1%\n)\n\n\n38201\n(\n11.1%\n)\n\n\n38218\n(\n11.1%\n)\n\n\n\n\n344084 (100.0%)\n0 (0.0%)\n\n\n2\nfemale [numeric]\n\n\n\nMin : 0\n\n\nMean : 0.5\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n172289\n(\n50.1%\n)\n\n\n1\n:\n171795\n(\n49.9%\n)\n\n\n\n\n344084 (100.0%)\n0 (0.0%)\n\n\n3\nyob [numeric]\n\n\n\nMean (sd) : 1956.2 (14.4)\n\n\nmin ≤ med ≤ max:\n\n\n1900 ≤ 1956 ≤ 1986\n\n\nIQR (CV) : 18 (0)\n\n\n\n86 distinct values\n\n344084 (100.0%)\n0 (0.0%)\n\n\n4\nhh_size [numeric]\n\n\n\nMean (sd) : 2.2 (0.8)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 2 ≤ 8\n\n\nIQR (CV) : 0 (0.4)\n\n\n\n\n\n\n1\n:\n47834\n(\n13.9%\n)\n\n\n2\n:\n214086\n(\n62.2%\n)\n\n\n3\n:\n57474\n(\n16.7%\n)\n\n\n4\n:\n20916\n(\n6.1%\n)\n\n\n5\n:\n3315\n(\n1.0%\n)\n\n\n6\n:\n402\n(\n0.1%\n)\n\n\n7\n:\n49\n(\n0.0%\n)\n\n\n8\n:\n8\n(\n0.0%\n)\n\n\n\n\n344084 (100.0%)\n0 (0.0%)\n\n\n5\nvoted2000 [numeric]\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n257464\n(\n74.8%\n)\n\n\n1\n:\n86620\n(\n25.2%\n)\n\n\n\n\n344084 (100.0%)\n0 (0.0%)\n\n\n6\nvoted2002 [numeric]\n\n\n\nMin : 0\n\n\nMean : 0.4\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n209947\n(\n61.0%\n)\n\n\n1\n:\n134137\n(\n39.0%\n)\n\n\n\n\n344084 (100.0%)\n0 (0.0%)\n\n\n7\nvoted2004 [numeric]\n\n\n\nMin : 0\n\n\nMean : 0.4\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n205934\n(\n59.8%\n)\n\n\n1\n:\n138150\n(\n40.2%\n)\n\n\n\n\n344084 (100.0%)\n0 (0.0%)\n\n\n8\nvoted2006 [numeric]\n\n\n\nMin : 0\n\n\nMean : 0.3\n\n\nMax : 1\n\n\n\n\n\n\n0\n:\n235388\n(\n68.4%\n)\n\n\n1\n:\n108696\n(\n31.6%\n)\n\n\n\n\n344084 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.4.1)2024-08-15",
    "crumbs": [
      "因果推論の考え方とランダム化比較試験"
    ]
  },
  {
    "objectID": "material/intro_rct.html#バランスチェック",
    "href": "material/intro_rct.html#バランスチェック",
    "title": "因果推論の考え方とランダム化比較試験",
    "section": "バランスチェック",
    "text": "バランスチェック\n　バランスチェックの簡単な方法はグループごとに処置前変数（pre-treatment variables）の平均値を比較することである。無作為割当が成功しているのであれば、処置前に測定された変数の平均値は近似するはずである。ここではグループ（treatment）ごとに性別、誕生年、世帯規模、2000〜2004年の投票参加の平均値を比較してみる。\n\ndf |&gt;\n  group_by(treatment) |&gt;\n  summarise(female    = mean(female, na.rm = TRUE),\n            yob       = mean(yob, na.rm = TRUE),\n            hh_size   = mean(hh_size, na.rm = TRUE),\n            voted2000 = mean(voted2000, na.rm = TRUE),\n            voted2002 = mean(voted2002, na.rm = TRUE),\n            voted2004 = mean(voted2004, na.rm = TRUE))\n\n# A tibble: 5 × 7\n  treatment  female   yob hh_size voted2000 voted2002 voted2004\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 Civic Duty  0.500 1956.    2.19     0.254     0.389     0.399\n2 Control     0.499 1956.    2.18     0.252     0.389     0.400\n3 Hawthorne   0.499 1956.    2.18     0.250     0.394     0.403\n4 Neighbors   0.500 1956.    2.19     0.251     0.387     0.407\n5 Self        0.500 1956.    2.18     0.251     0.392     0.402\n\n\n　それぞれの変数の平均値は非常に似ているため、無作為割当が成功したと考えられる。しかし、変数の単位によって判断が難しいかも知れない。たとえば、2つのグループがあり、年齢の平均値の差は3、世帯規模のそれは2だとする。これを見ると年齢の方がよりバランスが取れていないようにも見えるが、年齢の幅は数十であるに対し、世帯規模はせいぜい5〜6程度であろう。したがって、各変数のばらつきまで考慮した比較が適切であり、その方法の一つが標準化バイアス（=標準化差分）である。\n　標準化差分を計算する便利パッケージ、{BalanceR}を使ってみよう。第1引数はデータだから、パイプで渡せば良い。BalanceR()内にはgroup引数にグループ識別変数を、covには処置前変数のベクトルを入れる。\n\nblc_chk &lt;- df |&gt;\n  BalanceR(group = treatment,\n           cov   = c(female, yob, hh_size, voted2000, voted2002, voted2004))\n\nblc_chk\n\n  Covariate Mean:Civic Duty SD:Civic Duty Mean:Control SD:Control\n1    female           0.500         0.500        0.499      0.500\n2       yob        1956.341        14.465     1956.186     14.436\n3   hh_size           2.189         0.802        2.184      0.788\n4 voted2000           0.254         0.435        0.252      0.434\n5 voted2002           0.389         0.487        0.389      0.488\n6 voted2004           0.399         0.490        0.400      0.490\n  Mean:Hawthorne SD:Hawthorne Mean:Neighbors SD:Neighbors Mean:Self SD:Self\n1          0.499        0.500          0.500        0.500     0.500   0.500\n2       1956.295       14.400       1956.147       14.579  1956.207  14.416\n3          2.180        0.789          2.188        0.805     2.181   0.782\n4          0.250        0.433          0.251        0.434     0.251   0.434\n5          0.394        0.489          0.387        0.487     0.392   0.488\n6          0.403        0.491          0.407        0.491     0.402   0.490\n  SB:Civic Duty-Control SB:Civic Duty-Hawthorne SB:Civic Duty-Neighbors\n1                 0.248                   0.236                   0.024\n2                 1.069                   0.317                   1.335\n3                 0.687                   1.130                   0.169\n4                 0.388                   0.738                   0.547\n5                -0.108                  -1.123                   0.464\n6                -0.182                  -0.772                  -1.472\n  SB:Civic Duty-Self SB:Control-Hawthorne SB:Control-Neighbors SB:Control-Self\n1              0.120               -0.013               -0.225          -0.128\n2              0.924               -0.754                0.272          -0.146\n3              1.051                0.448               -0.515           0.365\n4              0.566                0.350                0.158           0.178\n5             -0.628               -1.015                0.572          -0.520\n6             -0.619               -0.590               -1.289          -0.437\n  SB:Hawthorne-Neighbors SB:Hawthorne-Self SB:Neighbors-Self\n1                 -0.212            -0.115             0.097\n2                  1.022             0.609            -0.417\n3                 -0.958            -0.085             0.878\n4                 -0.192            -0.172             0.020\n5                  1.587             0.496            -1.092\n6                 -0.700             0.153             0.853\n\n\n　ちなみに、df内にfemaleからvoted2004は連続している（names(df)で確認してみよう）。この場合は以下のように（female:voted2004）書き換えることもできる。\n\nblc_chk &lt;- df |&gt;\n  BalanceR(group = treatment,\n           cov   = female:voted2004)\n\nblc_chk\n\n　標準化差分（標準化バイアス）を用いたバランスチェックはそれぞれのペアごとに計算を行うため、グループが多い場合は凡例が圧迫される場合が多い。しかし、重要なのは標準化差分の最大値だろう。ペア1、2、3でバランスが取れても、ペア4のバランスが取られていない場合は無意味だからだ。また、標準化差分の場合、符号の意味はなく、絶対値が重要だ。また、バランスチェックにおいてグループごとの平均値や標準偏差は不要である。ここでsummary()関数を使うと、絶対値が最も大きい標準化差分のみ出力される。\n\nsummary(blc_chk)\n\n  Covariate Abs_Maximum_SB\n1    female          0.248\n2       yob          1.335\n3   hh_size          1.130\n4 voted2000          0.738\n5 voted2002          1.587\n6 voted2004          1.472\n\n\n　plot()関数を使えば、これらの結果を可視化することもできる。\n\nplot(blc_chk)\n\n\n\n\n\n\n\n図 1: 標準化差分によるバランス✔\n\n\n\n\n\n　先ほど述べたようにバランスチェックで重要なのは絶対値が最も大きい標準化差分である。plot()内にsimplify = TRUEを指定すれば最大値のみ表示され、更にabs = TRUEにすると絶対値へ変換される。また、垂直のガイドラインはvline引数で変更できる。\n\n# plot() の第1引数は blc_chk なのでパイプの使える\nblc_chk |&gt;\n  plot(vline = c(5, 10), simplify = TRUE, abs = TRUE)\n\n\n\n\n\n\n\n図 2: 標準化差分を全て絶対値にし、最も大きいもののみを表示",
    "crumbs": [
      "因果推論の考え方とランダム化比較試験"
    ]
  },
  {
    "objectID": "material/intro_rct.html#処置効果の推定",
    "href": "material/intro_rct.html#処置効果の推定",
    "title": "因果推論の考え方とランダム化比較試験",
    "section": "処置効果の推定",
    "text": "処置効果の推定\n\nグループごとの応答変数の平均値\n　処置効果を確認するためには各グループごとの応答変数（ここではvoted2006）の平均値を計算し、処置群の平均値から統制群の平均値を引く必要がある。まずは、特定の変数の平均値を計算する方法について紹介する。データ内にある特定の変数の平均値を計算するためにはsummarise()関数内に平均値を求めるmean()関数を入れる。たとえば、dfのvoted2006の平均値を計算するコードは以下の通りである。\n\ndf |&gt;\n  summarise(mean(voted2006, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  `mean(voted2006, na.rm = TRUE)`\n                            &lt;dbl&gt;\n1                           0.316\n\n\n　na.rm = TRUEは「欠損値があれば、それを除外する」を意味し、指定されていない場合（=既定値）はFALSEになる。今回は欠損値がないものの、念の為に入れておく。\n　出力結果を見ると、平均値が表示される列の名前が`mean(voted2006, na.rm = TRUE)`となっており、非常に見にくい。この場合、以下のようにmean()の前に出力される列名を予め指定することもできる。\n\ndf |&gt;\n  # voted2006の平均値が表示される列名を Outcome にする。\n  summarise(Outcome = mean(voted2006, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  Outcome\n    &lt;dbl&gt;\n1   0.316\n\n\n　我々が知りたいのはvoted2006の平均値でなく、グループごとの平均値だろう。被験者がどのグループに属しているかわ示す変数はtreatmentであるが、summarise()にデータを渡す前にgroup_by()変数を使うと、グループごとに計算を行い、その結果を返す。\n\ndf |&gt;\n  group_by(treatment) |&gt;\n  summarise(Outcome = mean(voted2006, na.rm = TRUE))\n\n# A tibble: 5 × 2\n  treatment  Outcome\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Civic Duty   0.315\n2 Control      0.297\n3 Hawthorne    0.322\n4 Neighbors    0.378\n5 Self         0.345\n\n\n　group_by()内でも=演算子を使うと、グループ名が出力される列名を変更することができる。\n\ndf |&gt;\n  # グループ名が表示される列名を Group にする。\n  group_by(Groups = treatment) |&gt;\n  summarise(Outcome = mean(voted2006, na.rm = TRUE))\n\n# A tibble: 5 × 2\n  Groups     Outcome\n  &lt;chr&gt;        &lt;dbl&gt;\n1 Civic Duty   0.315\n2 Control      0.297\n3 Hawthorne    0.322\n4 Neighbors    0.378\n5 Self         0.345\n\n\n　ここで一つ注目したいのが、グループの表示順番である。変数のデータ型が文字型だと（Rコンソール上でclass(df$treatment)を入力するか、dfの出力画面でtreatmentの下に&lt;chr&gt;と表示されていることで確認できる）、今のようにアルファベット順で表示される。しかし、統制群は最初か最後に来るのが通例である。この順番をアルファベット順でなく、任意の順番にするためにはtreatment変数をfactor型変数へ変換する必要がある。Factor型は「順序付きの文字型変数」だと理解しても良い6。列の追加・上書き（今回はtreatment列の上書き）の処理が必要なのでmutate()関数を使う。変数をfactor型に変換する関数はfactor()関数で、第1引数としてはfactor型へ変換する変数名を指定する。第2引数はlevelsであり、出力したい順番の文字型ベクトルを指定する。スペルミスに注意すること。\n\ndf |&gt;\n  mutate(treatment = factor(treatment,\n                            levels = c(\"Control\", \"Civic Duty\",\n                                       \"Self\", \"Neighbors\", \"Hawthorne\")))\n\n# A tibble: 344,084 × 13\n   treatment  female   yob hh_size voted2000 voted2002 voted2004 voted2006\n   &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 Civic Duty      0  1941       2         0         1         0         0\n 2 Civic Duty      1  1947       2         0         1         0         0\n 3 Hawthorne       0  1951       3         0         1         0         1\n 4 Hawthorne       1  1950       3         0         1         0         1\n 5 Hawthorne       1  1982       3         0         1         0         1\n 6 Control         0  1981       3         0         0         0         0\n 7 Control         1  1959       3         0         1         0         1\n 8 Control         0  1956       3         0         1         0         1\n 9 Control         1  1968       2         0         1         0         0\n10 Control         0  1967       2         0         1         0         0\n# ℹ 344,074 more rows\n# ℹ 5 more variables: `treatment_Civic Duty` &lt;int&gt;, treatment_Control &lt;int&gt;,\n#   treatment_Hawthorne &lt;int&gt;, treatment_Neighbors &lt;int&gt;, treatment_Self &lt;int&gt;\n\n\n　treatment列名の下が&lt;fct&gt;となっていることが分かる。これはtreatment列のデータ型がfactor型であることを意味する。問題なく動くことが確認できたので、dfを上書きしよう。\n\ndf &lt;- df |&gt;\n  mutate(treatment = factor(treatment,\n                            levels = c(\"Control\", \"Civic Duty\", \"Hawthorne\",\n                                       \"Self\", \"Neighbors\")))\n\n　それでは、改めてグループごとのvoted2006の平均値を計算してみよう。今回は計算結果をout_mean_dfという名のオブジェクトとして格納する。\n\nout_mean_df &lt;- df |&gt;\n  group_by(Groups = treatment) |&gt;\n  summarise(Outcome = mean(voted2006, na.rm = TRUE))\n\nout_mean_df\n\n# A tibble: 5 × 2\n  Groups     Outcome\n  &lt;fct&gt;        &lt;dbl&gt;\n1 Control      0.297\n2 Civic Duty   0.315\n3 Hawthorne    0.322\n4 Self         0.345\n5 Neighbors    0.378\n\n\n　今回は統制群は最初に出力されていることが確認できる。\n　それではこの結果をグラフとして示してみよう。作図には{ggplot2}パッケージを使う。まずはout_mean_dfをggplot()関数に渡す。ggplot()関数以降は、+演算子を使ってレイヤーを足していくこととなる。棒グラフのレイヤーはgeom_bar()関数であり、その中にaes()関数を入れる。aes()の中には棒グラフの作図に必要な情報を入れる必要がある（これをマッピング（mapping）と呼ぶ）。棒グラフを作成するために必要な最低限の情報とは各棒の横軸上の位置（x）と棒の高さ（y）だ。今回は横軸がグループ名、縦軸が平均値となる棒グラフを作る。aes()外側にはstat = \"identity\"を忘れずに付けること。\n\nout_mean_df |&gt;\n  ggplot() +\n  geom_bar(aes(x = Groups, y = Outcome), stat = \"identity\")\n\n\n\n\n\n\n\n図 3: 各グループごとの投票率\n\n\n\n\n\n　続いて、このグラフの見た目を調整してみよう。\n\nout_mean_df |&gt;\n  ggplot() +\n  geom_bar(aes(x = Groups, y = Outcome), stat = \"identity\") +\n  # 縦軸（y軸）のラベルを変更する\n  labs(y = \"Mean(Outcome)\") +\n  # grayテーマ（デフォルトのテーマ）を使用し、フォントサイズは14\n  theme_gray(base_size = 14)\n\n\n\n\n\n\n\n図 4: 縦軸タイトルの変更 + 文字サイスの修正\n\n\n\n\n\n　また、geom_label()レイヤーを足すと、棒の上にラベルを付けることもできる。ラベルに必要な情報は各ラベルの横軸上の位置（x）、縦軸上の位置（y）、ラベルの表示内容（label）だ。今回のラベルは平均値の具体的な数値を入れてみよう。\n\nout_mean_df |&gt;\n  ggplot() +\n  geom_bar(aes(x = Groups, y = Outcome), stat = \"identity\") +\n  geom_label(aes(x = Groups, y = Outcome, label = Outcome)) +\n  labs(y = \"Mean(Outcome)\") +\n  theme_gray(base_size = 14)\n\n\n\n\n\n\n\n図 5: 棒にラベルを追加\n\n\n\n\n\n　小数点が長すぎるので3桁まで表示としよう。ここではsprintf()を使用する。使い方が簡単とは言えないが、覚える必要はなく、必要な時にググるか、本資料のコードをコピペすれば良い7。\n\nout_mean_df |&gt;\n  ggplot() +\n  geom_bar(aes(x = Groups, y = Outcome), stat = \"identity\") +\n  # 2桁までなら %.3f を %.2f に変更\n  geom_label(aes(x = Groups, y = Outcome, label = sprintf(\"%.3f\", Outcome))) +\n  labs(y = \"Mean(Outcome)\") +\n  theme_gray(base_size = 14)\n\n\n\n\n\n\n\n図 6: 推定値を小数点3桁まで表示\n\n\n\n\n\n　これで可視化ができた。ただし、以上のコードには改善の余地がある。geom_bar()とgeom_label()内のaes()関数に注目して欲しい。よく見るとxとyと同じだろう。geom_*()が共有するマッピングがあれば、ggplot()内で指定することでコードを効率化することもできる。\n\nout_mean_df |&gt;\n  ggplot(aes(x = Groups, y = Outcome)) +\n  geom_bar(stat = \"identity\") +\n  geom_label(aes(label = sprintf(\"%.3f\", Outcome))) +\n  labs(y = \"Mean(Outcome)\") +\n  theme_gray(base_size = 14)\n\n\n\n\n\n\n\n図 7: マッピングを共有する箇所をggplot()内でまとめる\n\n\n\n\n\n\n\n統計的推定（単回帰分析）\n　これまでの作業はグループごとの応答変数の平均値であって、処置効果ではない。処置効果を計算するためには処置群の平均値から統制群の平均値を引く必要がある。たとえば、Civic Dutyはがき群の平均値は約0.315、統制群のそれは0.297であるため、Civic Dutyはがきの処置効果は約0.018である。しかし、これを各グループごとに計算することは面倒だし、何よりも得られた値が点推定値だという限界がある。得られた処置効果の不確実性は計算できない。\n　ここで有効なのが線形回帰分析である。回帰分析を行うことで処置効果の点推定値のみならず、不確実性の指標である標準誤差も計算され、区間推定や統計的仮説検定も可能となる。線形回帰分析の関数はlm()だ。第1引数としては回帰式であり、応答変数 ~ 説明変数と表記する。第2引数はdataであり、回帰式で指定した変数が入っているデータ名を指定する。回帰分析の結果は名前を付けてオブジェクトとして格納し、summary()関数を使うと、詳細が確認できる。\n\nfit1 &lt;- lm(voted2006 ~ treatment, data = df)\n\nsummary(fit1)\n\n\nCall:\nlm(formula = voted2006 ~ treatment, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.3780 -0.3145 -0.2966  0.6549  0.7034 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         0.296638   0.001061 279.525  &lt; 2e-16 ***\ntreatmentCivic Duty 0.017899   0.002600   6.884 5.85e-12 ***\ntreatmentHawthorne  0.025736   0.002601   9.896  &lt; 2e-16 ***\ntreatmentSelf       0.048513   0.002600  18.657  &lt; 2e-16 ***\ntreatmentNeighbors  0.081310   0.002601  31.263  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4641 on 344079 degrees of freedom\nMultiple R-squared:  0.003394,  Adjusted R-squared:  0.003383 \nF-statistic:   293 on 4 and 344079 DF,  p-value: &lt; 2.2e-16\n\n\n　ちなみに、これもパイプ演算子を使うことができる。ただし、第1引数として渡すパイプ演算子の特徴上、そのまま使うことはできない。なぜならlm()関数の第1引数はデータでなく、回帰式（formula型）だから。この場合はプレースホルダー（place holder）を指定する必要がある。パイプ前のオブジェクトが入る位置を任意に指定することであり、_を使う。%&gt;%演算子を使う場合は_でなく、.を使う。上記のコードと以下のコードは同じコードとなる。プレースホルダーは自分が使うパイプ演算子によって使い分けること。\n\nfit1 &lt;- df |&gt; # |&gt; パイプを使う場合\n  lm(voted2006 ~ treatment, data = _)\n\nfit1 &lt;- df %&gt;% # %&gt;% パイプを使う場合\n  lm(voted2006 ~ treatment, data = .)\n\n　Factor型、または文字型変数が説明変数の場合、自動的にダミー変数として処理され、factor型の場合、最初の水準（ここでは\"Control\"）がベースカテゴリとなる。もし説明変数が文字型なら、アルファベット順で最初の水準がベースカテゴリとなり、今回の例だと\"Civic Duty\"がベースカテゴリとなる。処置効果は「統制群に比べて〜」が重要となるので、数値型以外の説明変数は予めfactor化しておいた方が望ましい。\n　Civic Dutyの推定値は約0.018であり、これは統制群に比べ、Civic Duty群のvoted2006の平均値は約0.018高いことを意味する。応答変数が0、1であるため、これを割合（=投票率）で換算すると、約1.8%p高いことを意味する。つまり、Civic Dutyのはがきをもらった被験者はそうでない被験者に比べて投票率が約1.8%p高いことを意味する。他の推定値も同じやり方で解釈すれば良い。\n　それではこれらの処置効果が統計的に有意なものかを確認してみよう。統計的有意か否かを判定するためには有意と非有意の境界線が必要である、これは通常、有意水準（significance level; \\(\\alpha\\)）と呼ばれる。この有意水準は分析者が決めるものであるが、社会科学で広く使われる基準は\\(\\alpha = 0.05\\)、つまり5%だ。分析結果の画面にはPr(&gt;|t|)列が表示されているが、これが\\(p\\)値と呼ばれるもので、これが0.05を下回る場合、統計的に有意と判定する。もし、\\(\\alpha = 0.1\\)を採用するなら、\\(p &lt; 0.1\\)の場合において統計的に有意と判定する。Civic Dutyの\\(p\\)値は5.85e-12であり、これは\\(5.75 \\times 10^{-12}\\)を意味する。\\(10^{-1}\\)は0.1、\\(10^{-2}\\)は0.01であることを考えると非常に小さい数値であり、統計的に有意であると考えられる。また、\\(p\\)値が一定値以下であれば&lt; 2e-16と表示される。4つの処置群において処置効果は統計的に有意であると判定できよう。\n　続いて、この結果を可視化してみよう。ここでも{ggplot2}パッケージを使って可視化をするが、{ggplot2}で使用可能なオブジェクトは表形式のデータである。Rコンソール上でclass(オブジェクト名)を入力すると、データのクラスが出力されるが、このクラスに\"data.frame\"があれば、{ggplot2}で使用できる。たとえば、fit1オブジェクトのクラスは\"lm\"であるため、そのまま{ggplot2}で使うことはできない。\n\nclass(fit1)\n\n[1] \"lm\"\n\n\n　推定結果を表形式に変換するためには{broom}パッケージのtidy()関数が便利だ。使い方は簡単でtidy()内に回帰分析の推定結果が格納されたオブジェクトを入れるだけである。ただし、デフォルトの設定では95%信頼区間が表示されないため、中にはconf.int = TRUEを追加しておく必要がある。\n\n# 90%信頼区間を使うのであれば conf.int = 0.9 を追加（デフォルトは0.95）\nfit1_coef &lt;- tidy(fit1, conf.int = TRUE)\n\nfit1_coef\n\n# A tibble: 5 × 7\n  term                estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)           0.297    0.00106    280.   0           0.295     0.299 \n2 treatmentCivic Duty   0.0179   0.00260      6.88 5.85e- 12   0.0128    0.0230\n3 treatmentHawthorne    0.0257   0.00260      9.90 4.37e- 23   0.0206    0.0308\n4 treatmentSelf         0.0485   0.00260     18.7  1.22e- 77   0.0434    0.0536\n5 treatmentNeighbors    0.0813   0.00260     31.3  2.94e-214   0.0762    0.0864\n\nclass(fit1_coef)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n　fit1_coefのクラスに\"data.frame\"が含まれているので、これを使って作図することができる。\n　作図する前に、fit1_coefの加工しておきたい。それぞれの係数（estimate列）は処置効果を表しているが、切片（\"(Intercept)\"）の推定値は処置効果とは無関係である。したがって、予め切片の行を除外しておきたい。特定の行を残したり、除外する関数はfilter()である。今回はterm列の値が\"(Intercept)\"ではない行を残したいので、同値演算子（==）の否定を意味する!=演算子を使用する。\n\nfit1_coef &lt;- fit1_coef |&gt;\n  filter(term != \"(Intercept)\")\n\nfit1_coef\n\n# A tibble: 4 × 7\n  term                estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 treatmentCivic Duty   0.0179   0.00260      6.88 5.85e- 12   0.0128    0.0230\n2 treatmentHawthorne    0.0257   0.00260      9.90 4.37e- 23   0.0206    0.0308\n3 treatmentSelf         0.0485   0.00260     18.7  1.22e- 77   0.0434    0.0536\n4 treatmentNeighbors    0.0813   0.00260     31.3  2.94e-214   0.0762    0.0864\n\n\n　それでは作図に入ろう。処置効果を示す場合は、点推定値以外にもその不確実性を示すのは一般的である。不確実性の指標として幅広く使われるのは標準誤差（standard error; 標準偏差ではない）であるが、可視化の際にはこの標準誤差に基づき計算した信頼区間を示すのが一般的だ。有意水準が5%（\\(\\alpha\\) = 0.05）であれば、95%信頼区間を示し、10%（\\(\\alpha\\) = 0.1）なら90%信頼区間を用いる。tidy()で得られたデータの場合、信頼区間の下限と上限はそれぞれconf.lowとconf.highという名の列に格納されている（conf.int = TRUEを指定しておかないと、信頼区間は計算されない）。\n　点と区間を同時に示すプロットがpoint-rangeプロットであり、{ggplot2}ではgeom_pointrange()レイヤーを使う。必要な情報はpoint-rangeの横軸上の位置（x）、点の縦軸上の位置（y）、区間の上限（ymax）と下限（ymin）である。これらの情報は全てfit1_coefに入っているため、fit1_coefをそのままggplot()関数に渡して作図することができる。\n\nfit1_coef |&gt;\n  ggplot() +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high))\n\n\n\n\n\n\n\n図 8: 処置効果と95%信頼区間\n\n\n\n\n\n　それでは図をカスタマイズしてみよう。図内の様々なラベルを修正するlabs()レイヤーでラベルを修正する。テーマはデフォルトのtheme_gray()の代わりに白黒テーマ（theme_bw()）を使用し、フォントサイズは12とする。また、y = 0の水平線を追加する。95%信頼区間内に0が含まれる場合、「5%水準で統計的に有意でない」と判断できる。水平線を描くにはgeom_hline()レイヤーを追加し、yintercept = 0を指定することで、0のところに水平線が描ける。\n\nfit1_coef |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n図 9: 軸タイトルの修正 + y = 0の水平線を追加 + テーマの変更\n\n\n\n\n\n　まだ気になる点がある。それは横軸の目盛りラベルにtreatmentという不要な情報がある点だ。これは作図の時点で修正することも可能だが、まずはdfのterm変数の値を修正する方法を紹介する。変数の値を修正する時にはrecode()関数を使用する。第1引数はリコーディングする変数名であり、引き続き\"元の値\" = \"新しい値\"を指定すれば良い。スペルミスに注意すること。\n\nfit1_coef &lt;- fit1_coef |&gt;\n  mutate(term = recode(term,\n                       \"treatmentCivic Duty\" = \"Civic Duty\",\n                       \"treatmentHawthorne\"  = \"Hawthorne\",\n                       \"treatmentSelf\"       = \"Self\",\n                       \"treatmentNeighbors\"  = \"Neighbors\"))\n\nfit1_coef\n\n# A tibble: 4 × 7\n  term       estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Civic Duty   0.0179   0.00260      6.88 5.85e- 12   0.0128    0.0230\n2 Hawthorne    0.0257   0.00260      9.90 4.37e- 23   0.0206    0.0308\n3 Self         0.0485   0.00260     18.7  1.22e- 77   0.0434    0.0536\n4 Neighbors    0.0813   0.00260     31.3  2.94e-214   0.0762    0.0864\n\n\n　以上の作業はterm列の各値から\"treatment\"文字を\"\"に置換することなので、文字列を置換する関数であるstr_replace()を使えば、より短くすることができる8。\n\nfit1_coef &lt;- fit1_coef |&gt;\n  mutate(term = str_replace(term, \"treatment\", \"\"))\n\n　fit1_coefも修正できたので、 図 9 と同じコードでもう一度作図してみよう。\n\nfit1_coef |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n図 10: 横軸ラベルの変更\n\n\n\n\n\n　最後に横軸の順番を修正してみよう。fit1_coefのterm列は文字型変数であるため、アルファベット順になる。これをdfのtreatment列と同様、Civic Duty、Self、Neighbors、Hawthorneの順にしたい。この場合fit1_coefのterm列をfactor化すれば良い。factor()関数を使っても良いが、ここではまた便利な技を紹介しよう。それはfct_inorder()関数だ。これは表示されている順番をfactorの順番とする関数だ。実際、fit1_coefの中身を見ると、表示順番はCivic Duty、Self、Neighbors、Hawthorneだ。非常に嬉しい状況なので、fct_inorder()を使ってみよう。\n\nfit1_coef &lt;- fit1_coef |&gt;\n  mutate(term = fct_inorder(term))\n\nfit1_coef\n\n# A tibble: 4 × 7\n  term       estimate std.error statistic   p.value conf.low conf.high\n  &lt;fct&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Civic Duty   0.0179   0.00260      6.88 5.85e- 12   0.0128    0.0230\n2 Hawthorne    0.0257   0.00260      9.90 4.37e- 23   0.0206    0.0308\n3 Self         0.0485   0.00260     18.7  1.22e- 77   0.0434    0.0536\n4 Neighbors    0.0813   0.00260     31.3  2.94e-214   0.0762    0.0864\n\n\n　それでは、 図 10 と同じコードでもう一度作図してみよう。\n\nfit1_coef |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n図 11: 横軸ラベルの順番を変更した後\n\n\n\n\n\n　これで処置効果の可視化もバッチリだ。\n\n\n多重比較の問題\n　グループが2つ、つまり統制群と統制群のみが存在する場合、我々が比較を行う回数は1回のみである（統制群 - 処置群）。しかし、今回のデータの場合、処置群は4つである。これは比較を4回行うことを意味する。具体的には「統制群 - 処置群1」、「統制群 - 処置群2」、「統制群 - 処置群3」、「統制群 - 処置群4」だ。比較を繰り返すほど、統計的に有意な結果が得られる可能性は高い。極端な話、1000回程度検定を繰り返せば、本当は効果がなくてもたまたま統計的に有意な結果が何回かは得られるだろう。これが多重検定（multiple testing）の問題である。したがって、比較の回数が多くなるにつれ、統計的有意性検定にも何らかのペナルティーを課す必要がある。\n　多重比較におけるペナルティーの付け方はいくつかあるが、ここでは最も保守的な（=研究者にとって都合の悪い）補正法であるボンフェローニ補正（Bonferroni correction）を紹介する。これは非常に単純で、\\(p\\)値や信頼区間を計算する際、「統計的有意」と判定されるハードルを上げる方法である。予め決めておいた有意水準（\\(\\alpha\\)）が0.05で、比較の回数が4回であれば、\\(p\\)値が\\(0.05 \\times \\frac{1}{4} = 0.0125\\)を下回る場合において「5%水準で有意である」と判定する。信頼区間でいえば通常の95%信頼区間（1 - 0.05）でなく、98.75%信頼区間（1 - 0.0125）を使うこととなる。この結果、統計的に有意な結果が得られたら「1.25%水準で〜」と解釈するのではなく、「5%水準で〜」と解釈する必要がある。\n　95%以外の信頼区間を求めるのは簡単で、tidy()関数内にconf.levelを修正すれば良い。指定されていない場合はデフォルトで0.95が割り当てられているが、これを0.9875と修正する。\n\nfit1_coef &lt;- tidy(fit1, conf.int = TRUE, conf.level = 0.9875)\n\nfit1_coef\n\n# A tibble: 5 × 7\n  term                estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)           0.297    0.00106    280.   0           0.294     0.299 \n2 treatmentCivic Duty   0.0179   0.00260      6.88 5.85e- 12   0.0114    0.0244\n3 treatmentHawthorne    0.0257   0.00260      9.90 4.37e- 23   0.0192    0.0322\n4 treatmentSelf         0.0485   0.00260     18.7  1.22e- 77   0.0420    0.0550\n5 treatmentNeighbors    0.0813   0.00260     31.3  2.94e-214   0.0748    0.0878\n\n\n　それでは 図 11 と同じ図を作ってみよう。まず、切片の行を除外するが、ここではfilter()を使わず、slice()の使った方法を紹介する。slice()は()内に指定した行を残す関数だ。たとえば、slice(fit1_coef, 2)ならfit1_coefの2行目のみを残す。fit1_coefはslice()の第1引数だから、パイプ演算子を使うことも可能で、こちらの方を推奨する。そうすれば()内には残す行のみの指定で済む。slice(2)のみなら2行目を残し、slice(1, 3, 5)なら1、3、5行目を残す。:を使うと「〜行目から〜行目まで」の指定ができる。処置効果の係数はfit1_coefの2行目から5行目までなので、2:5と指定すれば良い。\n\nfit1_coef &lt;- fit1_coef |&gt;\n  slice(2:5)\n\nfit1_coef\n\n# A tibble: 4 × 7\n  term                estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 treatmentCivic Duty   0.0179   0.00260      6.88 5.85e- 12   0.0114    0.0244\n2 treatmentHawthorne    0.0257   0.00260      9.90 4.37e- 23   0.0192    0.0322\n3 treatmentSelf         0.0485   0.00260     18.7  1.22e- 77   0.0420    0.0550\n4 treatmentNeighbors    0.0813   0.00260     31.3  2.94e-214   0.0748    0.0878\n\n\n　続いて、term変数の値から\"treatment\"の文字を除去し、fit1_coefでの出力順番でtermをfactor化する。\n\nfit1_coef &lt;- fit1_coef |&gt;\n  mutate(term = recode(term,\n                       \"treatmentCivic Duty\" = \"Civic Duty\",\n                       \"treatmentHawthorne\"  = \"Hawthorne\",\n                       \"treatmentSelf\"       = \"Self\",\n                       \"treatmentNeighbors\"  = \"Neighbors\"),\n         term = fct_inorder(term))\n\nfit1_coef\n\n# A tibble: 4 × 7\n  term       estimate std.error statistic   p.value conf.low conf.high\n  &lt;fct&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Civic Duty   0.0179   0.00260      6.88 5.85e- 12   0.0114    0.0244\n2 Hawthorne    0.0257   0.00260      9.90 4.37e- 23   0.0192    0.0322\n3 Self         0.0485   0.00260     18.7  1.22e- 77   0.0420    0.0550\n4 Neighbors    0.0813   0.00260     31.3  2.94e-214   0.0748    0.0878\n\n\n　最後に 図 11 と同じコードで作図する。\n\nfit1_coef |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Treatments\", \n       y = \"Average Treatment Effects (w/ 98.75% CI)\") +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n図 12: 処置効果と98.75%信頼区間\n\n\n\n\n\n\n\n統計的推定（重回帰分析）\n　今回の例は無作為割当が成功しており、処置前変数の偏りは見られない。しかし、何らかの理由で処置前変数の偏りが生じる場合がある。その「何らかの理由」が応答変数にまで影響を与えるのであれば、それは交絡変数（confounder）となり、バイアスの原因となる。この場合、偏りが生じている処置前変数を統制（control）することによってバイアスを小さくすることができる。今回は不要であるが、性別や誕生年などの共変量を統制した推定をしてみよう。\n　やり方は簡単で、lm()内の回帰式を応答変数 ~ 説明変数1 + 説明変数2 + ...のように説明変数を+で足していけば良い。\n\nfit2 &lt;-lm(voted2006 ~ treatment + female + yob + hh_size +\n            voted2000 + voted2002 + voted2004, data = df)\n\nsummary(fit2)\n\n\nCall:\nlm(formula = voted2006 ~ treatment + female + yob + hh_size + \n    voted2000 + voted2002 + voted2004, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7679 -0.3344 -0.1953  0.5300  0.9359 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          5.845e+00  1.099e-01  53.202  &lt; 2e-16 ***\ntreatmentCivic Duty  1.839e-02  2.504e-03   7.343 2.10e-13 ***\ntreatmentHawthorne   2.506e-02  2.504e-03  10.005  &lt; 2e-16 ***\ntreatmentSelf        4.797e-02  2.504e-03  19.157  &lt; 2e-16 ***\ntreatmentNeighbors   8.064e-02  2.504e-03  32.199  &lt; 2e-16 ***\nfemale              -5.783e-03  1.525e-03  -3.791  0.00015 ***\nyob                 -2.913e-03  5.642e-05 -51.633  &lt; 2e-16 ***\nhh_size              5.075e-03  1.018e-03   4.986 6.17e-07 ***\nvoted2000            9.401e-02  1.783e-03  52.722  &lt; 2e-16 ***\nvoted2002            1.414e-01  1.590e-03  88.876  &lt; 2e-16 ***\nvoted2004            1.578e-01  1.564e-03 100.838  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4469 on 344073 degrees of freedom\nMultiple R-squared:  0.07592,   Adjusted R-squared:  0.0759 \nF-statistic:  2827 on 10 and 344073 DF,  p-value: &lt; 2.2e-16\n\n\n　{modelsummary}パッケージのmodelsummary()関数を使えば、推定結果がより見やすくなる。\n\nmodelsummary(fit2)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)        \n                  5.845      \n                \n                \n                                     \n                  (0.110)    \n                \n                \n                  treatmentCivic Duty\n                  0.018      \n                \n                \n                                     \n                  (0.003)    \n                \n                \n                  treatmentHawthorne \n                  0.025      \n                \n                \n                                     \n                  (0.003)    \n                \n                \n                  treatmentSelf      \n                  0.048      \n                \n                \n                                     \n                  (0.003)    \n                \n                \n                  treatmentNeighbors \n                  0.081      \n                \n                \n                                     \n                  (0.003)    \n                \n                \n                  female             \n                  -0.006     \n                \n                \n                                     \n                  (0.002)    \n                \n                \n                  yob                \n                  -0.003     \n                \n                \n                                     \n                  (0.000)    \n                \n                \n                  hh_size            \n                  0.005      \n                \n                \n                                     \n                  (0.001)    \n                \n                \n                  voted2000          \n                  0.094      \n                \n                \n                                     \n                  (0.002)    \n                \n                \n                  voted2002          \n                  0.141      \n                \n                \n                                     \n                  (0.002)    \n                \n                \n                  voted2004          \n                  0.158      \n                \n                \n                                     \n                  (0.002)    \n                \n                \n                  Num.Obs.           \n                  344084     \n                \n                \n                  R2                 \n                  0.076      \n                \n                \n                  R2 Adj.            \n                  0.076      \n                \n                \n                  AIC                \n                  422192.9   \n                \n                \n                  BIC                \n                  422321.9   \n                \n                \n                  Log.Lik.           \n                  -211084.453\n                \n                \n                  F                  \n                  2826.942   \n                \n                \n                  RMSE               \n                  0.45       \n                \n        \n      \n    \n\n\n\n　また、複数のモデルをlist()関数でまとめると、モデル間比較もできる。\n\nmodelsummary(list(\"w/o Covariates\" = fit1, \"w/ Covariates\" = fit2))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                w/o Covariates\n                w/ Covariates\n              \n        \n        \n        \n                \n                  (Intercept)        \n                  0.297      \n                  5.845      \n                \n                \n                                     \n                  (0.001)    \n                  (0.110)    \n                \n                \n                  treatmentCivic Duty\n                  0.018      \n                  0.018      \n                \n                \n                                     \n                  (0.003)    \n                  (0.003)    \n                \n                \n                  treatmentHawthorne \n                  0.026      \n                  0.025      \n                \n                \n                                     \n                  (0.003)    \n                  (0.003)    \n                \n                \n                  treatmentSelf      \n                  0.049      \n                  0.048      \n                \n                \n                                     \n                  (0.003)    \n                  (0.003)    \n                \n                \n                  treatmentNeighbors \n                  0.081      \n                  0.081      \n                \n                \n                                     \n                  (0.003)    \n                  (0.003)    \n                \n                \n                  female             \n                             \n                  -0.006     \n                \n                \n                                     \n                             \n                  (0.002)    \n                \n                \n                  yob                \n                             \n                  -0.003     \n                \n                \n                                     \n                             \n                  (0.000)    \n                \n                \n                  hh_size            \n                             \n                  0.005      \n                \n                \n                                     \n                             \n                  (0.001)    \n                \n                \n                  voted2000          \n                             \n                  0.094      \n                \n                \n                                     \n                             \n                  (0.002)    \n                \n                \n                  voted2002          \n                             \n                  0.141      \n                \n                \n                                     \n                             \n                  (0.002)    \n                \n                \n                  voted2004          \n                             \n                  0.158      \n                \n                \n                                     \n                             \n                  (0.002)    \n                \n                \n                  Num.Obs.           \n                  344084     \n                  344084     \n                \n                \n                  R2                 \n                  0.003      \n                  0.076      \n                \n                \n                  R2 Adj.            \n                  0.003      \n                  0.076      \n                \n                \n                  AIC                \n                  448179.9   \n                  422192.9   \n                \n                \n                  BIC                \n                  448244.4   \n                  422321.9   \n                \n                \n                  Log.Lik.           \n                  -224083.935\n                  -211084.453\n                \n                \n                  F                  \n                  292.976    \n                  2826.942   \n                \n                \n                  RMSE               \n                  0.46       \n                  0.45       \n                \n        \n      \n    \n\n\n\n　modelsummary()は推定値と標準誤差（カッコ内）が別々の行として出力する。これを一行でまとめるためには、以下のようにコードを修正する。\n\nmodelsummary(list(\"w/o Covariates\" = fit1, \"w/ Covariates\" = fit2),\n             estimate  = \"{estimate} ({std.error})\",\n             statistic = NULL)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                w/o Covariates\n                w/ Covariates\n              \n        \n        \n        \n                \n                  (Intercept)        \n                  0.297 (0.001)\n                  5.845 (0.110) \n                \n                \n                  treatmentCivic Duty\n                  0.018 (0.003)\n                  0.018 (0.003) \n                \n                \n                  treatmentHawthorne \n                  0.026 (0.003)\n                  0.025 (0.003) \n                \n                \n                  treatmentSelf      \n                  0.049 (0.003)\n                  0.048 (0.003) \n                \n                \n                  treatmentNeighbors \n                  0.081 (0.003)\n                  0.081 (0.003) \n                \n                \n                  female             \n                               \n                  -0.006 (0.002)\n                \n                \n                  yob                \n                               \n                  -0.003 (0.000)\n                \n                \n                  hh_size            \n                               \n                  0.005 (0.001) \n                \n                \n                  voted2000          \n                               \n                  0.094 (0.002) \n                \n                \n                  voted2002          \n                               \n                  0.141 (0.002) \n                \n                \n                  voted2004          \n                               \n                  0.158 (0.002) \n                \n                \n                  Num.Obs.           \n                  344084       \n                  344084        \n                \n                \n                  R2                 \n                  0.003        \n                  0.076         \n                \n                \n                  R2 Adj.            \n                  0.003        \n                  0.076         \n                \n                \n                  AIC                \n                  448179.9     \n                  422192.9      \n                \n                \n                  BIC                \n                  448244.4     \n                  422321.9      \n                \n                \n                  Log.Lik.           \n                  -224083.935  \n                  -211084.453   \n                \n                \n                  F                  \n                  292.976      \n                  2826.942      \n                \n                \n                  RMSE               \n                  0.46         \n                  0.45          \n                \n        \n      \n    \n\n\n\n　また、alignで各列を左寄せや右寄せに（文字列は左寄せ、数値は右寄せが一般的）、coef_rename引数で表示される変数名を変更することもできる。\n\nmodelsummary(list(\"w/o Covariates\" = fit1, \"w/ Covariates\" = fit2),\n             estimate  = \"{estimate} ({std.error})\",\n             statistic = NULL,\n             align = \"lrr\", # 1列は左寄せ、2列は右寄せ、3列は右寄せ\n             coef_rename = c(\"treatmentCivic Duty\" = \"Civic Duty\",\n                             \"treatmentHawthorne\"  = \"Hawthorne\",\n                             \"treatmentSelf\"       = \"Self\",\n                             \"treatmentNeighbors\"  = \"Neighbors\",\n                             \"female\"              = \"Female\",\n                             \"yob\"                 = \"Year of Birth\",\n                             \"hh_size\"             = \"Household Size\",\n                             \"voted2000\"           = \"Voted (2000)\",\n                             \"voted2002\"           = \"Voted (2002)\",\n                             \"voted2004\"           = \"Voted (2004)\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                w/o Covariates\n                w/ Covariates\n              \n        \n        \n        \n                \n                  (Intercept)   \n                  0.297 (0.001)\n                  5.845 (0.110) \n                \n                \n                  Civic Duty    \n                  0.018 (0.003)\n                  0.018 (0.003) \n                \n                \n                  Hawthorne     \n                  0.026 (0.003)\n                  0.025 (0.003) \n                \n                \n                  Self          \n                  0.049 (0.003)\n                  0.048 (0.003) \n                \n                \n                  Neighbors     \n                  0.081 (0.003)\n                  0.081 (0.003) \n                \n                \n                  Female        \n                               \n                  -0.006 (0.002)\n                \n                \n                  Year of Birth \n                               \n                  -0.003 (0.000)\n                \n                \n                  Household Size\n                               \n                  0.005 (0.001) \n                \n                \n                  Voted (2000)  \n                               \n                  0.094 (0.002) \n                \n                \n                  Voted (2002)  \n                               \n                  0.141 (0.002) \n                \n                \n                  Voted (2004)  \n                               \n                  0.158 (0.002) \n                \n                \n                  Num.Obs.      \n                  344084       \n                  344084        \n                \n                \n                  R2            \n                  0.003        \n                  0.076         \n                \n                \n                  R2 Adj.       \n                  0.003        \n                  0.076         \n                \n                \n                  AIC           \n                  448179.9     \n                  422192.9      \n                \n                \n                  BIC           \n                  448244.4     \n                  422321.9      \n                \n                \n                  Log.Lik.      \n                  -224083.935  \n                  -211084.453   \n                \n                \n                  F             \n                  292.976      \n                  2826.942      \n                \n                \n                  RMSE          \n                  0.46         \n                  0.45          \n                \n        \n      \n    \n\n\n\n　処置効果に注目すると、共変量の有無が推定結果に影響をほぼ与えないことが分かる。これは無作為割当に成功したことを意味する。",
    "crumbs": [
      "因果推論の考え方とランダム化比較試験"
    ]
  },
  {
    "objectID": "material/intro_rct.html#番外編",
    "href": "material/intro_rct.html#番外編",
    "title": "因果推論の考え方とランダム化比較試験",
    "section": "番外編",
    "text": "番外編\n\n複数モデルの出力\n　modelsummary()を使えば、複数のモデルの推定結果を一つの表としてまとめられる。しかし、図の場合はどうだろう。共変量なしモデルとありモデルを 図 12 のように一つにまとめることはできるだろうか。もちろん出来る。\n　まず、重回帰分析を行った結果（fit2）から処置効果の推定値情報を抽出し、fit1_coefと同じ構造のデータとしてまとめる。\n\nfit2_coef &lt;- tidy(fit2, conf.int = TRUE, conf.level = 0.9875)\n\nfit2_coef &lt;- fit2_coef |&gt;\n  slice(2:5) |&gt;\n  mutate(term = recode(term,\n                       \"treatmentCivic Duty\" = \"Civic Duty\",\n                       \"treatmentHawthorne\"  = \"Hawthorne\",\n                       \"treatmentSelf\"       = \"Self\",\n                       \"treatmentNeighbors\"  = \"Neighbors\"),\n         term = fct_inorder(term))\n\nfit2_coef\n\n# A tibble: 4 × 7\n  term       estimate std.error statistic   p.value conf.low conf.high\n  &lt;fct&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Civic Duty   0.0184   0.00250      7.34 2.10e- 13   0.0121    0.0246\n2 Hawthorne    0.0251   0.00250     10.0  1.45e- 23   0.0188    0.0313\n3 Self         0.0480   0.00250     19.2  9.27e- 82   0.0417    0.0542\n4 Neighbors    0.0806   0.00250     32.2  3.92e-227   0.0744    0.0869\n\n\n　処置効果の推定値や標準誤差などが異なるが、構造としては同じである。続いて、bind_rows()を用い、この2つのデータを一つの表として結合する。2つの表はlist()関数でまとめるが、それぞれ\"モデル名\" = データ名と指定する。最後に、.id = \"Model\"を追加する。\n\nbind_rows(list(\"Model 1\" = fit1_coef, \n               \"Model 2\" = fit2_coef),\n          .id = \"Model\")\n\n# A tibble: 8 × 8\n  Model   term       estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;   &lt;fct&gt;         &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Model 1 Civic Duty   0.0179   0.00260      6.88 5.85e- 12   0.0114    0.0244\n2 Model 1 Hawthorne    0.0257   0.00260      9.90 4.37e- 23   0.0192    0.0322\n3 Model 1 Self         0.0485   0.00260     18.7  1.22e- 77   0.0420    0.0550\n4 Model 1 Neighbors    0.0813   0.00260     31.3  2.94e-214   0.0748    0.0878\n5 Model 2 Civic Duty   0.0184   0.00250      7.34 2.10e- 13   0.0121    0.0246\n6 Model 2 Hawthorne    0.0251   0.00250     10.0  1.45e- 23   0.0188    0.0313\n7 Model 2 Self         0.0480   0.00250     19.2  9.27e- 82   0.0417    0.0542\n8 Model 2 Neighbors    0.0806   0.00250     32.2  3.92e-227   0.0744    0.0869\n\n\n　2つの表が1つとなり、Modelという列が追加される（これは.idで指定した名前）。そして、fit1_coefだった行は\"Model 1\"、fit2_coefだった行は\"Model 2\"が付く。ただし、これだけだと表が結合されて出力されるだけなので、fit_coefという名のオブジェクトとして作業環境内に格納しておく。\n\nfit_coef &lt;- bind_rows(list(\"Model 1\" = fit1_coef, \n                           \"Model 2\" = fit2_coef),\n                      .id = \"Model\")\n\n　それではfit_coefを使って、作図をしてみよう。コードは 図 12 と同じであるが、facet_wrap()レイヤーを追加する。これはグラフのファセット（facet）分割を意味し、ファセットとは「面」を意味する。()内には~分割の基準となる変数名を入れる。2つのモデルがあり、fit_coefだとModel列がどのモデルの推定値かを示している。\n\nfit_coef |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  facet_wrap(~ Model) +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n図 13: Model 1とModel 2の比較（ファセット分割）\n\n\n\n\n\n　今回の結果だとモデル1もモデル2も推定値がほぼ同じである。ファセット分割の場合、小さい差の比較が難しいというデメリットがある。この場合、ファセット分割をせず、一つのファセットにpoint-rangeの色分けした方が読みやすくなる。point-rangeをModelの値に応じて色分けする場合、aes()内にcolor = Modelを追加する。\n\nfit_coef |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high,\n                      color = Model)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n図 14: Model 1とModel 2の比較（色分け）\n\n\n\n\n\n　何かおかしい。point-rangeの横軸上の位置が同じということから重なってしまい、モデル1のpoint-rangeがよく見えない。これをずらすためにaes()の外側にposition = position_dodge2(1/2)を追加する。\n\nfit_coef |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high,\n                      color = Model),\n                  position = position_dodge2(1/2)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n図 15: Pointrangeの位置調整\n\n\n\n\n\n　これで図は完成だが、少し修正してみよう。{ggplot2}の場合、凡例は右側に表示されるが、これを下側へ移動させるためにはtheme()レイヤーを追加し、legend.position = \"bottom\"を指定する。また、モデル1とモデル2が具体的に何を意味するのかを明確に示したい。これはfit_coefのModel列を修正しても良いが、今回はscale_color_discrete()レイヤーで修正する例を紹介する。\n\nfit_coef |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = term, y = estimate,\n                      ymin = conf.low, ymax = conf.high,\n                      color = Model),\n                  position = position_dodge2(1/2)) +\n  labs(x = \"Treatments\", y = \"Average Treatment Effects\") +\n  scale_color_discrete(labels = c(\"Model 1\" = \"w/o Covariates\",\n                                  \"Model 2\" = \"w/ Covariates\")) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n図 16: 凡例の位置調整\n\n\n\n\n\n\n\n交互作用\n\nfit3 &lt;- lm(voted2006 ~ treatment * hh_size + female + yob + hh_size +\n             voted2000 + voted2002 + voted2004, data = df)\n\nmodelsummary(list(\"w/o Interaction\" = fit2, \"w/ Interaction\" = fit3),\n             estimate  = \"{estimate} ({std.error})\",\n             statistic = NULL)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                w/o Interaction\n                w/ Interaction\n              \n        \n        \n        \n                \n                  (Intercept)                  \n                  5.845 (0.110) \n                  5.836 (0.110) \n                \n                \n                  treatmentCivic Duty          \n                  0.018 (0.003) \n                  0.044 (0.007) \n                \n                \n                  treatmentHawthorne           \n                  0.025 (0.003) \n                  0.034 (0.007) \n                \n                \n                  treatmentSelf                \n                  0.048 (0.003) \n                  0.076 (0.007) \n                \n                \n                  treatmentNeighbors           \n                  0.081 (0.003) \n                  0.111 (0.007) \n                \n                \n                  female                       \n                  -0.006 (0.002)\n                  -0.006 (0.002)\n                \n                \n                  yob                          \n                  -0.003 (0.000)\n                  -0.003 (0.000)\n                \n                \n                  hh_size                      \n                  0.005 (0.001) \n                  0.010 (0.001) \n                \n                \n                  voted2000                    \n                  0.094 (0.002) \n                  0.094 (0.002) \n                \n                \n                  voted2002                    \n                  0.141 (0.002) \n                  0.141 (0.002) \n                \n                \n                  voted2004                    \n                  0.158 (0.002) \n                  0.158 (0.002) \n                \n                \n                  treatmentCivic Duty × hh_size\n                                \n                  -0.012 (0.003)\n                \n                \n                  treatmentHawthorne × hh_size \n                                \n                  -0.004 (0.003)\n                \n                \n                  treatmentSelf × hh_size      \n                                \n                  -0.013 (0.003)\n                \n                \n                  treatmentNeighbors × hh_size \n                                \n                  -0.014 (0.003)\n                \n                \n                  Num.Obs.                     \n                  344084        \n                  344084        \n                \n                \n                  R2                           \n                  0.076         \n                  0.076         \n                \n                \n                  R2 Adj.                      \n                  0.076         \n                  0.076         \n                \n                \n                  AIC                          \n                  422192.9      \n                  422163.5      \n                \n                \n                  BIC                          \n                  422321.9      \n                  422335.5      \n                \n                \n                  Log.Lik.                     \n                  -211084.453   \n                  -211065.750   \n                \n                \n                  F                            \n                  2826.942      \n                  2022.112      \n                \n                \n                  RMSE                         \n                  0.45          \n                  0.45          \n                \n        \n      \n    \n\n\n\n\npacman::p_load(marginaleffects)\n\n\nfit3_pred &lt;- predictions(fit3,\n                         newdata = datagrid(treatment = c(\"Control\",\n                                                          \"Civic Duty\",\n                                                          \"Hawthorne\",\n                                                          \"Neighbors\",\n                                                          \"Self\"),\n                                            hh_size   = c(1, 4, 8)))\n\nfit3_pred\n\n\n  treatment hh_size Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 % female\n Control          1    0.146    0.00232 62.8   &lt;0.001   Inf 0.141  0.150      0\n Control          4    0.175    0.00285 61.5   &lt;0.001   Inf 0.170  0.181      0\n Control          8    0.215    0.00787 27.3   &lt;0.001 542.3 0.199  0.230      0\n Civic Duty       1    0.178    0.00433 41.2   &lt;0.001   Inf 0.170  0.187      0\n Civic Duty       4    0.173    0.00578 29.8   &lt;0.001 647.9 0.161  0.184      0\n Civic Duty       8    0.165    0.01684  9.8   &lt;0.001  72.9 0.132  0.198      0\n Hawthorne        1    0.176    0.00435 40.4   &lt;0.001   Inf 0.167  0.184      0\n Hawthorne        4    0.193    0.00588 32.9   &lt;0.001 785.2 0.182  0.205      0\n Hawthorne        8    0.217    0.01714 12.7   &lt;0.001 119.9 0.184  0.251      0\n Neighbors        1    0.243    0.00431 56.3   &lt;0.001   Inf 0.234  0.251      0\n Neighbors        4    0.231    0.00577 40.1   &lt;0.001   Inf 0.220  0.242      0\n Neighbors        8    0.215    0.01678 12.8   &lt;0.001 122.7 0.182  0.248      0\n Self             1    0.209    0.00438 47.8   &lt;0.001   Inf 0.201  0.218      0\n Self             4    0.200    0.00592 33.8   &lt;0.001 827.7 0.188  0.212      0\n Self             8    0.188    0.01728 10.9   &lt;0.001  88.8 0.154  0.221      0\n  yob voted2000 voted2002 voted2004\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n 1956         0         0         0\n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, female, yob, voted2000, voted2002, voted2004, treatment, hh_size, voted2006 \nType:  response \n\n\n\nfit3_pred |&gt; \n  ggplot() +\n  geom_col(aes(x = treatment, y = Estimate)) +\n  facet_wrap(~hh_size)\n\nError in `geom_col()`:\n! Problem while computing aesthetics.\nℹ Error occurred in the 1st layer.\nCaused by error:\n! object 'Estimate' not found\n\n\n\nprint(fit3_pred, style = \"data.frame\")\n\n   rowid  estimate   std.error statistic       p.value   s.value  conf.low\n1      1 0.1459165 0.002323454 62.801566  0.000000e+00       Inf 0.1413627\n2      2 0.1754264 0.002851464 61.521525  0.000000e+00       Inf 0.1698376\n3      3 0.2147729 0.007870487 27.288382 5.826749e-164 542.25352 0.1993470\n4      4 0.1782236 0.004325704 41.201066  0.000000e+00       Inf 0.1697454\n5      5 0.1725458 0.005780891 29.847619 9.425960e-196 647.86127 0.1612155\n6      6 0.1649754 0.016840204  9.796522  1.165292e-22  72.86173 0.1319692\n7      7 0.1755679 0.004349619 40.363982  0.000000e+00       Inf 0.1670428\n8      8 0.1934422 0.005883334 32.879697 4.288219e-237 785.19658 0.1819111\n9      9 0.2172746 0.017138668 12.677451  7.885487e-37 119.93214 0.1836834\n10    10 0.2429128 0.004311551 56.340003  0.000000e+00       Inf 0.2344623\n11    11 0.2310648 0.005768525 40.056126  0.000000e+00       Inf 0.2197587\n12    12 0.2152674 0.016782230 12.827101  1.156090e-37 122.70209 0.1823748\n13    13 0.2091471 0.004375073 47.804251  0.000000e+00       Inf 0.2005721\n14    14 0.1999174 0.005921035 33.763922 6.679244e-250 827.74234 0.1883123\n15    15 0.1876110 0.017280299 10.856931  1.848586e-27  88.80564 0.1537422\n   conf.high female      yob voted2000 voted2002 voted2004  treatment hh_size\n1  0.1504704      0 1956.214         0         0         0    Control       1\n2  0.1810152      0 1956.214         0         0         0    Control       4\n3  0.2301987      0 1956.214         0         0         0    Control       8\n4  0.1867018      0 1956.214         0         0         0 Civic Duty       1\n5  0.1838762      0 1956.214         0         0         0 Civic Duty       4\n6  0.1979816      0 1956.214         0         0         0 Civic Duty       8\n7  0.1840930      0 1956.214         0         0         0  Hawthorne       1\n8  0.2049734      0 1956.214         0         0         0  Hawthorne       4\n9  0.2508658      0 1956.214         0         0         0  Hawthorne       8\n10 0.2513633      0 1956.214         0         0         0  Neighbors       1\n11 0.2423709      0 1956.214         0         0         0  Neighbors       4\n12 0.2481599      0 1956.214         0         0         0  Neighbors       8\n13 0.2177221      0 1956.214         0         0         0       Self       1\n14 0.2115224      0 1956.214         0         0         0       Self       4\n15 0.2214798      0 1956.214         0         0         0       Self       8\n   voted2006\n1          0\n2          0\n3          0\n4          0\n5          0\n6          0\n7          0\n8          0\n9          0\n10         0\n11         0\n12         0\n13         0\n14         0\n15         0\n\n\n\nfit3_pred |&gt; \n  ggplot() +\n  geom_col(aes(x = treatment, y = estimate)) +\n  facet_wrap(~hh_size)\n\n\n\n\n\n\n\n\n\nfit3_pred |&gt; \n  mutate(hh_size = case_when(hh_size == 1 ~ \"Household size = 1\",\n                             hh_size == 4 ~ \"Household size = 4\",\n                             hh_size == 8 ~ \"Household size = 8\"),\n         hh_size = fct_inorder(hh_size)) |&gt; \n  ggplot() +\n  geom_col(aes(x = treatment, y = estimate)) +\n  labs(x = \"Groups\", y = \"Predicted Turnout\") +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +\n  facet_wrap(~hh_size)\n\n\n\n\n\n\n\n\n\nfit3_pred |&gt; \n  mutate(hh_size = case_when(hh_size == 1 ~ \"Household size = 1\",\n                             hh_size == 4 ~ \"Household size = 4\",\n                             hh_size == 8 ~ \"Household size = 8\"),\n         hh_size = fct_inorder(hh_size)) |&gt; \n  ggplot() +\n  geom_col(aes(x = treatment, y = estimate)) +\n  geom_text(aes(x = treatment, y = estimate, label = sprintf(\"%.3f\", estimate))) +\n  labs(x = \"Groups\", y = \"Predicted Turnout\") +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +\n  facet_wrap(~hh_size)\n\n\n\n\n\n\n\n\n\nfit3_pred |&gt; \n  mutate(hh_size = case_when(hh_size == 1 ~ \"Household size = 1\",\n                             hh_size == 4 ~ \"Household size = 4\",\n                             hh_size == 8 ~ \"Household size = 8\"),\n         hh_size = fct_inorder(hh_size)) |&gt; \n  ggplot() +\n  geom_col(aes(x = treatment, y = estimate)) +\n  geom_text(aes(x = treatment, y = estimate, label = sprintf(\"%.3f\", estimate)),\n            color = \"white\", vjust = 2) +\n  labs(x = \"Groups\", y = \"Predicted Turnout\") +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +\n  facet_wrap(~hh_size)\n\n\n\n\n\n\n\n\n\nfit3_ame &lt;- fit3 |&gt; \n  marginaleffects(variables = \"treatment\",\n                  newdata = datagrid(hh_size = 1:8))\n\nprint(fit3_ame, style = \"data.frame\")\n\n   rowid      term             contrast      estimate   std.error   statistic\n1      1 treatment Civic Duty - Control  0.0323070808 0.004485340  7.20281612\n2      2 treatment Civic Duty - Control  0.0205778631 0.002572273  7.99987543\n3      3 treatment Civic Duty - Control  0.0088486454 0.003568488  2.47966211\n4      4 treatment Civic Duty - Control -0.0028805723 0.006202487 -0.46442217\n5      5 treatment Civic Duty - Control -0.0146097900 0.009155697 -1.59570485\n6      6 treatment Civic Duty - Control -0.0263390077 0.012198440 -2.15921112\n7      7 treatment Civic Duty - Control -0.0380682254 0.015277314 -2.49181409\n8      8 treatment Civic Duty - Control -0.0497974431 0.018374163 -2.71018834\n9      1 treatment  Hawthorne - Control  0.0296514006 0.004508577  6.57666514\n10     2 treatment  Hawthorne - Control  0.0257728789 0.002569135 10.03173439\n11     3 treatment  Hawthorne - Control  0.0218943571 0.003610946  6.06333052\n12     4 treatment  Hawthorne - Control  0.0180158353 0.006296244  2.86136215\n13     5 treatment  Hawthorne - Control  0.0141373135 0.009295792  1.52082938\n14     6 treatment  Hawthorne - Control  0.0102587917 0.012383299  0.82843770\n15     7 treatment  Hawthorne - Control  0.0063802699 0.015506312  0.41146277\n16     8 treatment  Hawthorne - Control  0.0025017481 0.018647000  0.13416358\n17     1 treatment  Neighbors - Control  0.0969962701 0.004473502 21.68240168\n18     2 treatment  Neighbors - Control  0.0832103023 0.002571525 32.35834603\n19     3 treatment  Neighbors - Control  0.0694243344 0.003565984 19.46849168\n20     4 treatment  Neighbors - Control  0.0556383666 0.006190536  8.98764986\n21     5 treatment  Neighbors - Control  0.0418523987 0.009134122  4.58198361\n22     6 treatment  Neighbors - Control  0.0280664309 0.012167360  2.30669851\n23     7 treatment  Neighbors - Control  0.0142804630 0.015236800  0.93723505\n24     8 treatment  Neighbors - Control  0.0004944951 0.018324260  0.02698582\n25     1 treatment       Self - Control  0.0632305717 0.004532556 13.95031202\n26     2 treatment       Self - Control  0.0503173668 0.002570076 19.57815989\n27     3 treatment       Self - Control  0.0374041619 0.003623024 10.32401664\n28     4 treatment       Self - Control  0.0244909571 0.006333017  3.86718662\n29     5 treatment       Self - Control  0.0115777522 0.009356692  1.23737664\n30     6 treatment       Self - Control -0.0013354527 0.012467881 -0.10711145\n31     7 treatment       Self - Control -0.0142486576 0.015614359 -0.91253556\n32     8 treatment       Self - Control -0.0271618625 0.018778395 -1.44644215\n         p.value      s.value     conf.low    conf.high hh_size predicted_lo\n1   5.898149e-13  40.62480292  0.023515975  0.041098186       1    0.1459165\n2   1.245451e-15  49.51225261  0.015536301  0.025619425       2    0.1557532\n3   1.315069e-02   6.24871731  0.001854537  0.015842754       3    0.1655898\n4   6.423453e-01   0.63857903 -0.015037223  0.009276078       4    0.1754264\n5   1.105547e-01   3.17716767 -0.032554626  0.003335046       5    0.1852630\n6   3.083379e-02   5.01934386 -0.050247511 -0.002430504       6    0.1950996\n7   1.270925e-02   6.29797681 -0.068011210 -0.008125241       7    0.2049363\n8   6.724501e-03   7.21635703 -0.085810141 -0.013784745       8    0.2147729\n9   4.811166e-11  34.27482244  0.020814752  0.038488049       1    0.1459165\n10  1.105573e-23  76.25955221  0.020737467  0.030808291       2    0.1557532\n11  1.333313e-09  29.48233766  0.014817034  0.028971681       3    0.1655898\n12  4.218249e-03   7.88914003  0.005675423  0.030356247       4    0.1754264\n13  1.283027e-01   2.96237701 -0.004082104  0.032356731       5    0.1852630\n14  4.074227e-01   1.29540186 -0.014012028  0.034529612       6    0.1950996\n15  6.807332e-01   0.55483854 -0.024011543  0.036772082       7    0.2049363\n16  8.932732e-01   0.16282657 -0.034045699  0.039049196       8    0.2147729\n17 3.007683e-104 343.89186917  0.088228367  0.105764173       1    0.1459165\n18 1.058753e-229 760.63916829  0.078170205  0.088250399       2    0.1557532\n19  2.031661e-84 278.01930021  0.062435134  0.076413535       3    0.1655898\n20  2.525732e-19  61.77993215  0.043505140  0.067771593       4    0.1754264\n21  4.605860e-06  17.72809798  0.023949848  0.059754949       5    0.1852630\n22  2.107163e-02   5.56855404  0.004218844  0.051914018       6    0.1950996\n23  3.486377e-01   1.52019965 -0.015583116  0.044144042       7    0.2049363\n24  9.784710e-01   0.03139893 -0.035420394  0.036409385       8    0.2147729\n25  3.132320e-44 144.51760437  0.054346925  0.072114218       1    0.1459165\n26  2.374442e-85 281.11629947  0.045280110  0.055354624       2    0.1557532\n27  5.487823e-25  80.59196838  0.030303165  0.044505159       3    0.1655898\n28  1.100982e-04  13.14892185  0.012078473  0.036903441       4    0.1754264\n29  2.159473e-01   2.21124890 -0.006761027  0.029916532       5    0.1852630\n30  9.147006e-01   0.12862855 -0.025772050  0.023101145       6    0.1950996\n31  3.614869e-01   1.46798490 -0.044852238  0.016354923       7    0.2049363\n32  1.480532e-01   2.75581216 -0.063966841  0.009643116       8    0.2147729\n   predicted_hi predicted treatment female      yob voted2000 voted2002\n1     0.1782236 0.1459165   Control      0 1956.214         0         0\n2     0.1763310 0.1557532   Control      0 1956.214         0         0\n3     0.1744384 0.1655898   Control      0 1956.214         0         0\n4     0.1725458 0.1754264   Control      0 1956.214         0         0\n5     0.1706532 0.1852630   Control      0 1956.214         0         0\n6     0.1687606 0.1950996   Control      0 1956.214         0         0\n7     0.1668680 0.2049363   Control      0 1956.214         0         0\n8     0.1649754 0.2147729   Control      0 1956.214         0         0\n9     0.1755679 0.1459165   Control      0 1956.214         0         0\n10    0.1815260 0.1557532   Control      0 1956.214         0         0\n11    0.1874841 0.1655898   Control      0 1956.214         0         0\n12    0.1934422 0.1754264   Control      0 1956.214         0         0\n13    0.1994003 0.1852630   Control      0 1956.214         0         0\n14    0.2053584 0.1950996   Control      0 1956.214         0         0\n15    0.2113165 0.2049363   Control      0 1956.214         0         0\n16    0.2172746 0.2147729   Control      0 1956.214         0         0\n17    0.2429128 0.1459165   Control      0 1956.214         0         0\n18    0.2389635 0.1557532   Control      0 1956.214         0         0\n19    0.2350141 0.1655898   Control      0 1956.214         0         0\n20    0.2310648 0.1754264   Control      0 1956.214         0         0\n21    0.2271154 0.1852630   Control      0 1956.214         0         0\n22    0.2231661 0.1950996   Control      0 1956.214         0         0\n23    0.2192167 0.2049363   Control      0 1956.214         0         0\n24    0.2152674 0.2147729   Control      0 1956.214         0         0\n25    0.2091471 0.1459165   Control      0 1956.214         0         0\n26    0.2060705 0.1557532   Control      0 1956.214         0         0\n27    0.2029939 0.1655898   Control      0 1956.214         0         0\n28    0.1999174 0.1754264   Control      0 1956.214         0         0\n29    0.1968408 0.1852630   Control      0 1956.214         0         0\n30    0.1937642 0.1950996   Control      0 1956.214         0         0\n31    0.1906876 0.2049363   Control      0 1956.214         0         0\n32    0.1876110 0.2147729   Control      0 1956.214         0         0\n   voted2004 voted2006\n1          0         0\n2          0         0\n3          0         0\n4          0         0\n5          0         0\n6          0         0\n7          0         0\n8          0         0\n9          0         0\n10         0         0\n11         0         0\n12         0         0\n13         0         0\n14         0         0\n15         0         0\n16         0         0\n17         0         0\n18         0         0\n19         0         0\n20         0         0\n21         0         0\n22         0         0\n23         0         0\n24         0         0\n25         0         0\n26         0         0\n27         0         0\n28         0         0\n29         0         0\n30         0         0\n31         0         0\n32         0         0\n\n\n\nfit3_ame |&gt; \n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = hh_size, y = estimate, ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Household Size\", y = \"Average Marginal Effects\") +\n  facet_wrap(~contrast)\n\n\n\n\n\n\n\n\n\nfit3_ame |&gt; \n  mutate(contrast = str_remove(contrast, \" - Control\")) |&gt; \n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = hh_size, y = estimate, ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"Household Size\", y = \"Average Marginal Effects\") +\n  facet_wrap(~contrast)\n\n\n\n\n\n\n\n\n\nfit3_ame |&gt; \n  mutate(contrast = str_remove(contrast, \" - Control\"),\n         sig      = if_else(p.value &lt; 0.05, \"sig\", \"insig\")) |&gt; \n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = hh_size, y = estimate, ymin = conf.low, ymax = conf.high,\n                      color = sig)) +\n  labs(x = \"Household Size\", y = \"Average Marginal Effects\") +\n  facet_wrap(~contrast)\n\n\n\n\n\n\n\n\n\nfit3_ame |&gt; \n  mutate(contrast = str_remove(contrast, \" - Control\"),\n         sig      = if_else(p.value &lt; 0.05, \"sig\", \"insig\")) |&gt; \n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = hh_size, y = estimate, ymin = conf.low, ymax = conf.high,\n                      color = sig)) +\n  labs(x = \"Household Size\", y = \"Average Marginal Effects\") +\n  scale_color_manual(values = c(\"sig\" = \"black\", \"insig\" = \"gray80\")) +\n  facet_wrap(~contrast) +\n  theme_bw() +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "因果推論の考え方とランダム化比較試験"
    ]
  },
  {
    "objectID": "material/intro_rct.html#footnotes",
    "href": "material/intro_rct.html#footnotes",
    "title": "因果推論の考え方とランダム化比較試験",
    "section": "脚注",
    "text": "脚注\n\n\npacman::p_load()は「{pacman}パッケージのp_load()関数」を意味する。このような書き方をすると、パッケージを読み込まず、関数を使うことができる。むろん、library(pacman)で予め{pacman}パッケージを読み込んでおくと、pacman::は省略し、p_load()だけでも問題ない。ただし、最初の1、2回程度しか使わないパッケージをわざわざ読み込んでおくのは目盛りの無駄遣いなので、このようにパッケージから直接呼び出したほうが効率が良い。↩︎\nパッケージのアップデートにはpacman::p_update()またはpacman::p_up()関数を使う。()内に何も入力しない場合、全パッケージがアップデートされる。↩︎\nMicrosoft Excel形式（.xls、.xlsx）は{readxl}パッケージのread_excel()関数を、Stata形式（.dta）は{heaven}のread_dta()（またはread_stata()）、SPSS形式（.sav）は{haven}のread_sav()（またはread_spss()）を使用する。ただし、データ分析界隈の標準は.csvフォーマットである。↩︎\n変数のデータ型はデータを出力する際、列名の下段に表示される。&lt;chr&gt;は文字型、&lt;dbl&gt;と&lt;int&gt;は数値型、&lt;fct&gt;はfactor型である。他にもいくつかのデータ型がある。詳細は『私たちのR』の第8章を参照すること。↩︎\nRMarkdown内に埋め込むなら更にstyle = \"rmarkdown\"を追加してみよう。ただし、Chunkオプションにresults = \"asis\"（Quartoなら#| results: \"asis\"）を付けること。↩︎\n中身が1、2、3、…であってもfactor型であれば1、2、3、…は数字でなく文字として認識される。↩︎\nもっと使いやすいround()があるが、round()の場合、丸めた結果が1.100なら1.1としか表記されない。表示される桁数を固定するためにはsprintf()を使う。↩︎\nstr_replace(term, \"treatment\", \"\")の代わりにstr_remove(term, \"treatment\")でも良い。↩︎",
    "crumbs": [
      "因果推論の考え方とランダム化比較試験"
    ]
  },
  {
    "objectID": "material/did.html",
    "href": "material/did.html",
    "title": "差分の差分法",
    "section": "",
    "text": "新しいタブで開く",
    "crumbs": [
      "差分の差分法"
    ]
  },
  {
    "objectID": "material/did.html#スライド",
    "href": "material/did.html#スライド",
    "title": "差分の差分法",
    "section": "",
    "text": "新しいタブで開く",
    "crumbs": [
      "差分の差分法"
    ]
  },
  {
    "objectID": "material/did.html#セットアップ",
    "href": "material/did.html#セットアップ",
    "title": "差分の差分法",
    "section": "セットアップ",
    "text": "セットアップ\n　本日の実習に必要なパッケージとデータを読み込む。\n\npacman::p_load(tidyverse,     # Rの必須パッケージ\n               summarytools,  # 記述統計\n               modelsummary,  # 推定結果の要約\n               estimatr,      # ロバストな回帰分析\n               gsynth,        # 一般化SCM\n               panelView)     # パネルデータのチェック\n\ndid_df &lt;- read_csv(\"data/did_data4.csv\")\n\ndid_df\n\n# A tibble: 18,749 × 14\n   county state  year shooting fatal_shooting non_fatal_shooting turnout demvote\n    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;              &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1   1001 01     1996        0              0                  0    56.1    32.5\n 2   1001 01     2000        0              0                  0    56.8    28.7\n 3   1001 01     2004        0              0                  0    60.2    23.7\n 4   1001 01     2008        0              0                  0    64.1    25.8\n 5   1001 01     2012        0              0                  0    61.0    26.5\n 6   1001 01     2016        0              0                  0    60.7    24.0\n 7   1003 01     1996        0              0                  0    51.8    27.1\n 8   1003 01     2000        0              0                  0    54.6    24.8\n 9   1003 01     2004        0              0                  0    59.8    22.5\n10   1003 01     2008        0              0                  0    62.4    23.8\n# ℹ 18,739 more rows\n# ℹ 6 more variables: population &lt;dbl&gt;, non_white &lt;dbl&gt;,\n#   change_unem_rate &lt;dbl&gt;, county_f &lt;dbl&gt;, state_f &lt;chr&gt;, year_f &lt;dbl&gt;\n\n\n　データの詳細はスライドを参照すること。DID推定には時間（年）とカウンティー（郡）の固定効果を投入し、州レベルでクラスタリングした標準誤差を使う予定である。これらの変数を予めfactor化しておこう。factor化した変数は変数名の後ろに_fを付けて、新しい列として追加しておく。\n\ndid_df &lt;- did_df |&gt;\n  mutate(county_f = factor(county),\n         state_f  = factor(state),\n         year_f   = factor(year))\n\ndid_df\n\n# A tibble: 18,749 × 14\n   county state  year shooting fatal_shooting non_fatal_shooting turnout demvote\n    &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;              &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1   1001 01     1996        0              0                  0    56.1    32.5\n 2   1001 01     2000        0              0                  0    56.8    28.7\n 3   1001 01     2004        0              0                  0    60.2    23.7\n 4   1001 01     2008        0              0                  0    64.1    25.8\n 5   1001 01     2012        0              0                  0    61.0    26.5\n 6   1001 01     2016        0              0                  0    60.7    24.0\n 7   1003 01     1996        0              0                  0    51.8    27.1\n 8   1003 01     2000        0              0                  0    54.6    24.8\n 9   1003 01     2004        0              0                  0    59.8    22.5\n10   1003 01     2008        0              0                  0    62.4    23.8\n# ℹ 18,739 more rows\n# ℹ 6 more variables: population &lt;dbl&gt;, non_white &lt;dbl&gt;,\n#   change_unem_rate &lt;dbl&gt;, county_f &lt;fct&gt;, state_f &lt;fct&gt;, year_f &lt;fct&gt;\n\n\n　連続変数（shootingからchange_unem_rateまで）の記述統計量を出力する。\n\ndid_df |&gt;\n  select(shooting:change_unem_rate) |&gt;\n  descr(stats = c(\"mean\", \"sd\", \"min\", \"max\", \"n.valid\"),\n        transpose = TRUE, order = \"p\")\n\nDescriptive Statistics  \n\n                               Mean     Std.Dev      Min           Max    N.Valid\n------------------------ ---------- ----------- -------- ------------- ----------\n                shooting       0.00        0.07     0.00          1.00   18749.00\n          fatal_shooting       0.00        0.05     0.00          1.00   18749.00\n      non_fatal_shooting       0.00        0.04     0.00          1.00   18749.00\n                 turnout      57.94       10.32     1.08        300.00   18627.00\n                 demvote      39.01       13.79     3.14         92.85   18627.00\n              population   95121.69   306688.63    55.00   10137915.00   18749.00\n               non_white       0.13        0.16     0.00          0.96   18749.00\n        change_unem_rate      -0.39        2.34   -19.60         15.30   18749.00\n\n\n\n\n\n\n\n\nselect()関数がおかしい?\n\n\n\n　今回の講義に限らず、よくある問題としてパッケージ間の衝突がある。これは同じ名前の関数が複数存在する際に生じる。たとえば、select()関数は{dplyr}パッケージだけでなく、{MASS}という有名なパッケージにも同じ名前の関数が存在する。自分が{dplyr}のみ読み込み、{MASS}を読み込まなかったとしても衝突は生じうる。たとえば、{X}というパッケージが{MASS}に依存する場合、{X}を読み込むと、裏では{MASS}も読み込まれるからだ。そもそも我々も{dplyr}を読み込んでないが、{tidyverse}が{dplyr}に依存しているため、{dplyr}が読み込まれている。\n　したがって、絶対存在するはずの関数で使い方も間違っていないにも関わらずエラーが発生した場合は、「どのパッケージの関数か」を明記してみよう。書き方はパッケージ名::関数名()だ。たとえば、{dplyr}パッケージのselect()関数はdplyr::select()と書く。",
    "crumbs": [
      "差分の差分法"
    ]
  },
  {
    "objectID": "material/did.html#diff-in-diff",
    "href": "material/did.html#diff-in-diff",
    "title": "差分の差分法",
    "section": "Diff-in-Diff",
    "text": "Diff-in-Diff\n　それでは差分の差分法の実装について紹介する。推定式は以下の通りである。\n\\[\n\\mbox{Outcome}_{i, t} = \\beta_0 + \\beta_1 \\mbox{Shooting}_{i, t} + \\sum_k \\delta_{k, i, t} \\mbox{Controls}_{k, i, t} + \\lambda_{t} + \\omega_{i} + \\varepsilon_{i, t}\n\\]\n\n\\(\\mbox{Otucome}\\): 応答変数\n\nturnout: 投票率（大統領選挙）\ndemvote: 民主党候補者の得票率\n\n\\(\\mbox{Shooting}\\): 処置変数\n\nshooting: 銃撃事件の発生有無\nfatal_shooting: 死者を伴う銃撃事件の発生有無\nnon_fatal_shooting: 死者を伴わない銃撃事件の発生有無\n\n\\(\\mbox{Controls}\\): 統制変数\n\npopulation: カウンティーの人口\nnon_white: 非白人の割合\nchange_unem_rate: 失業率の変化\n統制変数あり/なしのモデルを個別に推定\n\n\\(\\lambda\\): 年固定効果\n\\(\\omega\\): カウンティー固定効果\n\n応答変数が2種類、処置変数が3種類、共変量の有無でモデルを分けるので、推定するモデルは計12個である。\n\n\n\nモデル\nオブジェクト名\n応答変数\n処置変数\n統制変数\n\n\n\n\nモデル1\ndid_fit1\nturnout\nshooting\nなし\n\n\nモデル2\ndid_fit2\nturnout\nshooting\nあり\n\n\nモデル3\ndid_fit3\nturnout\nfatal_shooting\nなし\n\n\nモデル4\ndid_fit4\nturnout\nfatal_shooting\nあり\n\n\nモデル5\ndid_fit5\nturnout\nnon_fatal_shooting\nなし\n\n\nモデル6\ndid_fit6\nturnout\nnon_fatal_shooting\nあり\n\n\nモデル7\ndid_fit7\ndemvote\nshooting\nなし\n\n\nモデル8\ndid_fit8\ndemvote\nshooting\nあり\n\n\nモデル9\ndid_fit9\ndemvote\nfatal_shooting\nなし\n\n\nモデル10\ndid_fit10\ndemvote\nfatal_shooting\nあり\n\n\nモデル11\ndid_fit11\ndemvote\nnon_fatal_shooting\nなし\n\n\nモデル12\ndid_fit12\ndemvote\nnon_fatal_shooting\nあり\n\n\n\n　まずはモデル1を推定し、did_fit1という名のオブジェクトとして格納する。基本的には線形回帰分析であるため、lm()でも推定はできる。しかし、差分の差分法の場合、通常、クラスター化した頑健な標準誤差（cluster robust standard error）を使う。lm()単体ではこれが計算できないため、今回は{estimatr}パッケージが提供するlm_robust()関数を使用する。使い方はlm()同様、まず回帰式と使用するデータ名を指定する。続いて、固定効果をfixed_effects引数で指定する1。書き方は~固定効果変数1 + 固定効果変数2 + ...である。回帰式と違って、~の左側には変数がないことに注意すること。続いて、clusters引数でクラスタリングする変数を指定する。今回は州レベルでクラスタリングするので、state_fで良い。最後に標準誤差のタイプを指定するが、デフォルトは\"CR2\"となっている。今回のデータはそれなりの大きさのデータであり、\"CR2\"だと推定時間が非常に長くなる。ここでは推定時間が比較的早い\"stata\"とする。\n\ndid_fit1 &lt;- lm_robust(turnout ~ shooting, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\nsummary(did_fit1)\n\n\nCall:\nlm_robust(formula = turnout ~ shooting, data = did_df, clusters = state_f, \n    fixed_effects = ~year_f + county_f, se_type = \"stata\")\n\nStandard error type:  stata \n\nCoefficients:\n         Estimate Std. Error t value Pr(&gt;|t|) CI Lower CI Upper DF\nshooting  -0.5211     0.6457  -0.807   0.4235   -1.819   0.7764 49\n\nMultiple R-squared:  0.8575 ,   Adjusted R-squared:  0.8288\nMultiple R-squared (proj. model):  6.907e-05 ,  Adjusted R-squared (proj. model):  -0.2008 \nF-statistic (proj. model): 0.6513 on 1 and 49 DF,  p-value: 0.4235\n\n\n　処置効果の推定値は-0.521である。これは学校内銃撃事件が発生したカウンティーの場合、大統領選挙において投票率が約-0.521%p低下することを意味する。しかし、標準誤差がかなり大きく、統計的有意な結果ではない。つまり、「学校内銃撃事件が投票率を上げる（or 下げる）とは言えない」と解釈できる。決して「学校内銃撃事件が投票率を上げない（or 下げない）」と解釈しないこと。\n　共変量を投入してみたらどうだろうか。たとえば、人口は自治体の都市化程度を表すこともあるので、都市化程度と投票率には関係があると考えられる。また、人口が多いと自然に事件が発生する確率もあがるので、交絡要因として考えられる。人種や失業率も同様であろう。ここではカウンティーの人口（population）、非白人の割合（non_white）、失業率の変化（change_unem_rate）を統制変数として投入し、did_fit2という名で格納する。\n\ndid_fit2 &lt;- lm_robust(turnout ~ shooting + \n                        population + non_white + change_unem_rate, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\nsummary(did_fit2)\n\n\nCall:\nlm_robust(formula = turnout ~ shooting + population + non_white + \n    change_unem_rate, data = did_df, clusters = state_f, fixed_effects = ~year_f + \n    county_f, se_type = \"stata\")\n\nStandard error type:  stata \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)   CI Lower   CI Upper\nshooting         -7.098e-01  6.237e-01  -1.138  0.26066 -1.963e+00  5.436e-01\npopulation        8.029e-06  5.688e-06   1.411  0.16443 -3.402e-06  1.946e-05\nnon_white        -3.483e+01  1.558e+01  -2.236  0.02990 -6.613e+01 -3.534e+00\nchange_unem_rate  1.592e-01  6.584e-02   2.418  0.01938  2.688e-02  2.915e-01\n                 DF\nshooting         49\npopulation       49\nnon_white        49\nchange_unem_rate 49\n\nMultiple R-squared:  0.8598 ,   Adjusted R-squared:  0.8316\nMultiple R-squared (proj. model):  0.01669 ,    Adjusted R-squared (proj. model):  -0.1811 \nF-statistic (proj. model): 5.047 on 4 and 49 DF,  p-value: 0.001739\n\n\n　処置効果の推定値は-0.710である。これは他の条件が同じ場合、学校内銃撃事件が発生したカウンティーは大統領選挙において投票率が約-0.710%p低下することを意味する。ちなみに、e-01は\\(\\times 10^{-1}\\)を、e-06は\\(\\times 10^{-6}\\)を、e+01は\\(\\times 10^{1}\\)意味する。今回も統計的に非有意な結果が得られている。\n　これまでの処置変数は死者の有無と関係なく、学校内銃撃事件が発生したか否かだった。もしかしたら、死者を伴う銃撃事件が発生した場合、その効果が大きいかも知れない。したがって、これからは処置変数を死者を伴う学校内銃撃事件の発生有無（fatal_shooting）、死者を伴わない学校内銃撃事件の発生有無（non_fatal_shooting）に変えてもう一度推定してみよう。\n\ndid_fit3 &lt;- lm_robust(turnout ~ fatal_shooting, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit4 &lt;- lm_robust(turnout ~ fatal_shooting + \n                        population + non_white + change_unem_rate, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit5 &lt;- lm_robust(turnout ~ non_fatal_shooting, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit6 &lt;- lm_robust(turnout ~ non_fatal_shooting + \n                        population + non_white + change_unem_rate, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\n　これまで推定してきた6つのモデルを比較してみよう。\n\nmodelsummary(list(did_fit1, did_fit2, did_fit3, \n                  did_fit4, did_fit5, did_fit6))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n                (3)\n                (4)\n                (5)\n                (6)\n              \n        \n        \n        \n                \n                  shooting          \n                  -0.521     \n                  -0.710     \n                             \n                             \n                             \n                             \n                \n                \n                                    \n                  (0.646)    \n                  (0.624)    \n                             \n                             \n                             \n                             \n                \n                \n                  population        \n                             \n                  0.000      \n                             \n                  0.000      \n                             \n                  0.000      \n                \n                \n                                    \n                             \n                  (0.000)    \n                             \n                  (0.000)    \n                             \n                  (0.000)    \n                \n                \n                  non_white         \n                             \n                  -34.834    \n                             \n                  -34.844    \n                             \n                  -34.814    \n                \n                \n                                    \n                             \n                  (15.575)   \n                             \n                  (15.618)   \n                             \n                  (15.614)   \n                \n                \n                  change_unem_rate  \n                             \n                  0.159      \n                             \n                  0.159      \n                             \n                  0.160      \n                \n                \n                                    \n                             \n                  (0.066)    \n                             \n                  (0.066)    \n                             \n                  (0.066)    \n                \n                \n                  fatal_shooting    \n                             \n                             \n                  -0.678     \n                  -0.918     \n                             \n                             \n                \n                \n                                    \n                             \n                             \n                  (0.619)    \n                  (0.658)    \n                             \n                             \n                \n                \n                  non_fatal_shooting\n                             \n                             \n                             \n                             \n                  -0.239     \n                  -0.327     \n                \n                \n                                    \n                             \n                             \n                             \n                             \n                  (1.094)    \n                  (1.145)    \n                \n                \n                  Num.Obs.          \n                  18627      \n                  18627      \n                  18627      \n                  18627      \n                  18627      \n                  18627      \n                \n                \n                  R2                \n                  0.857      \n                  0.860      \n                  0.857      \n                  0.860      \n                  0.857      \n                  0.860      \n                \n                \n                  R2 Adj.           \n                  0.829      \n                  0.832      \n                  0.829      \n                  0.832      \n                  0.829      \n                  0.832      \n                \n                \n                  AIC               \n                  103543.4   \n                  103237.2   \n                  103543.3   \n                  103237.1   \n                  103544.6   \n                  103239.4   \n                \n                \n                  BIC               \n                  103559.0   \n                  103276.4   \n                  103559.0   \n                  103276.3   \n                  103560.2   \n                  103278.6   \n                \n                \n                  RMSE              \n                  3.90       \n                  3.87       \n                  3.90       \n                  3.87       \n                  3.90       \n                  3.87       \n                \n                \n                  Std.Errors        \n                  by: state_f\n                  by: state_f\n                  by: state_f\n                  by: state_f\n                  by: state_f\n                  by: state_f\n                \n        \n      \n    \n\n\n\n　いずれのモデルも統計的に有意な処置効果は確認されていない。これらの結果を表として報告するには紙がもったいない気もする。これらの結果はOnline Appendixに回し、本文中には処置効果の点推定値と95%信頼区間を示せば良いだろう。\n　{broom}のtidy()関数で推定結果のみを抽出し、それぞれオブジェクトとして格納しておこう。\n\ntidy_fit1 &lt;- tidy(did_fit1, conf.int = TRUE)\ntidy_fit2 &lt;- tidy(did_fit2, conf.int = TRUE)\ntidy_fit3 &lt;- tidy(did_fit3, conf.int = TRUE)\ntidy_fit4 &lt;- tidy(did_fit4, conf.int = TRUE)\ntidy_fit5 &lt;- tidy(did_fit5, conf.int = TRUE)\ntidy_fit6 &lt;- tidy(did_fit6, conf.int = TRUE)\n\n　全て確認する必要はないので、tidy_fit1のみを確認してみる。\n\ntidy_fit1\n\n      term   estimate std.error  statistic   p.value conf.low conf.high df\n1 shooting -0.5210841 0.6456718 -0.8070417 0.4235426 -1.81861  0.776442 49\n  outcome\n1 turnout\n\n\n　以上の6つの表形式オブジェクトを一つの表としてまとめる。それぞれのオブジェクトには共変量の有無_処置変数の種類の名前を付けよう。共変量なしのモデルはM1、ありのモデルはM2とする。処置変数はshootingの場合はTr1、fatal_shootingはTr2、non_fatal_shootingはTr3とする。\n\ndid_est1 &lt;- bind_rows(list(\"M1_Tr1\" = tidy_fit1,\n                           \"M2_Tr1\" = tidy_fit2,\n                           \"M1_Tr2\" = tidy_fit3,\n                           \"M2_Tr2\" = tidy_fit4,\n                           \"M1_Tr3\" = tidy_fit5,\n                           \"M2_Tr3\" = tidy_fit6),\n                      .id = \"Model\")\n\ndid_est1\n\n    Model               term      estimate    std.error  statistic    p.value\n1  M1_Tr1           shooting -5.210841e-01 6.456718e-01 -0.8070417 0.42354260\n2  M2_Tr1           shooting -7.097922e-01 6.237320e-01 -1.1379763 0.26066411\n3  M2_Tr1         population  8.028568e-06 5.688141e-06  1.4114574 0.16442833\n4  M2_Tr1          non_white -3.483443e+01 1.557543e+01 -2.2364985 0.02990378\n5  M2_Tr1   change_unem_rate  1.592020e-01 6.584450e-02  2.4178480 0.01937671\n6  M1_Tr2     fatal_shooting -6.779229e-01 6.191749e-01 -1.0948810 0.27892152\n7  M2_Tr2     fatal_shooting -9.179995e-01 6.576559e-01 -1.3958659 0.16904785\n8  M2_Tr2         population  8.026778e-06 5.747531e-06  1.3965611 0.16883977\n9  M2_Tr2          non_white -3.484436e+01 1.561829e+01 -2.2309975 0.03029042\n10 M2_Tr2   change_unem_rate  1.591126e-01 6.591001e-02  2.4140886 0.01955574\n11 M1_Tr3 non_fatal_shooting -2.387205e-01 1.093832e+00 -0.2182423 0.82814672\n12 M2_Tr3 non_fatal_shooting -3.269742e-01 1.145303e+00 -0.2854915 0.77647098\n13 M2_Tr3         population  7.821482e-06 5.712400e-06  1.3692110 0.17717684\n14 M2_Tr3          non_white -3.481384e+01 1.561438e+01 -2.2296020 0.03038921\n15 M2_Tr3   change_unem_rate  1.595359e-01 6.590170e-02  2.4208169 0.01923637\n        conf.low     conf.high df outcome\n1  -1.818610e+00  7.764420e-01 49 turnout\n2  -1.963229e+00  5.436442e-01 49 turnout\n3  -3.402178e-06  1.945932e-05 49 turnout\n4  -6.613442e+01 -3.534428e+00 49 turnout\n5   2.688251e-02  2.915215e-01 49 turnout\n6  -1.922202e+00  5.663557e-01 49 turnout\n7  -2.239609e+00  4.036096e-01 49 turnout\n8  -3.523318e-06  1.957687e-05 49 turnout\n9  -6.623047e+01 -3.458237e+00 49 turnout\n10  2.666148e-02  2.915637e-01 49 turnout\n11 -2.436859e+00  1.959418e+00 49 turnout\n12 -2.628546e+00  1.974598e+00 49 turnout\n13 -3.658017e-06  1.930098e-05 49 turnout\n14 -6.619211e+01 -3.435580e+00 49 turnout\n15  2.710152e-02  2.919704e-01 49 turnout\n\n\n　続いて、処置効果のみを抽出する。処置効果はterm列の値が\"shooting\"、\"fatal_shooting\"、\"non_fatal_shooting\"のいずれかと一致する行であるため、filter()関数を使用する。\n\ndid_est1 &lt;- did_est1 |&gt;\n  filter(term %in% c(\"shooting\", \"fatal_shooting\", \"non_fatal_shooting\"))\n\ndid_est1\n\n   Model               term   estimate std.error  statistic   p.value  conf.low\n1 M1_Tr1           shooting -0.5210841 0.6456718 -0.8070417 0.4235426 -1.818610\n2 M2_Tr1           shooting -0.7097922 0.6237320 -1.1379763 0.2606641 -1.963229\n3 M1_Tr2     fatal_shooting -0.6779229 0.6191749 -1.0948810 0.2789215 -1.922202\n4 M2_Tr2     fatal_shooting -0.9179995 0.6576559 -1.3958659 0.1690478 -2.239609\n5 M1_Tr3 non_fatal_shooting -0.2387205 1.0938325 -0.2182423 0.8281467 -2.436859\n6 M2_Tr3 non_fatal_shooting -0.3269742 1.1453027 -0.2854915 0.7764710 -2.628546\n  conf.high df outcome\n1 0.7764420 49 turnout\n2 0.5436442 49 turnout\n3 0.5663557 49 turnout\n4 0.4036096 49 turnout\n5 1.9594182 49 turnout\n6 1.9745977 49 turnout\n\n\n　ちなみにgrepl()関数を使うと、\"shooting\"が含まれる行を抽出することもできる。以下のコードは上記のコードと同じ機能をする。\n\ndid_est1 &lt;- did_est1 |&gt;\n  filter(grepl(\"shooting\", term))\n\n　つづいて、Model列をModelとTreat列へ分割する。\n\ndid_est1 &lt;- did_est1 |&gt;\n  separate(col  = Model,\n           into = c(\"Model\", \"Treat\"),\n           sep  = \"_\")\n\ndid_est1\n\n  Model Treat               term   estimate std.error  statistic   p.value\n1    M1   Tr1           shooting -0.5210841 0.6456718 -0.8070417 0.4235426\n2    M2   Tr1           shooting -0.7097922 0.6237320 -1.1379763 0.2606641\n3    M1   Tr2     fatal_shooting -0.6779229 0.6191749 -1.0948810 0.2789215\n4    M2   Tr2     fatal_shooting -0.9179995 0.6576559 -1.3958659 0.1690478\n5    M1   Tr3 non_fatal_shooting -0.2387205 1.0938325 -0.2182423 0.8281467\n6    M2   Tr3 non_fatal_shooting -0.3269742 1.1453027 -0.2854915 0.7764710\n   conf.low conf.high df outcome\n1 -1.818610 0.7764420 49 turnout\n2 -1.963229 0.5436442 49 turnout\n3 -1.922202 0.5663557 49 turnout\n4 -2.239609 0.4036096 49 turnout\n5 -2.436859 1.9594182 49 turnout\n6 -2.628546 1.9745977 49 turnout\n\n\n　可視化に入る前にModel列とTreat列の値を修正する。Model列の値が\"M1\"なら\"County-Year FE\"に、それ以外なら\"County-Year FE + Covariates\"とリコーディングする。戻り値が2種類だからif_else()を使う。Treat列の場合、戻り値が3つなので、recode()かcase_when()を使う。ここではrecode()を使ってリコーディングする。最後にModelとTreatを表示順番でfactor化し（fct_inorder()）、更に順番を逆転する（fct_rev()）。\n\ndid_est1 &lt;- did_est1 |&gt;\n  mutate(Model = if_else(Model == \"M1\",\n                           \"County-Year FE\", \n                           \"County-Year FE + Covariates\"),\n         Treat = recode(Treat,\n                        \"Tr1\" = \"Any Shooting (t-1)\",\n                        \"Tr2\" = \"Fatal Shooting (t-1)\",\n                        \"Tr3\" = \"Nonfatal Shooting (t-1)\"),\n         Model = fct_rev(fct_inorder(Model)),\n         Treat = fct_rev(fct_inorder(Treat)))\n\ndid_est1\n\n                        Model                   Treat               term\n1              County-Year FE      Any Shooting (t-1)           shooting\n2 County-Year FE + Covariates      Any Shooting (t-1)           shooting\n3              County-Year FE    Fatal Shooting (t-1)     fatal_shooting\n4 County-Year FE + Covariates    Fatal Shooting (t-1)     fatal_shooting\n5              County-Year FE Nonfatal Shooting (t-1) non_fatal_shooting\n6 County-Year FE + Covariates Nonfatal Shooting (t-1) non_fatal_shooting\n    estimate std.error  statistic   p.value  conf.low conf.high df outcome\n1 -0.5210841 0.6456718 -0.8070417 0.4235426 -1.818610 0.7764420 49 turnout\n2 -0.7097922 0.6237320 -1.1379763 0.2606641 -1.963229 0.5436442 49 turnout\n3 -0.6779229 0.6191749 -1.0948810 0.2789215 -1.922202 0.5663557 49 turnout\n4 -0.9179995 0.6576559 -1.3958659 0.1690478 -2.239609 0.4036096 49 turnout\n5 -0.2387205 1.0938325 -0.2182423 0.8281467 -2.436859 1.9594182 49 turnout\n6 -0.3269742 1.1453027 -0.2854915 0.7764710 -2.628546 1.9745977 49 turnout\n\n\n　それでは{ggplot2}を使ってpoint-rangeプロットを作成してみよう。\n\ndid_est1 |&gt;\n  ggplot() +\n  # x = 0の箇所に垂直線を引く。垂直線は破線（linetype = 2）とする。\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(x = estimate, xmin = conf.low, xmax = conf.high,\n                      y = Treat, color = Model),\n                  position = position_dodge2(1/2)) +\n  labs(x = \"Change in Turnout (%p)\", y = \"\", color = \"\") +\n  # 色を指定する。\n  # Modelの値が County-Year FE なら黒、\n  # County-Year FE + Covariates ならグレー、\n  scale_color_manual(values = c(\"County-Year FE\" = \"black\", \n                                \"County-Year FE + Covariates\" = \"gray50\")) +\n  # 横軸の下限と上限を-10〜10とする。\n  coord_cartesian(xlim = c(-10, 10)) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　元の論文を見ると、点の上に点推定値が書かれているが、私たちもこれを真似してみよう。文字列をプロットするレイヤーはgeom_text()とgeom_label()、annotate()があるが、ここではgeom_text()を使用する。文字列が表示される横軸上の位置（x）と縦軸上の位置（y）、そして出力する文字列（label）をマッピングする。点推定値は3桁まで出力したいので、sprintf()を使って、3桁に丸める。ただし、これだけだと点と文字が重なってしまう。vjustを-0.75にすることで、出力する文字列を点の位置を上の方向へ若干ずらすことができる。\n\ndid_est1 |&gt;\n  ggplot() +\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(x = estimate, xmin = conf.low, xmax = conf.high,\n                      y = Treat, color = Model),\n                  position = position_dodge2(1/2)) +\n  geom_text(aes(x = estimate, y = Treat, color = Model, \n                label = sprintf(\"%.3f\", estimate)),\n            position = position_dodge2(1/2),\n            vjust = -0.75) +\n  labs(x = \"Change in Turnout (%p)\", y = \"\", color = \"\") +\n  scale_color_manual(values = c(\"County-Year FE\" = \"black\", \n                                \"County-Year FE + Covariates\" = \"gray50\")) +\n  coord_cartesian(xlim = c(-10, 10)) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　ちなみにこのコードを見ると、geom_pointrange()とgeom_text()はx、y、colorを共有しているので、ggplot()内でマッピングすることもできる。\n\ndid_est1 |&gt;\n  ggplot(aes(x = estimate, y = Treat, color = Model)) +\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(xmin = conf.low, xmax = conf.high),\n                  position = position_dodge2(1/2)) +\n  geom_text(aes(label = sprintf(\"%.3f\", estimate)),\n            position = position_dodge2(1/2),\n            vjust = -0.75) +\n  labs(x = \"Change in Turnout (%p)\", y = \"\", color = \"\") +\n  scale_color_manual(values = c(\"County-Year FE\" = \"black\", \n                                \"County-Year FE + Covariates\" = \"gray50\")) +\n  coord_cartesian(xlim = c(-10, 10)) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n　続いて、民主党候補者の得票率（demvote）を応答変数として6つのモデルを推定し、同じ作業を繰り返す。\n\ndid_fit7 &lt;- lm_robust(demvote ~ shooting, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit8 &lt;- lm_robust(demvote ~ shooting + \n                        population + non_white + change_unem_rate, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit9 &lt;- lm_robust(demvote ~ fatal_shooting, \n                      data          = did_df, \n                      fixed_effects = ~year_f + county_f,\n                      clusters      = state_f,\n                      se_type       = \"stata\")\n\ndid_fit10 &lt;- lm_robust(demvote ~ fatal_shooting + \n                         population + non_white + change_unem_rate, \n                       data          = did_df, \n                       fixed_effects = ~year_f + county_f,\n                       clusters      = state_f,\n                       se_type       = \"stata\")\n\ndid_fit11 &lt;- lm_robust(demvote ~ non_fatal_shooting, \n                       data          = did_df, \n                       fixed_effects = ~year_f + county_f,\n                       clusters      = state_f,\n                       se_type       = \"stata\")\n\ndid_fit12 &lt;- lm_robust(demvote ~ non_fatal_shooting + \n                         population + non_white + change_unem_rate, \n                       data          = did_df, \n                       fixed_effects = ~year_f + county_f,\n                       clusters      = state_f,\n                       se_type       = \"stata\")\n\nmodelsummary(list(\"Model 7\"  = did_fit7,  \"Model 8\"  = did_fit8, \n                  \"Model 9\"  = did_fit9,  \"Model 10\" = did_fit10, \n                  \"Model 11\" = did_fit11, \"Model 12\" = did_fit12))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model 7\n                Model 8\n                Model 9\n                Model 10\n                Model 11\n                Model 12\n              \n        \n        \n        \n                \n                  shooting          \n                  4.513      \n                  2.364      \n                             \n                             \n                             \n                             \n                \n                \n                                    \n                  (0.875)    \n                  (0.737)    \n                             \n                             \n                             \n                             \n                \n                \n                  population        \n                             \n                  0.000      \n                             \n                  0.000      \n                             \n                  0.000      \n                \n                \n                                    \n                             \n                  (0.000)    \n                             \n                  (0.000)    \n                             \n                  (0.000)    \n                \n                \n                  non_white         \n                             \n                  86.873     \n                             \n                  86.866     \n                             \n                  86.796     \n                \n                \n                                    \n                             \n                  (17.863)   \n                             \n                  (17.855)   \n                             \n                  (17.855)   \n                \n                \n                  change_unem_rate  \n                             \n                  -0.139     \n                             \n                  -0.139     \n                             \n                  -0.140     \n                \n                \n                                    \n                             \n                  (0.127)    \n                             \n                  (0.128)    \n                             \n                  (0.127)    \n                \n                \n                  fatal_shooting    \n                             \n                             \n                  4.404      \n                  1.782      \n                             \n                             \n                \n                \n                                    \n                             \n                             \n                  (1.092)    \n                  (0.836)    \n                             \n                             \n                \n                \n                  non_fatal_shooting\n                             \n                             \n                             \n                             \n                  4.217      \n                  2.930      \n                \n                \n                                    \n                             \n                             \n                             \n                             \n                  (1.298)    \n                  (1.037)    \n                \n                \n                  Num.Obs.          \n                  18627      \n                  18627      \n                  18627      \n                  18627      \n                  18627      \n                  18627      \n                \n                \n                  R2                \n                  0.882      \n                  0.894      \n                  0.882      \n                  0.894      \n                  0.882      \n                  0.894      \n                \n                \n                  R2 Adj.           \n                  0.859      \n                  0.873      \n                  0.859      \n                  0.873      \n                  0.859      \n                  0.873      \n                \n                \n                  AIC               \n                  110745.2   \n                  108755.4   \n                  110772.0   \n                  108768.2   \n                  110786.5   \n                  108762.1   \n                \n                \n                  BIC               \n                  110760.8   \n                  108794.6   \n                  110787.7   \n                  108807.3   \n                  110802.2   \n                  108801.3   \n                \n                \n                  RMSE              \n                  4.73       \n                  4.48       \n                  4.73       \n                  4.48       \n                  4.73       \n                  4.48       \n                \n                \n                  Std.Errors        \n                  by: state_f\n                  by: state_f\n                  by: state_f\n                  by: state_f\n                  by: state_f\n                  by: state_f\n                \n        \n      \n    \n\n\n\n　今回はいずれも統計的に有意な結果が得られている。例えば、モデル7（did_fit7）の場合、処置効果の推定値は4.513である。これは学校内銃撃事件が発生したカウンティーの場合、大統領選挙において民主党候補者の得票率が約4.513%p増加することを意味する。\n　以上の結果を図としてまとめてみよう。\n\ntidy_fit7  &lt;- tidy(did_fit7)\ntidy_fit8  &lt;- tidy(did_fit8)\ntidy_fit9  &lt;- tidy(did_fit9)\ntidy_fit10 &lt;- tidy(did_fit10)\ntidy_fit11 &lt;- tidy(did_fit11)\ntidy_fit12 &lt;- tidy(did_fit12)\n\ndid_est2 &lt;- bind_rows(list(\"M1_Tr1\" = tidy_fit7,\n                           \"M2_Tr1\" = tidy_fit8,\n                           \"M1_Tr2\" = tidy_fit9,\n                           \"M2_Tr2\" = tidy_fit10,\n                           \"M1_Tr3\" = tidy_fit11,\n                           \"M2_Tr3\" = tidy_fit12),\n                      .id = \"Model\")\n\ndid_est2\n\n    Model               term      estimate    std.error statistic      p.value\n1  M1_Tr1           shooting  4.513237e+00 8.752702e-01  5.156393 4.514820e-06\n2  M2_Tr1           shooting  2.363839e+00 7.367346e-01  3.208536 2.353748e-03\n3  M2_Tr1         population  3.174252e-05 6.778757e-06  4.682646 2.275534e-05\n4  M2_Tr1          non_white  8.687344e+01 1.786287e+01  4.863352 1.234074e-05\n5  M2_Tr1   change_unem_rate -1.389392e-01 1.274198e-01 -1.090405 2.808682e-01\n6  M1_Tr2     fatal_shooting  4.404109e+00 1.091944e+00  4.033274 1.920110e-04\n7  M2_Tr2     fatal_shooting  1.782393e+00 8.363792e-01  2.131083 3.812471e-02\n8  M2_Tr2         population  3.206812e-05 6.801197e-06  4.715070 2.039958e-05\n9  M2_Tr2          non_white  8.686629e+01 1.785535e+01  4.865000 1.227169e-05\n10 M2_Tr2   change_unem_rate -1.392341e-01 1.275138e-01 -1.091914 2.802109e-01\n11 M1_Tr3 non_fatal_shooting  4.216683e+00 1.298056e+00  3.248460 2.098382e-03\n12 M2_Tr3 non_fatal_shooting  2.929866e+00 1.037217e+00  2.824737 6.825655e-03\n13 M2_Tr3         population  3.229215e-05 6.717999e-06  4.806810 1.495567e-05\n14 M2_Tr3          non_white  8.679618e+01 1.785514e+01  4.861131 1.243440e-05\n15 M2_Tr3   change_unem_rate -1.400321e-01 1.274994e-01 -1.098296 2.774427e-01\n        conf.low    conf.high df outcome\n1   2.754316e+00 6.272159e+00 49 demvote\n2   8.833157e-01 3.844363e+00 49 demvote\n3   1.812010e-05 4.536494e-05 49 demvote\n4   5.097665e+01 1.227702e+02 49 demvote\n5  -3.949989e-01 1.171206e-01 49 demvote\n6   2.209766e+00 6.598453e+00 49 demvote\n7   1.016261e-01 3.463160e+00 49 demvote\n8   1.840061e-05 4.573564e-05 49 demvote\n9   5.098461e+01 1.227480e+02 49 demvote\n10 -3.954828e-01 1.170146e-01 49 demvote\n11  1.608142e+00 6.825225e+00 49 demvote\n12  8.454996e-01 5.014232e+00 49 demvote\n13  1.879182e-05 4.579247e-05 49 demvote\n14  5.091493e+01 1.226774e+02 49 demvote\n15 -3.962518e-01 1.161876e-01 49 demvote\n\n\n\ndid_est2 &lt;- did_est2 |&gt;\n  filter(grepl(\"shooting\", term))\n\ndid_est2\n\n   Model               term estimate std.error statistic      p.value  conf.low\n1 M1_Tr1           shooting 4.513237 0.8752702  5.156393 4.514820e-06 2.7543158\n2 M2_Tr1           shooting 2.363839 0.7367346  3.208536 2.353748e-03 0.8833157\n3 M1_Tr2     fatal_shooting 4.404109 1.0919440  4.033274 1.920110e-04 2.2097656\n4 M2_Tr2     fatal_shooting 1.782393 0.8363792  2.131083 3.812471e-02 0.1016261\n5 M1_Tr3 non_fatal_shooting 4.216683 1.2980560  3.248460 2.098382e-03 1.6081422\n6 M2_Tr3 non_fatal_shooting 2.929866 1.0372173  2.824737 6.825655e-03 0.8454996\n  conf.high df outcome\n1  6.272159 49 demvote\n2  3.844363 49 demvote\n3  6.598453 49 demvote\n4  3.463160 49 demvote\n5  6.825225 49 demvote\n6  5.014232 49 demvote\n\n\n\ndid_est2 &lt;- did_est2 |&gt;\n  separate(col  = Model,\n           into = c(\"Model\", \"Treat\"),\n           sep  = \"_\")\n\ndid_est2\n\n  Model Treat               term estimate std.error statistic      p.value\n1    M1   Tr1           shooting 4.513237 0.8752702  5.156393 4.514820e-06\n2    M2   Tr1           shooting 2.363839 0.7367346  3.208536 2.353748e-03\n3    M1   Tr2     fatal_shooting 4.404109 1.0919440  4.033274 1.920110e-04\n4    M2   Tr2     fatal_shooting 1.782393 0.8363792  2.131083 3.812471e-02\n5    M1   Tr3 non_fatal_shooting 4.216683 1.2980560  3.248460 2.098382e-03\n6    M2   Tr3 non_fatal_shooting 2.929866 1.0372173  2.824737 6.825655e-03\n   conf.low conf.high df outcome\n1 2.7543158  6.272159 49 demvote\n2 0.8833157  3.844363 49 demvote\n3 2.2097656  6.598453 49 demvote\n4 0.1016261  3.463160 49 demvote\n5 1.6081422  6.825225 49 demvote\n6 0.8454996  5.014232 49 demvote\n\n\n\ndid_est2 &lt;- did_est2 |&gt;\n  mutate(Model = if_else(Model == \"M1\",\n                           \"County-Year FE\", \n                           \"County-Year FE + Covariates\"),\n         Treat = recode(Treat,\n                        \"Tr1\" = \"Any Shooting (t-1)\",\n                        \"Tr2\" = \"Fatal Shooting (t-1)\",\n                        \"Tr3\" = \"Nonfatal Shooting (t-1)\"),\n         Model = fct_rev(fct_inorder(Model)),\n         Treat = fct_rev(fct_inorder(Treat)))\n\ndid_est2\n\n                        Model                   Treat               term\n1              County-Year FE      Any Shooting (t-1)           shooting\n2 County-Year FE + Covariates      Any Shooting (t-1)           shooting\n3              County-Year FE    Fatal Shooting (t-1)     fatal_shooting\n4 County-Year FE + Covariates    Fatal Shooting (t-1)     fatal_shooting\n5              County-Year FE Nonfatal Shooting (t-1) non_fatal_shooting\n6 County-Year FE + Covariates Nonfatal Shooting (t-1) non_fatal_shooting\n  estimate std.error statistic      p.value  conf.low conf.high df outcome\n1 4.513237 0.8752702  5.156393 4.514820e-06 2.7543158  6.272159 49 demvote\n2 2.363839 0.7367346  3.208536 2.353748e-03 0.8833157  3.844363 49 demvote\n3 4.404109 1.0919440  4.033274 1.920110e-04 2.2097656  6.598453 49 demvote\n4 1.782393 0.8363792  2.131083 3.812471e-02 0.1016261  3.463160 49 demvote\n5 4.216683 1.2980560  3.248460 2.098382e-03 1.6081422  6.825225 49 demvote\n6 2.929866 1.0372173  2.824737 6.825655e-03 0.8454996  5.014232 49 demvote\n\n\n\ndid_est2 |&gt;\n  ggplot() +\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(x = estimate, xmin = conf.low, xmax = conf.high,\n                      y = Treat, color = Model),\n                  position = position_dodge2(1/2)) +\n  geom_text(aes(x = estimate, y = Treat, color = Model, \n                label = sprintf(\"%.3f\", estimate)),\n            position = position_dodge2(1/2),\n            vjust = -0.75) +\n  labs(x = \"Change in Democratic Vote Share (%p)\", y = \"\", color = \"\") +\n  scale_color_manual(values = c(\"County-Year FE\" = \"black\", \n                                \"County-Year FE + Covariates\" = \"gray50\")) +\n  coord_cartesian(xlim = c(-10, 10)) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　最後に、これまで作成した2つの図を一つにまとめてみよう。bind_rows()関数を使い、それぞれの表に識別子（Outcome）を与える。\n\ndid_est &lt;- bind_rows(list(\"Out1\" = did_est1,\n                          \"Out2\" = did_est2),\n                     .id = \"Outcome\")\n\ndid_est\n\n   Outcome                       Model                   Treat\n1     Out1              County-Year FE      Any Shooting (t-1)\n2     Out1 County-Year FE + Covariates      Any Shooting (t-1)\n3     Out1              County-Year FE    Fatal Shooting (t-1)\n4     Out1 County-Year FE + Covariates    Fatal Shooting (t-1)\n5     Out1              County-Year FE Nonfatal Shooting (t-1)\n6     Out1 County-Year FE + Covariates Nonfatal Shooting (t-1)\n7     Out2              County-Year FE      Any Shooting (t-1)\n8     Out2 County-Year FE + Covariates      Any Shooting (t-1)\n9     Out2              County-Year FE    Fatal Shooting (t-1)\n10    Out2 County-Year FE + Covariates    Fatal Shooting (t-1)\n11    Out2              County-Year FE Nonfatal Shooting (t-1)\n12    Out2 County-Year FE + Covariates Nonfatal Shooting (t-1)\n                 term   estimate std.error  statistic      p.value   conf.low\n1            shooting -0.5210841 0.6456718 -0.8070417 4.235426e-01 -1.8186103\n2            shooting -0.7097922 0.6237320 -1.1379763 2.606641e-01 -1.9632286\n3      fatal_shooting -0.6779229 0.6191749 -1.0948810 2.789215e-01 -1.9222015\n4      fatal_shooting -0.9179995 0.6576559 -1.3958659 1.690478e-01 -2.2396086\n5  non_fatal_shooting -0.2387205 1.0938325 -0.2182423 8.281467e-01 -2.4368592\n6  non_fatal_shooting -0.3269742 1.1453027 -0.2854915 7.764710e-01 -2.6285461\n7            shooting  4.5132372 0.8752702  5.1563930 4.514820e-06  2.7543158\n8            shooting  2.3638394 0.7367346  3.2085357 2.353748e-03  0.8833157\n9      fatal_shooting  4.4041092 1.0919440  4.0332738 1.920110e-04  2.2097656\n10     fatal_shooting  1.7823931 0.8363792  2.1310825 3.812471e-02  0.1016261\n11 non_fatal_shooting  4.2166835 1.2980560  3.2484602 2.098382e-03  1.6081422\n12 non_fatal_shooting  2.9298657 1.0372173  2.8247368 6.825655e-03  0.8454996\n   conf.high df outcome\n1  0.7764420 49 turnout\n2  0.5436442 49 turnout\n3  0.5663557 49 turnout\n4  0.4036096 49 turnout\n5  1.9594182 49 turnout\n6  1.9745977 49 turnout\n7  6.2721585 49 demvote\n8  3.8443631 49 demvote\n9  6.5984529 49 demvote\n10 3.4631600 49 demvote\n11 6.8252248 49 demvote\n12 5.0142319 49 demvote\n\n\n　Outcome列のリコーディングし、factor化する。\n\ndid_est &lt;- did_est |&gt;\n  mutate(Outcome = if_else(Outcome == \"Out1\",\n                           \"Change in Turnout (%p)\",\n                           \"Change in Democratic Vote Share (%p)\"),\n         Outcome = fct_inorder(Outcome))\n\ndid_est\n\n                                Outcome                       Model\n1                Change in Turnout (%p)              County-Year FE\n2                Change in Turnout (%p) County-Year FE + Covariates\n3                Change in Turnout (%p)              County-Year FE\n4                Change in Turnout (%p) County-Year FE + Covariates\n5                Change in Turnout (%p)              County-Year FE\n6                Change in Turnout (%p) County-Year FE + Covariates\n7  Change in Democratic Vote Share (%p)              County-Year FE\n8  Change in Democratic Vote Share (%p) County-Year FE + Covariates\n9  Change in Democratic Vote Share (%p)              County-Year FE\n10 Change in Democratic Vote Share (%p) County-Year FE + Covariates\n11 Change in Democratic Vote Share (%p)              County-Year FE\n12 Change in Democratic Vote Share (%p) County-Year FE + Covariates\n                     Treat               term   estimate std.error  statistic\n1       Any Shooting (t-1)           shooting -0.5210841 0.6456718 -0.8070417\n2       Any Shooting (t-1)           shooting -0.7097922 0.6237320 -1.1379763\n3     Fatal Shooting (t-1)     fatal_shooting -0.6779229 0.6191749 -1.0948810\n4     Fatal Shooting (t-1)     fatal_shooting -0.9179995 0.6576559 -1.3958659\n5  Nonfatal Shooting (t-1) non_fatal_shooting -0.2387205 1.0938325 -0.2182423\n6  Nonfatal Shooting (t-1) non_fatal_shooting -0.3269742 1.1453027 -0.2854915\n7       Any Shooting (t-1)           shooting  4.5132372 0.8752702  5.1563930\n8       Any Shooting (t-1)           shooting  2.3638394 0.7367346  3.2085357\n9     Fatal Shooting (t-1)     fatal_shooting  4.4041092 1.0919440  4.0332738\n10    Fatal Shooting (t-1)     fatal_shooting  1.7823931 0.8363792  2.1310825\n11 Nonfatal Shooting (t-1) non_fatal_shooting  4.2166835 1.2980560  3.2484602\n12 Nonfatal Shooting (t-1) non_fatal_shooting  2.9298657 1.0372173  2.8247368\n        p.value   conf.low conf.high df outcome\n1  4.235426e-01 -1.8186103 0.7764420 49 turnout\n2  2.606641e-01 -1.9632286 0.5436442 49 turnout\n3  2.789215e-01 -1.9222015 0.5663557 49 turnout\n4  1.690478e-01 -2.2396086 0.4036096 49 turnout\n5  8.281467e-01 -2.4368592 1.9594182 49 turnout\n6  7.764710e-01 -2.6285461 1.9745977 49 turnout\n7  4.514820e-06  2.7543158 6.2721585 49 demvote\n8  2.353748e-03  0.8833157 3.8443631 49 demvote\n9  1.920110e-04  2.2097656 6.5984529 49 demvote\n10 3.812471e-02  0.1016261 3.4631600 49 demvote\n11 2.098382e-03  1.6081422 6.8252248 49 demvote\n12 6.825655e-03  0.8454996 5.0142319 49 demvote\n\n\n　図の作り方はこれまでと変わらないが、ファセット分割を行うため、facet_wrap()レイヤーを追加する。\n\ndid_est |&gt;\n  ggplot() +\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(x = estimate, xmin = conf.low, xmax = conf.high,\n                      y = Treat, color = Model),\n                  position = position_dodge2(1/2)) +\n  geom_text(aes(x = estimate, y = Treat, color = Model, \n                label = sprintf(\"%.3f\", estimate)),\n            position = position_dodge2(1/2),\n            vjust = -0.75) +\n  labs(x = \"Treatment Effects\", y = \"\", color = \"\") +\n  scale_color_manual(values = c(\"County-Year FE\" = \"black\", \n                                \"County-Year FE + Covariates\" = \"gray50\")) +\n  coord_cartesian(xlim = c(-10, 10)) +\n  facet_wrap(~Outcome, ncol = 2) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　以上の結果から「学校内銃撃事件の発生は投票参加を促すとは言えないものの、民主党候補者の得票率を上げる」ということが言えよう。",
    "crumbs": [
      "差分の差分法"
    ]
  },
  {
    "objectID": "material/did.html#scm",
    "href": "material/did.html#scm",
    "title": "差分の差分法",
    "section": "SCM",
    "text": "SCM\n　ここでは、差分の差分法の応用としてSynthetic Control Method（SCM）を{gsynth}パッケージの使い方に重点を起きながら説明する。Synthetic Control MethodをRに実装したパッケージは{Synth}、{gsynth}、{bpCausal}などがある。SCMの代表的な論文の一つであるAbadie et al.（2015）は{Synth}パッケージを使っているが、使い方はかなり複雑である。したがって、ここでは使い方が最も簡単な{gsynth}パッケージについて説明する2。\n　ここで使用するのは歴代参院選（第7回以降）における都道府県の投票率である3。処置変数は第24回参院選から導入された「合区」だ。具体的には鳥取選挙区と島根選挙区が「鳥取・島根選挙区」に、徳島選挙区と高知選挙区が「徳島・高知選挙区」として合区されたか否かである。合区によって自分の1票の価値がほぼ半分に下がり、投票参加を妨げたのではないかという議論もあるが、本当だろうか。\n\nscm_df &lt;- read_csv(\"data/did_data5.csv\")\n\nscm_df\n\n# A tibble: 938 × 9\n   Election PrefCode PrefName_E PrefName_J Eligible  Voters EffVote Magnitude\n      &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n 1        7        1 Hokkaido   北海道      2903802 1829347 1683764         4\n 2        7        2 Aomori     青森県       823336  509254  478380         1\n 3        7        3 Iwate      岩手県       849109  619767  591977         1\n 4        7        4 Miyagi     宮城県      1049109  694827  666205         1\n 5        7        5 Akita      秋田県       771983  591315  558603         1\n 6        7        6 Yamagata   山形県       784438  636550  615414         1\n 7        7        7 Fukushima  福島県      1123975  893381  855609         2\n 8        7        8 Ibaraki    茨城県      1246254  785174  750181         2\n 9        7        9 Tochigi    栃木県       909245  638413  614249         2\n10        7       10 Gunma      群馬県       990083  719678  690448         2\n# ℹ 928 more rows\n# ℹ 1 more variable: Candidates &lt;dbl&gt;\n\n\n\nscm_df |&gt;\n  select(Eligible:Candidates) |&gt;\n  descr(stats = c(\"mean\", \"sd\", \"min\", \"max\", \"n.valid\"),\n        transpose = TRUE, order = \"p\")\n\nDescriptive Statistics  \n\n                         Mean      Std.Dev         Min           Max   N.Valid\n---------------- ------------ ------------ ----------- ------------- ---------\n        Eligible   1933435.87   1867850.63   364184.00   11454822.00    938.00\n          Voters   1139531.46   1029039.25   226580.00    6477709.00    938.00\n         EffVote   1096934.10    997876.11   217637.00    6298466.00    938.00\n       Magnitude         1.60         0.87        1.00          6.00    938.00\n      Candidates         5.49         5.42        2.00         72.00    938.00\n\n\n\n\n\n変数名\n説明\n備考\n\n\n\n\nElection\n選挙\n第XX回参議院議員通常選挙\n\n\nPrefCode\n都道府県\nJIS規格コード\n\n\nPrefName_E\n都道府県\n英語\n\n\nPrefName_J\n都道府県\n日本語\n\n\nEligible\n有権者数\n\n\n\nVoters\n投票者数\n\n\n\nEffVote\n有効投票数\n\n\n\nMagnitude\n定数\n\n\n\nCandidates\n候補者数\n\n\n\n\n　合区された選挙区における定数および候補者数の扱いについてだが、たとえば島根選挙区の場合、合区前の定数は1である。合区後の鳥取・島根選挙区も定数1だ。この場合、合区後の島根「県」の定数を1にするか0.5にするか、そして候補者数も合区における候補者数にすべきか、2に割るかが問題となるが、ここでは定数を1とし、候補者数も合区における候補者数とした。このようなコーディングが実証上、正しいかどうかは分からないが、実習の段階では問題ないだろう。\n　それでは、データを以下のように加工する。\n\nTreatという変数を作成する。PrefNameが「鳥取県」、「島根県」、「徳島県」、「高知県」であり、Electionが24以上なら1、それ以外のケースは0とする。\nTurnoutという変数を作成する。投票者数（Voters）を有権者数（Eligible）で割り、100を掛ける。\nSpoiltという変数を作成する。有効投票数（EffVote）を有権者数（Eligible）で割った値を1から引き、100を掛ける。\n都道府県名（PrefName_E）をfactor変数に変換し、PrefName_Fという列として追加します。水準（levels）の順番はデータの出現順とする。\n都道府県名（PrefName_J）をfactor化し、要素の順番はscm_df内における表示順番とする。\n\n\nscm_df &lt;- scm_df |&gt;\n  mutate(Treat      = if_else(PrefName_E %in% c(\"Tottori\", \"Shimane\",\n                                                \"Tokushima\",\"Kochi\") &\n                                Election &gt;= 24, 1, 0),\n         Turnout    = Voters / Eligible * 100,\n         Spoilt     = (1 - (EffVote / Voters)) * 100,\n         PrefName_J = fct_inorder(PrefName_J))\n\n　本格的な分析に入る前に、各ケースの処置有無を可視化してみよう。パネルデータの確認には{panelView}パッケージのpanelview()関数を使う。第一引数は応答変数 ~ 処置変数であり、data引数にデータフレームのオブジェクト名を指定する。また、indexにはユニットと時間を表す変数名を長さ2のcharacter型ベクトルとして指定します。ここでは\"PrefName_J\"と\"Election\"である。最後に、pre.post = TRUEを指定すると、処置前後を色分けしてくれるので、見やすくなる。\n\npanelview(Turnout ~ Treat, data = scm_df, \n          index = c(\"PrefName_J\", \"Election\"), pre.post = TRUE,\n          xlab = \"参院選\", ylab = \"都道府県\")\n\n\n\n\n\n\n\n\n　これを見ると処置を受けるケースが4県であり、どれも第24回参院選から処置を受けることが分かる。また、沖縄県の場合、第7・8回参院選のデータが欠損していることが分かる。\n　次は投票率の変化を時系列的に示してみよう。使い方は先ほどとほぼ同じだが、panelView()内にtype = \"outcome\"引数を追加する。\n\npanelview(Turnout ~ Treat, data = scm_df, \n          index = c(\"PrefName_J\", \"Election\"), \n          type  = \"outcome\",\n          main  = \"投票率の推移\",\n          xlab  = \"参院選\",\n          ylab  = \"投票率 (%)\")\n\n\n\n\n\n\n\n\n　これを見ると、都道府県内における投票率の変化にはバラツキがあるが、傾向としてはかなり似通っていることが分かる。また、処置後の変化（濃い青の線）を見ると、他の都道府県よりかなり落ちているようにも見える。これは合区によって何かの変化が生じた可能性があることを示唆している。\n　それではSCMをやってみよう。基本的な使い方はlm()関数に近いが、それでも必要な引数がそれなりにある。ここではその一部を紹介する。\n\n第1引数は応答変数 ~ 処置変数 + 統制変数1 + 統制変数2 + ...であり、統制変数は必須ではない。ここでは統制変数として定数（Magnitude）と候補者数（Candidates）を使用する。\ndataにはデータフレームのオブジェクト名を指定する。\nindexはpanelview()と同じだが、一つ注意が必要です。それは、ユニットを表す変数をこれまではfactor化された\"PrefName_J\"を使ってきたが、factor化されていない\"PrefName_E\"にすることだ。まだ開発途上のパッケージということもあり、ユニット変数がfactor型だと、正しく推定できない。PrefName_Eはfactor型でなくcharacter型ですので、問題ない（あえてPrefName_Eをfactor化しなかったのはこのためである）。また、numeric型であるPrefCodeを指定すれば良い。。\nforceは固定効果をユニットレベルにするか、時間レベルにするか、両方にするか、あるいはなしにするかを意味する。既定値はユニットレベル（\"unit\"）だが、ここでは両方（\"two-way\"）にする。\nseは標準誤差を計算するか否かであり、既定値はFALSEである。ここでは標準誤差も計算するためにTRUEに指定する。標準誤差を計算しない場合、計算が早く終わる。\ninferenceは推定方法を意味し、既定値はノンパラメトリック推定（\"nonparametric\"）です。ただし、処置ケースが少ない場合、パラメトリック推定が推奨されているため、ここでは\"parametric\"を指定する。\nnbootsは標準誤差を計算する際に使用されるブートストラッピングの回数である。既定値は200ですが、ここでは500回にする。\nparallelは並列計算の有無を意味する。既定値はTRUEで、このままでも通常は問題ない。ただし、R Markdown上で{gsynth}を使用する場合は並列計算ができないため、FALSEにしておく（処理時間が倍以上になる）。\n\n\nscm_fit &lt;- gsynth(Turnout ~ Treat + Magnitude + Candidates, \n                  data = scm_df, index = c(\"PrefName_E\", \"Election\"), \n                  force = \"two-way\", se = TRUE, inference = \"parametric\",\n                  nboots = 500, parallel = TRUE)\n\n\nprint(scm_fit)\n\nCall:\ngsynth.formula(formula = Turnout ~ Treat + Magnitude + Candidates, \n    data = scm_df, index = c(\"PrefName_E\", \"Election\"), force = \"two-way\", \n    se = TRUE, nboots = 500, inference = \"parametric\", parallel = FALSE)\n\nAverage Treatment Effect on the Treated:\n        Estimate S.E. CI.lower CI.upper   p.value\nATT.avg   -6.563 1.44   -9.386   -3.741 5.174e-06\n\n   ~ by Period (including Pre-treatment Periods):\n         ATT   S.E. CI.lower CI.upper   p.value n.Treated\n-16  0.09054 1.2472  -2.3539  2.53503 9.421e-01         0\n-15 -0.56609 1.3214  -3.1559  2.02374 6.683e-01         0\n-14  3.32790 1.0784   1.2142  5.44161 2.030e-03         0\n-13  1.44804 1.1103  -0.7280  3.62409 1.921e-01         0\n-12 -1.53058 1.1324  -3.7501  0.68897 1.765e-01         0\n-11 -1.21442 0.9235  -3.0245  0.59571 1.885e-01         0\n-10 -2.51664 1.2470  -4.9608 -0.07247 4.358e-02         0\n-9  -1.69683 1.1193  -3.8906  0.49691 1.295e-01         0\n-8   1.12683 1.0835  -0.9969  3.25055 2.984e-01         0\n-7  -1.03078 1.1020  -3.1907  1.12916 3.496e-01         0\n-6   3.60723 1.4785   0.7093  6.50514 1.470e-02         0\n-5  -0.85728 1.1469  -3.1051  1.39058 4.548e-01         0\n-4   0.34762 0.9078  -1.4316  2.12688 7.018e-01         0\n-3  -0.38462 0.9701  -2.2860  1.51674 6.918e-01         0\n-2   0.26204 0.9329  -1.5664  2.09047 7.788e-01         0\n-1   1.56199 0.9097  -0.2210  3.34494 8.597e-02         0\n0   -1.97495 0.9575  -3.8517 -0.09820 3.916e-02         0\n1   -6.57256 1.3963  -9.3093 -3.83577 2.514e-06         4\n2   -6.87683 1.9895 -10.7761 -2.97756 5.470e-04         4\n3   -6.24002 1.7844  -9.7374 -2.74262 4.706e-04         4\n\nCoefficients for the Covariates:\n               beta    S.E. CI.lower CI.upper   p.value\nMagnitude   2.64853 0.75614   1.1665  4.13053 0.0004605\nCandidates -0.05892 0.03847  -0.1343  0.01648 0.1256243\n\n\n　平均値な処置効果（ATT）は-6.563であり、統計的にも有意な結果が得られた。これは合区が行われた選挙区は、もし合区しなかった場合の投票率に比べ、約-6.563%p低いことを意味します。また、~ by Period以下の欄では各選挙ごとのATTが表示されます。1以降が合区以降の時期であり、それぞれ約-6.573%p、-6.877%p、-6.240%pである。上記の-6.563はこの3つの数値の平均値である。ちなみに処置群の県が4つにも関わらず、ATTが一つだけ表示されるのは、4つの平均値を出しているからだ。それぞれの県ごとに効果を確認する方法は後ほど解説する。とりあえず、この結果から合区は投票率を下げたという解釈ができよう。\n　以上の結果を可視化するためにはplot()関数を使う。タイトル、横軸、縦軸のラベルはmain、xlab、ylabで指定できる。\n\nplot(scm_fit, \n     main = \"Estimated ATT\", \n     xlab = \"Election (0 = 2013 Election)\", \n     ylab = \"ATT (%p)\")\n\n\n\n\n\n\n\n\n　処置を受ける前は架空の4県とその実際の4県の間に投票率の差はあまりなかったが、処置を受けてから差が広がることが分かる。差分でなく、合成された架空の4県と実際の4県のトレンドを見るためにはtype = \"counterfactual\"、もしくはtype = \"ct\"を指定します。\n\nplot(scm_fit, \n     type = \"counterfactual\", \n     main = \"\",\n     xlab = \"Election\", \n     ylab = \"Turnout (%)\")\n\n\n\n\n\n\n\n\n　処置を受けたのは4県であるが、線が1本になっている。ここからも処置前は架空の4県と実際の4県はほぼ同じトレンドを示していますが、処置後は傾向が変わったことが確認できる。\n　もし、4つの都道府県を個別に示したい場合はどうすれば良いだろうか。この場合、plot()内にid引数を使えば良い。たとえば、鳥取県の処置効果（ATT）を確認するためにはid = \"Tottori\"と指定する。\n\nplot(scm_fit, id = \"Tottori\")\n\n\n\n\n\n\n\n\n\nplot(scm_fit, id = \"Tottori\", type = \"ct\")\n\n\n\n\n\n\n\n\n　4つの都道府県のデータを個別のファセットで全て出すためにはゼロベースで作図した方が効率的かも知れない。また、この場合は図のカスタマイズの幅も広がる。{gsynth}から得られたオブジェクトには架空の鳥取、島根、徳島、高知のデータが個別に格納されているため、それを抽出すれば個別の図を作成することもできる。たとえば、処置群（4県）の観察済みのデータはオブジェクト名$Y.trで抽出できる。\n\nscm_fit$Y.tr\n\n      Kochi  Shimane Tokushima  Tottori\n7  74.63966 83.49050  69.39499 81.24437\n8  75.69312 84.78405  69.88441 83.69962\n9  71.37616 78.14244  63.66989 77.03502\n10 75.69410 86.92480  78.45754 84.82852\n11 70.90031 85.15588  63.40844 83.37384\n12 72.83410 87.58638  77.05070 84.86225\n13 61.27247 75.36695  49.81165 74.79201\n14 72.01185 86.89197  70.26960 85.81677\n15 70.52034 82.31831  65.59127 78.71451\n16 54.89730 73.79272  48.42299 67.28538\n17 50.63857 67.09330  47.14380 67.57092\n18 56.21296 73.26601  56.91326 70.03591\n19 58.38653 68.61257  57.24322 66.68463\n20 57.29701 68.87462  54.59808 64.16773\n21 58.39998 71.80893  58.46591 67.67363\n22 58.49266 71.70006  58.23675 65.76520\n23 49.88987 60.89257  49.29437 58.87696\n24 45.51522 62.19714  46.97798 56.28266\n25 46.34053 54.04000  38.59305 49.97934\n26 47.36311 56.37101  45.72428 48.92585\n\n\n　このデータは行列構造となっているため、as_tibble()で表形式へ変更し、treat_dfという名で格納する。\n\ntreat_df &lt;- as_tibble(scm_fit$Y.tr)\n\ntreat_df\n\n# A tibble: 20 × 4\n   Kochi Shimane Tokushima Tottori\n   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1  74.6    83.5      69.4    81.2\n 2  75.7    84.8      69.9    83.7\n 3  71.4    78.1      63.7    77.0\n 4  75.7    86.9      78.5    84.8\n 5  70.9    85.2      63.4    83.4\n 6  72.8    87.6      77.1    84.9\n 7  61.3    75.4      49.8    74.8\n 8  72.0    86.9      70.3    85.8\n 9  70.5    82.3      65.6    78.7\n10  54.9    73.8      48.4    67.3\n11  50.6    67.1      47.1    67.6\n12  56.2    73.3      56.9    70.0\n13  58.4    68.6      57.2    66.7\n14  57.3    68.9      54.6    64.2\n15  58.4    71.8      58.5    67.7\n16  58.5    71.7      58.2    65.8\n17  49.9    60.9      49.3    58.9\n18  45.5    62.2      47.0    56.3\n19  46.3    54.0      38.6    50.0\n20  47.4    56.4      45.7    48.9\n\n\n　このtreat_dfだけは各投票率がいつの投票率かが分からない。Election列をKochi列前に追加し（mutate()内の最後に.before = Kochiを指定すると、mutate()で生成・修正された列がKochi列の前へ移動する）、7から26までを入れる。\n\ntreat_df &lt;- treat_df |&gt;\n  mutate(Election = 7:26, .before = Kochi)\n\ntreat_df\n\n# A tibble: 20 × 5\n   Election Kochi Shimane Tokushima Tottori\n      &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n 1        7  74.6    83.5      69.4    81.2\n 2        8  75.7    84.8      69.9    83.7\n 3        9  71.4    78.1      63.7    77.0\n 4       10  75.7    86.9      78.5    84.8\n 5       11  70.9    85.2      63.4    83.4\n 6       12  72.8    87.6      77.1    84.9\n 7       13  61.3    75.4      49.8    74.8\n 8       14  72.0    86.9      70.3    85.8\n 9       15  70.5    82.3      65.6    78.7\n10       16  54.9    73.8      48.4    67.3\n11       17  50.6    67.1      47.1    67.6\n12       18  56.2    73.3      56.9    70.0\n13       19  58.4    68.6      57.2    66.7\n14       20  57.3    68.9      54.6    64.2\n15       21  58.4    71.8      58.5    67.7\n16       22  58.5    71.7      58.2    65.8\n17       23  49.9    60.9      49.3    58.9\n18       24  45.5    62.2      47.0    56.3\n19       25  46.3    54.0      38.6    50.0\n20       26  47.4    56.4      45.7    48.9\n\n\n　続いて、{tidyr}のpivot_longer()関数を使ってtreat_dfをlong型データへ変換する。pivot_*()関数の使い方については『私たちのR』第15章「整然データ構造」を参照されたい。\n\ntreat_df &lt;- treat_df |&gt;\n  pivot_longer(cols      = Kochi:Tottori,\n               names_to  = \"Pref\",\n               values_to = \"Turnout\")\n\ntreat_df\n\n# A tibble: 80 × 3\n   Election Pref      Turnout\n      &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1        7 Kochi        74.6\n 2        7 Shimane      83.5\n 3        7 Tokushima    69.4\n 4        7 Tottori      81.2\n 5        8 Kochi        75.7\n 6        8 Shimane      84.8\n 7        8 Tokushima    69.9\n 8        8 Tottori      83.7\n 9        9 Kochi        71.4\n10        9 Shimane      78.1\n# ℹ 70 more rows\n\n\n　同じ作業を架空の処置群についても行う。架空の処置群はオブジェクト名$Y.ctで抽出できる。今回は全ての作業をパイプ演算子で繋ぎ、コードを効率化する。\n\ncounter_df &lt;- scm_fit$Y.ct |&gt;\n  as_tibble() |&gt;\n  mutate(Election = 7:26, .before = Kochi) |&gt;\n  pivot_longer(cols      = Kochi:Tottori,\n               names_to  = \"Pref\",\n               values_to = \"Turnout\")\n\ncounter_df\n\n# A tibble: 80 × 3\n   Election Pref      Turnout\n      &lt;int&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1        7 Kochi        73.5\n 2        7 Shimane      84.0\n 3        7 Tokushima    67.6\n 4        7 Tottori      83.3\n 5        8 Kochi        75.3\n 6        8 Shimane      85.7\n 7        8 Tokushima    70.7\n 8        8 Tottori      84.7\n 9        9 Kochi        65.6\n10        9 Shimane      76.1\n# ℹ 70 more rows\n\n\n　最後にtreat_dfとcounter_dfを結合する。treat_dfの行なら\"観測値\"の値が、counter_dfの行なら\"反実仮想\"の値が付けられたTypeという列を追加し、このType列をfactor化する。要素の順番は\"反実仮想\"、\"観測値\"の順とする。\n\ntr_ct_df &lt;- bind_rows(list(\"観測値\"   = treat_df, \n                           \"反実仮想\" = counter_df),\n                      .id = \"Type\") |&gt;\n  mutate(Type = factor(Type, levels = c(\"反実仮想\", \"観測値\")))\n\n　データが揃ったので{ggplot2}を使って折れ線グラフを作ってみよう。\n\ntr_ct_df |&gt;\n  # Pref列をリコーディング & factor化\n  mutate(Pref = recode(Pref,\n                       \"Tottori\"   = \"鳥取\",\n                       \"Shimane\"   = \"島根\",\n                       \"Tokushima\" = \"徳島\",\n                       \"Kochi\"     = \"高知\"),\n         Pref = factor(Pref, levels = c(\"鳥取\", \"島根\", \"徳島\", \"高知\"))) |&gt;\n  ggplot() +\n  # x = 23の箇所に垂直線の破線を引く\n  geom_vline(xintercept = 23, linetype = 2) +\n  geom_line(aes(x = Election, y = Turnout, linetype = Type, color = Type),\n            size = 1) +\n  # 線の色\n  scale_color_manual(values = c(\"観測値\"   = \"black\", \n                                \"反実仮想\" = \"orange\")) +\n  # 線のタイプ（1 = 実線; 2 = 破線）\n  scale_linetype_manual(values = c(\"観測値\"   = 1, \n                                   \"反実仮想\" = 2)) +\n  # colorの凡例は残し、linetypeの凡例は無くす\n  guides(linetype = \"none\") +\n  labs(x = \"選挙\", y = \"投票率 (%)\", color = \"\") +\n  # 都道府県ごとにファセット分割\n  facet_wrap(~Pref, ncol = 2) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　ただし、この図だけだと処置効果（ATT）が分かりにくい。処置効果は観測値（=処置群）と反実仮想（=架空の統制群）の差分である。tr_ct_dfからもATTの計算はできるが、ATTの不確実性（標準誤差や信頼区間など）までは分からない。処置効果（ATT）を抽出はオブジェクト名$est.indで出来るが、3次元配列（array構造）になっているため、オブジェクト名$est.ind[, , \"処置群名\"]で抽出する必要がある。処置群名は今回の場合だとPrefName_E上の名前である。たとえば、鳥取における処置効果は以下のように抽出する。これらもまた表形式でなく、行列構造であるので、as_tibble()を使って表形式にしよう。\n\nas_tibble(scm_fit$est.ind[, , \"Tottori\"])\n\n# A tibble: 20 × 5\n        Eff  S.E. CI.lower CI.upper p.value\n      &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1  -2.03    2.49   -6.92     2.85  0.415  \n 2  -0.960   2.48   -5.83     3.91  0.699  \n 3   1.69    2.03   -2.30     5.67  0.407  \n 4   1.07    2.06   -2.97     5.11  0.605  \n 5   0.721   2.27   -3.72     5.16  0.750  \n 6  -0.704   1.77   -4.17     2.76  0.690  \n 7  -0.926   2.16   -5.17     3.31  0.668  \n 8   0.816   2.07   -3.25     4.88  0.694  \n 9   0.247   2.11   -3.88     4.38  0.907  \n10  -3.24    2.09   -7.34     0.862 0.122  \n11   5.88    2.91    0.184   11.6   0.0430 \n12   0.143   2.23   -4.22     4.51  0.949  \n13   0.0189  1.81   -3.53     3.57  0.992  \n14  -1.48    1.82   -5.06     2.09  0.416  \n15  -0.0566  1.78   -3.54     3.43  0.975  \n16   0.456   1.83   -3.12     4.04  0.803  \n17  -1.63    1.77   -5.11     1.84  0.357  \n18  -6.90    2.76  -12.3     -1.49  0.0124 \n19  -9.00    4.09  -17.0     -0.976 0.0279 \n20 -10.9     3.54  -17.8     -3.94  0.00211\n\n\n　ここでEff列が架空の鳥取と実際の鳥取の差、つまり処置効果である。そして、CI.lowerとCI.upperがそれぞれ95%信頼区間の下限と上限だ。これら4つの県のデータを結合し、Election変数を追加、都道府県をfactor化したものをatt_dfという名で格納する。\n\natt_df &lt;- bind_rows(list(\"鳥取\" = as_tibble(scm_fit$est.ind[, , \"Tottori\"]),\n                         \"島根\" = as_tibble(scm_fit$est.ind[, , \"Shimane\"]),\n                         \"徳島\" = as_tibble(scm_fit$est.ind[, , \"Tokushima\"]),\n                         \"高知\" = as_tibble(scm_fit$est.ind[, , \"Kochi\"])),\n                    .id = \"Pref\") |&gt;\n  mutate(Election = rep(7:26, 4), # 7~26を4回繰り返し\n         .before = Pref) |&gt;       # Election列をPref列の前に\n  mutate(Pref = fct_inorder(Pref))\n\natt_df\n\n# A tibble: 80 × 7\n   Election Pref     Eff  S.E. CI.lower CI.upper p.value\n      &lt;int&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1        7 鳥取  -2.03   2.49    -6.92    2.85    0.415\n 2        8 鳥取  -0.960  2.48    -5.83    3.91    0.699\n 3        9 鳥取   1.69   2.03    -2.30    5.67    0.407\n 4       10 鳥取   1.07   2.06    -2.97    5.11    0.605\n 5       11 鳥取   0.721  2.27    -3.72    5.16    0.750\n 6       12 鳥取  -0.704  1.77    -4.17    2.76    0.690\n 7       13 鳥取  -0.926  2.16    -5.17    3.31    0.668\n 8       14 鳥取   0.816  2.07    -3.25    4.88    0.694\n 9       15 鳥取   0.247  2.11    -3.88    4.38    0.907\n10       16 鳥取  -3.24   2.09    -7.34    0.862   0.122\n# ℹ 70 more rows\n\n\n　それでは折れ線グラフを作ってみよう。ただし、今回は点推定値（折れ線グラフ）だけでなく、信頼区間も示す必要があるのでgeom_ribbon()レイヤーを追加する。\n\natt_df |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0, linetype = 2) +\n  geom_vline(xintercept = 23, linetype = 2) +\n  # 信頼区間\n  geom_ribbon(aes(x = Election, ymin = CI.lower, ymax = CI.upper),\n              alpha = 0.25) +\n  geom_line(aes(x = Election, y = Eff)) +\n  # 以下のgeom_point()なあってもなくても良い\n  geom_point(aes(x = Election, y = Eff), \n             size = 3, shape = 21, fill = \"black\", color = \"white\") +\n  labs(x = \"Election\", y = \"Gap (%p)\") +\n  facet_wrap(~Pref, ncol = 2) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　個別に見ると、合区直後、合区によって投票率を下がったのは鳥取、徳島、高知である。しかし、合区から3回目の選挙となる2022年（第26回）では鳥取のみとなる。\n　SCMは統制群から合成された架空の鳥取、島根、徳島、高知を作成し、こちらを実際の統制群として用いる手法である。その際に43都道府県を重み付け合成されるが、それぞれの重みはいくつだろうか。gsynth()から得られたオブジェクトからwgt.impliedを抽出すればその重みが分かる。通常のSCMの場合、重みは正の値であるが、一般化SCMの場合は負も正もあり得る。\n\nscm_fit$wgt.implied\n\n\n\n\n\n\n\n\n\n\nKochi\nShimane\nTokushima\nTottori\n\n\n\n\nAichi\n0.022\n−2.169\n−2.755\n0.448\n\n\nAkita\n−0.151\n−0.161\n−0.798\n0.170\n\n\nAomori\n−0.069\n−1.188\n−1.613\n0.225\n\n\nChiba\n0.309\n−2.096\n−1.885\n0.327\n\n\nEhime\n0.238\n0.471\n0.851\n−0.009\n\n\nFukui\n−0.630\n4.081\n4.711\n−1.122\n\n\nFukuoka\n−0.541\n0.634\n0.342\n−0.368\n\n\nFukushima\n0.947\n−0.235\n0.669\n0.402\n\n\nGifu\n0.354\n0.149\n0.566\n0.097\n\n\nGunma\n0.318\n2.085\n2.968\n−0.291\n\n\nHiroshima\n−0.254\n1.622\n2.146\n−0.570\n\n\nHokkaido\n−0.553\n−3.254\n−5.161\n0.643\n\n\nHyogo\n0.117\n−3.045\n−3.918\n0.723\n\n\nIbaraki\n0.378\n−0.483\n0.902\n−0.263\n\n\nIshikawa\n−0.480\n1.476\n1.294\n−0.432\n\n\nIwate\n0.006\n−2.615\n−4.020\n0.833\n\n\nKagawa\n−0.391\n3.227\n3.960\n−0.902\n\n\nKagoshima\n0.098\n0.202\n−0.102\n0.200\n\n\nKanagawa\n0.506\n−3.426\n−3.741\n0.828\n\n\nKumamoto\n−0.791\n1.767\n1.083\n−0.490\n\n\nKyoto\n0.397\n−4.141\n−5.373\n1.200\n\n\nMie\n0.016\n−1.162\n−1.447\n0.231\n\n\nMiyagi\n0.712\n−0.122\n1.072\n0.070\n\n\nMiyazaki\n−1.071\n5.630\n6.465\n−1.699\n\n\nNagano\n0.498\n−1.419\n−1.244\n0.446\n\n\nNagasaki\n−0.921\n1.910\n1.572\n−0.763\n\n\nNara\n0.378\n−2.473\n−2.658\n0.589\n\n\nNigata\n0.856\n−2.080\n−1.318\n0.535\n\n\nOita\n−0.593\n2.253\n1.749\n−0.444\n\n\nOkayama\n−0.264\n0.966\n1.560\n−0.557\n\n\nOkinawa\n0.958\n0.416\n0.697\n0.637\n\n\nOsaka\n0.387\n−3.404\n−4.601\n1.118\n\n\nSaga\n−0.913\n4.668\n5.637\n−1.552\n\n\nSaitama\n0.217\n−0.975\n−0.328\n−0.031\n\n\nShiga\n−0.012\n−0.073\n−0.613\n0.235\n\n\nShizuoka\n0.599\n0.961\n2.654\n−0.330\n\n\nTochigi\n0.409\n0.338\n1.366\n−0.143\n\n\nTokyo\n0.619\n−4.424\n−5.420\n1.301\n\n\nToyama\n−0.819\n4.384\n5.389\n−1.467\n\n\nWakayama\n−0.050\n−1.103\n−1.730\n0.323\n\n\nYamagata\n0.652\n−1.077\n−0.815\n0.508\n\n\nYamaguchi\n−1.048\n1.821\n0.402\n−0.382\n\n\nYamanashi\n−0.444\n2.064\n1.486\n−0.274",
    "crumbs": [
      "差分の差分法"
    ]
  },
  {
    "objectID": "material/did.html#footnotes",
    "href": "material/did.html#footnotes",
    "title": "差分の差分法",
    "section": "脚注",
    "text": "脚注\n\n\nfixed_effects引数でなく、回帰式に説明変数として指定しても結果は同じである。しかし、回帰式に書く場合、固定効果の推定値も全て出力され、推定結果が非常に長くなる。しかし、固定効果の推定値は論文内で報告することもない。fixed_effectsで指定すると、それらの結果は省略される。↩︎\n{gsynth}は通常のSCMでなく、一般化SCM（Generalized Synthetic Control Method）を実装したパッケージである。通常のSCMは処置群は1つのみに使えるが、一般化SCMは処置群が複数あっても使える。一般化SCMについてはYiqing Xu. 2017. “Generalized Synthetic Control Method: Causal Inference with Interactive Fixed Effects Models,” Political Analysis, 25 (1): 57-76.を参照されたい。↩︎\n第7〜23回参院選のデータは参議院議員通常選挙データベースからダウンロードしたものを架空したものであり、第24〜26回データは宋が手入力したものである。↩︎",
    "crumbs": [
      "差分の差分法"
    ]
  },
  {
    "objectID": "syllabus/dataset.html",
    "href": "syllabus/dataset.html",
    "title": "データセットについて",
    "section": "",
    "text": "講義で使用する全てのデータセットはDiscordにて配布します。Discordサーバーへのアクセス方法は1日目の講義にて解説します。",
    "crumbs": [
      "データセットについて"
    ]
  },
  {
    "objectID": "intro/project.html",
    "href": "intro/project.html",
    "title": "プロジェクト管理",
    "section": "",
    "text": "なぜプロジェクト機能を使う必要があるのか\n\n\n\n　「なぜプロジェクト機能を使うのか」を知るためにはファイルシステムに関する理解が必要だ。もし、「ファイルシステム」という単語や「絶対パス」、「相対パス」という単語を聞いたことのない人はファイル・システムも予め読んでおこう。",
    "crumbs": [
      "プロジェクト管理"
    ]
  },
  {
    "objectID": "intro/project.html#プロジェクトの作成",
    "href": "intro/project.html#プロジェクトの作成",
    "title": "プロジェクト管理",
    "section": "プロジェクトの作成",
    "text": "プロジェクトの作成\n手順1: File &gt; New Project…をクリックする。\n\n\n\n\n\n手順2: New Directoryをクリックする。\n\n\n\n\n\n手順3: New Projectをクリックする。\n\n\n\n\n\n手順4: Directory name:にプロジェクト名を入力し、Create Projectをクリックする。\n\n\n\n\n\n\n\n\n\n\n\n注意: プロジェクト名の付け方\n\n\n\n　プロジェクト名にはローマ字、数字のみを使おう。つまり、日本語、中国語、韓国語、全角文字、スペースはなるべく使わないこと。空白を入れたい場合はスペースの代わりにアンダースコア（_）を使おう。",
    "crumbs": [
      "プロジェクト管理"
    ]
  },
  {
    "objectID": "intro/project.html#プロジェクトの開き方",
    "href": "intro/project.html#プロジェクトの開き方",
    "title": "プロジェクト管理",
    "section": "プロジェクトの開き方",
    "text": "プロジェクトの開き方\n　プロジェクトを作成すれば、自動的に出来たてのプロジェクトが開かれる。しかし、JDCat分析ツールから一旦ログアウトし、改めてRStudioを起動する場合、プロジェクトをロードする必要がある。\n手順1: File &gt; Open Project…をクリックする。\n\n\n\n\n\n手順2: プロジェクト・フォルダー名をダブルクリックする。\n\n\n\n\n\n手順3: .Rprojで終わるファイルをダブルクリックする。\n\n\n\n\n\nプロジェクトが正しくロードされている場合、RStudioの右上にプロジェクト名が表示される。\n\n\n\n\n\n\n\n\n\n\n\n常にプロジェクト機能を使おう!\n\n\n\n　RStudionの右上のプロジェクト名表示が「Project: (None)」になっていることは、現在プロジェクトを開いていないことを意味する。簡単な計算機として使う目的以外（つまり、授業中の実習や課題）は必ずプロジェクト機能を使おう。",
    "crumbs": [
      "プロジェクト管理"
    ]
  },
  {
    "objectID": "intro/install.html",
    "href": "intro/install.html",
    "title": "Rの導入",
    "section": "",
    "text": "自分のPCにRおよびRStudioがインストールされていない場合、『私たちのR』の内容に従って、RとRStudioをインストールしてください。インストール不要のクラウド版もあり、こちらを推奨しております。\n\nRのインストール\n\n本講義ではインストール不要のクラウド版（JDCat分析ツール）の使用を推奨します。自分のPCにRとRStudioがインストールされている場合でも全員が同じ環境で学習できるJDCat分析ツールを使ってください。R経験者であれば、自分のPCのものを使っても構いません。\n第2章：Rのインストール\n\nクラウド版（JDCat分析ツール）の使い方は上記ページの後半にあります。\n\n\nRStudioのインストール\n\n自分のPCにインストールする場合のみ。クラウド版（JDCat分析ツール）を使用する場合、この作業は不要です。\n第3章：IDEの導入\n\nRStudioの設定\n\n第4章：分析環境のカスタマイズ",
    "crumbs": [
      "Rの導入"
    ]
  },
  {
    "objectID": "intro/filesystem.html",
    "href": "intro/filesystem.html",
    "title": "ファイル・システム",
    "section": "",
    "text": "PC内に存在するほとんどのファイルは「名前.拡張子」と名付けられている1。名前の拡張子は.で区切られており、名前は英数字と_のみで構成することを推奨する（ファイル名に.が推奨されない理由の一つが名前と拡張子を区分する文字として使われるからだ）。ここで注目したいのはファイルの名前でなく、拡張子のことだ。拡張子とはファイルの特徴を示すものである。たとえば、拡張子が.htmlであれば、ウェブページ形式を意味し、.pngなら図、.pdfなら図・文書、.exeなら実行ファイル、.dmgならディスクイメージを意味する。ファイル名がFigure01.pngならFigure01という名の画像ファイルであることを意味する2。この拡張子によって、パソコンは当該ファイルをどのアプリケーションで開くかを判定する。.exeファイルをダブルクリックするとアプリケーションが立ち上がるし、.pdfファイルをダブルクリックするとPDFビュアーソフトが起動され、中身が表示される。\n　これは拡張子を変えると問題が生じ得ることを意味する。画像ファイルであるFigure01.pngのファイル名を動画ファイル拡張子であるMovie01.mp4に修正しても、そのファイルは動画ファイルにはならない。また、拡張子が.mp4になると、そのファイルを開く際、動画プレイヤーが起動されるが、ファイルの中身は画像ファイルのままなのでエラーが出る。したがって、拡張子は勝手に変えてはならない。たまに課題の結果物としてファイルを提出する際、自分の名前を入れたくてファイル名をXXXX.htmlからXXXX.html_Songへ変更して提出する場合がある。しかし、これは大きな間違いだ。もやはこのファイルはHTMLファイル（.html）でなく、未知のファイル形式（.html_Song）として認識され、ダブルクリックしてもPCはどのアプリケーションで開けば良いかが分からなくなる。ファイル名を修正するならXXXX_Song.htmlのように修正しよう3。\n　Rを用いたデータ分析の場面において頻繁に登場する拡張子は以下の通りである。ファイルの名前は大文字と小文字を区別するが、拡張子の場合、区別されないケースが多い。\n\n\n\n\n\n\n\n\n拡張子\n説明\n備考\n\n\n\n\n.R\nRスクリプトファイル\n\n\n\n.Rproj\nRプロジェクトファイル\n\n\n\n.Rmd\nR Markdownファイル\n\n\n\n.qmd\nQuartoファイル\nRMarkdownに似たようなもの\n\n\n.csv\n表形式ファイル\n業界標準のフォーマット\n\n\n.xlsx or .xls\n表形式ファイル\nExcelで使うフォーマット\n\n\n.dta\n表形式ファイル\nStataで使うフォーマット\n\n\n.sav\n表形式ファイル\nSPSSで使うフォーマット\n\n\n.html\nウェブページファイル\nR Markdown/QuartoをKnitした場合に得られる\n\n\n.png\n画像ファイル\n\n\n\n.pdf\n画像/文書ファイル\n画像にも文書にもなるファイル",
    "crumbs": [
      "ファイル・システム"
    ]
  },
  {
    "objectID": "intro/filesystem.html#拡張子",
    "href": "intro/filesystem.html#拡張子",
    "title": "ファイル・システム",
    "section": "",
    "text": "PC内に存在するほとんどのファイルは「名前.拡張子」と名付けられている1。名前の拡張子は.で区切られており、名前は英数字と_のみで構成することを推奨する（ファイル名に.が推奨されない理由の一つが名前と拡張子を区分する文字として使われるからだ）。ここで注目したいのはファイルの名前でなく、拡張子のことだ。拡張子とはファイルの特徴を示すものである。たとえば、拡張子が.htmlであれば、ウェブページ形式を意味し、.pngなら図、.pdfなら図・文書、.exeなら実行ファイル、.dmgならディスクイメージを意味する。ファイル名がFigure01.pngならFigure01という名の画像ファイルであることを意味する2。この拡張子によって、パソコンは当該ファイルをどのアプリケーションで開くかを判定する。.exeファイルをダブルクリックするとアプリケーションが立ち上がるし、.pdfファイルをダブルクリックするとPDFビュアーソフトが起動され、中身が表示される。\n　これは拡張子を変えると問題が生じ得ることを意味する。画像ファイルであるFigure01.pngのファイル名を動画ファイル拡張子であるMovie01.mp4に修正しても、そのファイルは動画ファイルにはならない。また、拡張子が.mp4になると、そのファイルを開く際、動画プレイヤーが起動されるが、ファイルの中身は画像ファイルのままなのでエラーが出る。したがって、拡張子は勝手に変えてはならない。たまに課題の結果物としてファイルを提出する際、自分の名前を入れたくてファイル名をXXXX.htmlからXXXX.html_Songへ変更して提出する場合がある。しかし、これは大きな間違いだ。もやはこのファイルはHTMLファイル（.html）でなく、未知のファイル形式（.html_Song）として認識され、ダブルクリックしてもPCはどのアプリケーションで開けば良いかが分からなくなる。ファイル名を修正するならXXXX_Song.htmlのように修正しよう3。\n　Rを用いたデータ分析の場面において頻繁に登場する拡張子は以下の通りである。ファイルの名前は大文字と小文字を区別するが、拡張子の場合、区別されないケースが多い。\n\n\n\n\n\n\n\n\n拡張子\n説明\n備考\n\n\n\n\n.R\nRスクリプトファイル\n\n\n\n.Rproj\nRプロジェクトファイル\n\n\n\n.Rmd\nR Markdownファイル\n\n\n\n.qmd\nQuartoファイル\nRMarkdownに似たようなもの\n\n\n.csv\n表形式ファイル\n業界標準のフォーマット\n\n\n.xlsx or .xls\n表形式ファイル\nExcelで使うフォーマット\n\n\n.dta\n表形式ファイル\nStataで使うフォーマット\n\n\n.sav\n表形式ファイル\nSPSSで使うフォーマット\n\n\n.html\nウェブページファイル\nR Markdown/QuartoをKnitした場合に得られる\n\n\n.png\n画像ファイル\n\n\n\n.pdf\n画像/文書ファイル\n画像にも文書にもなるファイル",
    "crumbs": [
      "ファイル・システム"
    ]
  },
  {
    "objectID": "intro/filesystem.html#ファイルシステム",
    "href": "intro/filesystem.html#ファイルシステム",
    "title": "ファイル・システム",
    "section": "2 ファイルシステム",
    "text": "2 ファイルシステム\n　R上でファイルを入出力を行うためにはファイルシステム（file system）を理解する必要がある。\n\n2.1 ファイルの入出力\n　そもそも、ファイルの「入出力」とは何だろうか。これはコンピューターの構造に関わる話なので極めて難しい内容であるが、我々のような消費者（end user）側から見れば、ファイルの入力（input）とは、いわゆるファイルの読み込みを意味し、多くの場合、表形式のデータ（.csv、.xlsxなど）をR上に読み込む作業を意味する。また、ファイルの出力（output）とは、いわゆるファイルの保存だ。たとえば、作成したスクリプトを.R形式で保存したり、加工済みのデータを.csv形式で保存したり、作成した図を.png、.pdf形式で保存したり、作成した文書を.pdf、.html形式で保存したりすることがファイルの出力だ。\n\n\n2.2 パスとは\n　ファイルを読み込む場合はファイル名を指定する必要がある。また、ファイルを書き出す場合もファイルに名付ける必要がある。そしてファイル名は名前.拡張子である。ただし、これらのファイルは全て一箇所に集まっているわけではない。もし、全てのファイルが一箇所に集まっていると、必要なファイルを探すのは非常に難しい。通常、PC内には数万のファイルがある。これらのファイルから必要なファイルを探すのは至難の業だろう。したがって、これらのファイルをいくつかの部屋に分けて保管し、この部屋のことをフォルダー（folder）、またはディレクトリ（directory）と呼ぶ（ここでは「フォルダー」と呼ぶとする）。パス（path）とは特定のファイルの位置と名前の書き方である。つまり、「どこのどのファイルを読み込むか」、「このファイルをどの名前でどこに保存するか」に関する書き方であり、プログラミングを学習する上で必須の知識と言っても過言ではない。\n　このパスという概念は我々が住んでいる居住地の「住所」と類似した概念だ。もし、日本に「都道府県」も「市区町村」も「〜丁目、〜番、〜号」という概念がないとしよう。ここでAmazonで魚を購入し、受取先を指定する場合はどうすれば良いだろうか。日本に人が数十人しか住んでいないのであれば、「XXXさんの家」と書くだけで十分かも知れない。しかし、日本には1億人以上の人がある。「ソンさんの家」と書いても届かないだろう。届いたとしても数年、あるいは数十年後に魚の化石の状態で届くかも知れない。そもそも日本に「ソンさん」はこの授業の担当教員以外にもいくらでもいる（ちなみに송（Song; 宋・松）さんも、손（Sohn; 孫）さんも、성（Seong/Sung; 成・星）さんも、선（Sun/Seon; 宣）さんも韓国語では発音が全く別だが、日本ではソンさんになってしまう。）。それぞれの家を何かの区域内に位置づけないとモノが届くまで数年かかってしまう。そこで必要なのが住所だ。「東京都千代田区永田町1丁目7番1号の田中さん」は「東京都」、「千代田区」、「永田町」、「1丁目」、「7番」、「1号」、「田中さん」で構成される。これをファイルシステムに例えると、東京都というフォルダーの中に千代田区というフォルダーがあり、その中には永田町というフォルダー、その中に1丁目といるファルダー、…が存在する。むろん、一つのフォルダーには複数のフォルダーが存在する可能性もある。東京都のフォルダーには千代田区以外にも大田区、中野区、文京区、葛飾区といった複数のフォルダーがあり、千代田区の中にも複数のフォルダーがある。最後の「田中さん」は受け取る人、コンピューターでいうファイル名である。\n　この住所と受取人のことをコンピューターではパス（path）と呼ぶ。それぞれのフォルダーは/で区切られる（macOS/Linuxでは/、Windowsでは\\または￥; JDCat分析ツールはLinuxベースであるため、/で区切られる）。先ほどの住所の例だと、東京都/千代田区/永田町/1丁目/7番/1号/田中さんとなる（macOS/Linuxの場合）。左に行くほど上位のフォルダーとなり、最後のものはファイル名である。ただし、コンピュターではパスの最初に/を付ける。Windowsなら主にC:\\でスタートし、C:\\東京都\\千代田区\\永田町\\1丁目\\7番\\1号\\田中さんとなる（\\の代わりに￥と表示される場合もある）。\n　たとえば、以下のような構造でファイルが保存されているとしよう。拡張子が付いているものはファイル、それ以外はフォルダー、1行目の.は最上位フォルダーである。\n\n\n                      levelName\n1  .                           \n2   ¦--Day01                   \n3   ¦   ¦--Day01.Rproj         \n4   ¦   ¦--Script01.R          \n5   ¦   ¦--Script02.R          \n6   ¦   ¦--Data                \n7   ¦   ¦   ¦--raw_data.csv    \n8   ¦   ¦   °--cleaned_data.csv\n9   ¦   °--Figs                \n10  ¦       ¦--Figure01.png    \n11  ¦       °--Figure02.png    \n12  °--Day02                   \n13      ¦--Day02.Rproj         \n14      ¦--Script01.R          \n15      ¦--Document01.qmd      \n16      ¦--Document01.html     \n17      ¦--Data                \n18      ¦   °--my_data.csv     \n19      °--Figs                \n20          ¦--Old             \n21          ¦   ¦--Figure01.pdf\n22          ¦   ¦--Figure02.pdf\n23          ¦   °--Figure03.pdf\n24          °--New             \n25              °--Figure01.png\n\n\n　ここでread_csv()関数を使ってDay01フォルダー内のDataフォルダー内のraw_data.csvを読み込む場合はread_csv(\"/Day01/Data/raw_data.csv\")となる。また、ggsave()を用いて、Day02内のFigs内のNew内にFigure02.pngという名で図を保存する場合は、ggsave(filename = \"/Day02/Figs/New/Figure02.png\", ...)と入力する必要がある。しかし、通常、パスを指定する際に、/（WindownならC:\\）から始めることは滅多にない。それは「作業フォルダーはパスで省略可能」だからだ。",
    "crumbs": [
      "ファイル・システム"
    ]
  },
  {
    "objectID": "intro/filesystem.html#rstudioのプロジェクト機能",
    "href": "intro/filesystem.html#rstudioのプロジェクト機能",
    "title": "ファイル・システム",
    "section": "3 RStudioのプロジェクト機能",
    "text": "3 RStudioのプロジェクト機能\n　Rでファイルを入出力する時に頭に入れておくべき概念として「作業フォルダー（working folder/working directory）」がある。通常、Rの作業フォルダーはmacOSだと/Users/ユーザー名/、JDCat分析ツールだと/home/joyvan/が作業フォルダーだ。そして、パスを指定する場合、作業フォルダーは省略することができる。つまり、現在の作業フォルダーが/home/joyvan/なら\"/home/joyvan/Day01/Data/raw_data.csv\"は\"Day01/Data/raw_data.csv\"に、\"/home/joyvan/Day02/Figs/New/Figure02.png\"は\"Day02/Figs/New/Figure02.png\"に省略される。我々が郵便局で手紙を送る際、住所にわざわざ「日本国」と書かないものと同じである。作業フォルダーはRコンソール上でgetwd()と入力すれば出力される。macOSなら/Users/ユーザー名、JDCat分析ツールなら/home/joyvanと出力される。\n\n\n\n\n\n\n最上位フォルダーの話\n\n\n\n　macOSとLinuxに限定した話であるが、最上位フォルダーは/であり、これはシステム上の最上位フォルダーである。個人レベルの最上位フォルダーはmacOSだと/Users/ユーザー名、JDCat分析ツールだと/home/joyvanである。そして、この個人レベルの最上位フォルダーは~/と表記することができる。Rコンソールでgetwd()を入力し、以上のように出力されれば個人レベルの最上位フォルダー（~/）が作業フォルダーになっている理解しても良い。ちなみに、WindowsはC:\\がシステム上の最上位フォルダーである。\n\n\n　もし、自分がこれから全ての作業をDay03という名のフォルダー内で完結するとする。つまり、保存するスクリプト（たとえば、Script.R）もDay03に保存し、図（たとえば、FigureA.png）はDay03のFigsフォルダーに、読み込む表形式データ（たとえば、Day03_Data.csv）もDay03の中のDataフォルダーに入れるとする。この場合、それぞれのファイルのパスはDay03/Script.R、Day03/Figs/FigureA.png、Day03/Data/Day03_Data.csvとなる（作業フォルダーが~/であるため、~/は省略可能）。全ての作業が同じフォルダー（とその下位フォルダー）内で行うとしたら、パス名にDay03も不要な気がする。そこで必要なのがRStudioのプロジェクト機能である。\n　RStudioでDay03というプロジェクトを作成すると、Day03フォルダーが自動的に生成され、Day03.Rprojというファイルも生成される。プロジェクトを最上位フォルダーに作成したのであれば、~/Day03/Day03.Rprojファイルが生成されるのである。ここでRStudioのFile &gt; Open ProjectでこのDay03.Rprojファイルを開くとRStudio画面の右上にプロジェクト名が表示され、作業フォルダーがDay03.Rprojが保存されているフォルダー、つまり~/Day03へ変更される（プロジェクトが開かれていな場合は「Project: (None)」と表示される）。実際、JDCat分析ツールでXXXという名前のプロジェクトを生成し、そのプロジェクトを開けば作業フォルダーは/home/joyvan/XXX/（=~/XXX/）になる（getwd()で確認可能）。これは大変便利な機能である。なぜなら作業フォルダーまでのパスは全て省略可能だからだ。これまでDay03/Script.R、Day03/Figs/FigureA.png、Day03/Data/Day03_Data.csvだったパスが、それぞれScript.R、Figs/FigureA.png、Data/Day03_Data.csvになる。\n　また、何らかの理由でDay03フォルダーの名前をDay05に変更したとしよう。もし、プロジェクト機能を使っていないのであれば、パスのDay03を全てDay05に変更する必要がある。しかし、プロジェクト機能を使っているのであれば、.Rprojファイルが存在するフォルダーが作業フォルダーになるため、そもそもパスにDay03は存在しない。つまり、修正不要ということだ。ちなみに、プロジェクトを一旦作成したら、そのプロジェクトのフォルダー名や.Rprojファイルの名前は自由に修正しても良いし、フォルダー名と.Rprojファイルの名前が一致しなくても良い。\n　以上の内容を住所と郵便の話で例えるとしよう。社内でも郵便物の行き来は頻繁に行われる。とりわけ面積が広く、キャンパスも複数ある大学なら尚更だ。たとえば、「大阪府吹田市山手町3-3-35 関西大学 ラーメン学部」の宋が「大阪府吹田市山手町3-3-35 関西大学 ラーメン研究支援課」の金に郵便を送る場合、同じ大学であるにも関わらず、住所を全て書くのは面倒なことであろう。ここで関西大学専用の郵便局を作れば問題は解決される（これは「学内便」と呼ばれる）。そうすれば差出人は「ラーメン学部　宋」、受取人は「ラーメン研究支援課　金」と書くだけで郵便物は届く。つまり、「大阪府吹田市山手町3-3-35 関西大学」は省略できる（同じ市区町村内の引っ越した際、転入・転出届けの住所欄に市区町村名までは省略できるのと同じ）。また、関西大学がなぜかキャンパスを沖縄に移転した場合を考えてみよう（もはや関西大学ではないが…）。学内便がなければ、郵便物の住所を全て「沖縄県〜」に変えなければならない。しかし、学内便が存在すればこれまで使ってきた「ラーメン学部　宋」という表記は有効であろう。\n　このようにRStudioのプロジェクト機能は必須といっても過言ではない。簡単な計算目的として使う場合は問題ないが、何かの分析をする時、授業の実習時、課題時には必ずRStudioの右上が「Project: (None)」になっていないことを確認しよう。\n\n\n\n\n\n\n絶対パスと相対パス\n\n\n\n　これまで紹介したパスの書き方で/（WindowsならC:\\）から始まるパスは、絶対パス（absolute path）またはフルパス（full path）と呼ばれる。これはファイル名を最上位フォルダーを起点に書く方法である。一方、/（WindowsならC:\\）で始まらないパスは相対パス（relative path）呼ばれ、ファイル名を作業フォルダーを起点に書く方法である。",
    "crumbs": [
      "ファイル・システム"
    ]
  },
  {
    "objectID": "intro/filesystem.html#本講義でおすすめするフォルダー構造",
    "href": "intro/filesystem.html#本講義でおすすめするフォルダー構造",
    "title": "ファイル・システム",
    "section": "4 本講義でおすすめするフォルダー構造",
    "text": "4 本講義でおすすめするフォルダー構造\n　プロジェクトを作成すれば、プロジェクトフォルダー内に以下のようなフォルダーを作成しよう。\n\n表形式のデータを読み込んだり、保存したりするのであればDataフォルダーをプロジェクトフォルダー内に作成する。\n\n.csv、.xlsx、.sav、.dtaのような表形式ファイルはDataフォルダーに入れる。\nデータを加工し、保存する場合はData/ファイル名.csvなどと指定する。\n\n図を作成し、保存する予定があれば、Figsフォルダーをプロジェクトフォルダー内に作成する。\n\n図を保存する場合、ファイルのパスをFigs/ファイル名.pngやFigs/ファイル名.pdfとする。\n\n\n　よく分からない場合はとりあえずプロジェクトフォルダー内にDataとFigsというフォルダーを作っておこう。ただし、.R、.qmdなどコードファイルはプロジェクトフォルダーの下位フォルダーに入れず、プロジェクトフォルダーの直に入れよう4。この場合、R Markdown / Quartoで作成された文書（.html、.pdfなど）は.Rmdや.qmdファイルと同じフォルダーに保存される（別途の設定をすれば別フォルダーに保存することも可能だが、そこまではしなくても良い）。",
    "crumbs": [
      "ファイル・システム"
    ]
  },
  {
    "objectID": "intro/filesystem.html#参考",
    "href": "intro/filesystem.html#参考",
    "title": "ファイル・システム",
    "section": "5 参考",
    "text": "5 参考\n　以下の内容も合わせて読むことを強く推奨する。\n\n宋財泫・矢内勇生.『私たちのR』の「ファイルシステム」",
    "crumbs": [
      "ファイル・システム"
    ]
  },
  {
    "objectID": "intro/filesystem.html#footnotes",
    "href": "intro/filesystem.html#footnotes",
    "title": "ファイル・システム",
    "section": "脚注",
    "text": "脚注\n\n\n一部、拡張子を持たないファイルもある。↩︎\n文書ファイルが.pdf以外にも.docx、.odt、.txtなどがあるように、画像ファイルも.pngだけでなく、.jpg、.gif、.bmp、.svgなど様々なフォーマットがある。↩︎\nただし、LMSに提出する場合、ファイル名をわざわざ修正しなくても良い。教員側からダウンロードする際、勝手に学生番号と氏名が付いたファイル名になるからだ。↩︎\n人によってはスクリプトファイルをScriptフォルダー内に入れる人もいるが推奨しない。とりわけ、R MarkdownやQuartoの場合、コンソール上で実行時のパスとKnit時のパスの扱いが異なる場合が多い。プロジェクトフォルダーに入れておけば、問題は解決される。↩︎",
    "crumbs": [
      "ファイル・システム"
    ]
  },
  {
    "objectID": "slide/matching.html#因果推論と内生性",
    "href": "slide/matching.html#因果推論と内生性",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "内生性: 処置変数と誤差項間の相関関係\n\n内生性は因果推論の敵\n例\n\n処置変数 = ソンさんの講義を履修するか否か\n結果変数 = 10年後の年収\nもし、やる気のある学生が履修する傾向があるとしたら?\nやる気のある学生は履修の有無と関係なく、高所得者になりやすい。\n\\(\\rightarrow\\) 「やる気」は処置と結果、両方と連関している\n\n\n\n\n内生性を除去する最良の手法 \\(\\rightarrow\\) RCT"
  },
  {
    "objectID": "slide/matching.html#rctの限界",
    "href": "slide/matching.html#rctの限界",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "高費用\n\n数万〜数億円\n\n倫理的な問題による実行不可能性\n\n喫煙と健康\nPhilip Zimbardo. 2008. The Lucifer Effect: How Good People Turn Evil. Rider.\n\n外的妥当性の問題\n\nMichael G. Findley, Kyosuke Kikuta, and Michael Denly. 2021. “External Validity,” Annual Review of Political Science, 24:365-393.\n\n回顧的因果推論には不向き\n\n主に介入 (intervention)の効果が推定対象"
  },
  {
    "objectID": "slide/matching.html#観察データを用いた因果推論",
    "href": "slide/matching.html#観察データを用いた因果推論",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "もし、\\(X\\)をしたら（did）\\(Y\\)はどうなった（would）だろうか\n\n過去を対象にRCTを行うことは不可能\n過去に収集された観察データを使用した因果推論が必要\nマッチング、回帰不連続デザイン、差分の差分法、操作変数法など\n\n\n割当メカニズム (assignment mechanism)\n\nユニットが処置を受けるか否かを規定するメカニズム\n例) 「やる気」が「履修」を規定\n無作為割当なら無作為に処置を受けるか否かが決まるため、考える必要がない。"
  },
  {
    "objectID": "slide/matching.html#内生性への対処",
    "href": "slide/matching.html#内生性への対処",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "matching_data1.csvの例（架空データ; 30行 \\(\\times\\) 4列）\n\n明らかに「やる気」と「履修」は連関\n履修有無による平均年収の差は約265.333万円\n\n\n\n\n\n\n\n\n# A tibble: 10 × 4\n      ID Income Yaruki Rishu\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1     1    659      0     1\n 2     2    587      1     1\n 3     3    628      1     1\n 4     4    563      1     1\n 5     5    531      1     1\n 6     6     79      0     0\n 7     7    356      0     1\n 8     8    176      0     0\n 9     9    339      0     0\n10    10    520      1     1\n\n\n\n\n# A tibble: 10 × 4\n      ID Income Yaruki Rishu\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1    11    239      0     0\n 2    12    276      1     0\n 3    13    609      1     1\n 4    14    254      0     0\n 5    15    423      0     1\n 6    16    172      0     1\n 7    17     20      0     0\n 8    18    447      1     0\n 9    19    498      1     1\n10    20    648      1     1\n\n\n\n\n# A tibble: 10 × 4\n      ID Income Yaruki Rishu\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1    21    155      0     0\n 2    22    768      1     1\n 3    23    463      1     0\n 4    24    309      1     0\n 5    25    304      0     0\n 6    26    408      1     1\n 7    27    259      0     0\n 8    28    516      1     1\n 9    29    476      1     0\n10    30    110      0     0"
  },
  {
    "objectID": "slide/matching.html#内生性への対処-1",
    "href": "slide/matching.html#内生性への対処-1",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "方法：処置変数と結果変数に影響を与える要因（交絡要因）を揃える\n\n「やる気」のない学生（Yaruki == 0）だけに絞ってみる\n履修有無による平均年収の差は209万円\n\n\n\n\ndf1 |&gt;\n  filter(Yaruki == 0) |&gt;\n  group_by(Rishu) |&gt;\n  summarise(Inc = mean(Income)) |&gt;\n  pull(Inc)\n\n[1] 193.5 402.5\n\n\n\n402.5 - 193.5\n\n[1] 209\n\n\n\n\n\n\n\n\n\n\n\nID\n所得\nやる気\n履修\n　\nID\n所得\nやる気\n履修\n\n\n\n\n1\n659\n0\n1\n\n6\n79\n0\n0\n\n\n7\n356\n0\n1\n\n8\n176\n0\n0\n\n\n15\n423\n0\n1\n\n9\n339\n0\n0\n\n\n16\n172\n0\n1\n\n11\n239\n0\n0\n\n\n\n\n\n\n\n14\n254\n0\n0\n\n\n\n\n\n\n\n17\n20\n0\n0\n\n\n\n\n\n\n\n21\n155\n0\n0\n\n\n\n\n\n\n\n25\n304\n0\n0\n\n\n\n\n\n\n\n27\n259\n0\n0\n\n\n\n\n\n\n\n30\n110\n0\n0\n\n\nMean\n402.5\n\n\n\nMean\n193.5"
  },
  {
    "objectID": "slide/matching.html#内生性への対処-2",
    "href": "slide/matching.html#内生性への対処-2",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "方法: 処置変数と結果変数に影響を与える要因(交絡要因)を揃える\n\n「やる気」のある学生（Yaruki == 1）だけに絞ってみる\n履修有無による平均年収の差は176.3万円\n\n\n\n\ndf1 |&gt;\n  filter(Yaruki == 1) |&gt;\n  group_by(Rishu) |&gt;\n  summarise(Inc = mean(Income)) |&gt;\n  pull(Inc)\n\n[1] 394.2000 570.5455\n\n\n\n570.5455 - 394.2000\n\n[1] 176.3455\n\n\n\n\n\n\n\n\n\n\n\nID\n所得\nやる気\n履修\n　\nID\n所得\nやる気\n履修\n\n\n\n\n2\n587\n1\n1\n\n12\n276\n1\n0\n\n\n3\n628\n1\n1\n\n18\n447\n1\n0\n\n\n4\n563\n1\n1\n\n23\n463\n1\n0\n\n\n5\n531\n1\n1\n\n24\n309\n1\n0\n\n\n10\n520\n1\n1\n\n29\n476\n1\n0\n\n\n13\n609\n1\n1\n\n\n\n\n\n\n\n19\n498\n1\n1\n\n\n\n\n\n\n\n20\n648\n1\n1\n\n\n\n\n\n\n\n22\n768\n1\n1\n\n\n\n\n\n\n\n26\n408\n1\n1\n\n\n\n\n\n\n\n28\n516\n1\n1\n\n\n\n\n\n\n\nMean\n570.5\n\n\n\nMean\n394.2"
  },
  {
    "objectID": "slide/matching.html#内生性への対処-3",
    "href": "slide/matching.html#内生性への対処-3",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "やる気なし\n\n\n\n\n\n\n履修 (T)\n平均年収 (Y)\n\n\n\n\n1\n402.5\n\n\n0\n193.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nやる気あり\n\n\n\n\n\n\n履修 (T)\n平均年収 (Y)\n\n\n\n\n1\n570.5\n\n\n0\n394.2\n\n\n\n\n\n\n\n\n\n\nやる気のある（ない）被験者を一人の被験者として考える場合、差分はITEと解釈可能。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID (i)\nN\nやる気 (Zi)\nYi(Ti = 1)\nYi(Ti = 0)\nITEi\n\n\n\n\n1\n14\n0\n402.5\n193.5\n209.0\n\n\n2\n16\n1\n570.5\n394.2\n176.3\n\n\n\n\n\n\n\n\nITEの加重平均 \\(\\rightarrow\\) 講義履修の因果効果 \\(\\rightarrow\\) 約191.6万円\n\n\nweighted.mean(c(209.0, 176.3), w = c(14, 16))\n\n[1] 191.56"
  },
  {
    "objectID": "slide/matching.html#マッチングの考え方-1",
    "href": "slide/matching.html#マッチングの考え方-1",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "割当メカニズムを想定し、交絡要因が同じユニット同士を比較\n\n交絡要因: 処置変数と結果変数、両方と関係のある変数\n以下の条件が満たされる場合、マッチングで因果効果の推定が可能\n条件付き独立の仮定 (Conditional Independece Assumption; CIA)\n\n\\(\\{Y_i(T_i = 1),Y_i(T_i = 0)\\} \\perp T_i∣X_i\\)\n\\(T_i\\) : 学生 \\(i\\) の履修有無、 \\(X_i\\) : 学生 \\(i\\) のやる気\nやる気(=交絡要因)が同じ場合、学生 \\(i\\) がソンさんの講義を履修するか否か(=処置変数)は彼(女)の将来収入(=結果変数)と関係なく決まる\n\\(\\rightarrow\\) 処置変数を外生変数として扱うことが可能に\n\nCIAが満たされるためには、割当メカニズム上のすべての交絡要因が必要"
  },
  {
    "objectID": "slide/matching.html#条件付き独立の仮定とは",
    "href": "slide/matching.html#条件付き独立の仮定とは",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "ID (i)\nZi\nTi\nY0, i\nY1, i\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nY0\nY1\n\n\n\n\nT = 0\n\n0.429\n\n\n0.429\n\n\n\nT = 1\n\n0.538\n\n\n0.538\n\n\n\n\n\n\n\n\n\n処置効果は0.538 − 0.429 = 0.109\nもし、統制群と処置群が同質なら\nA = C、そしてB = Dのはず\n処置群がもし統制群になっても、今の統制群と同じ\n\\(\\Rightarrow\\) 交換可能性が成立せず"
  },
  {
    "objectID": "slide/matching.html#条件付き独立の仮定とは-1",
    "href": "slide/matching.html#条件付き独立の仮定とは-1",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "ID (i)\nZi\nTi\nY0, i\nY1, i\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\n\n\n\\(Z\\) で条件づけた場合 ( \\(Z = 0\\) )\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nY0\nY1\n\n\n\n\nT = 0\n\n0.250\n\n\n0.250\n\n\n\nT = 1\n\n0.250\n\n\n0.250\n\n\n\n\n\n\n\n\n\n処置効果は0.250 − 0.250 = 0.000\nもし、統制群と処置群が同質なら\nA = C、そしてB = Dが成立\n\\(\\Rightarrow\\) 交換可能性が成立"
  },
  {
    "objectID": "slide/matching.html#条件付き独立の仮定とは-2",
    "href": "slide/matching.html#条件付き独立の仮定とは-2",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "ID (i)\nZi\nTi\nY0, i\nY1, i\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\n\n\n\\(Z\\) で条件づけた場合 ( \\(Z = 1\\) )\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nY0\nY1\n\n\n\n\nT = 0\n\n0.667\n\n\n0.667\n\n\n\nT = 1\n\n0.667\n\n\n0.667\n\n\n\n\n\n\n\n\n\n処置効果は0.667 − 0.667 = 0.000\nもし、統制群と処置群が同質なら\nA = C、そしてB = Dが成立\n\\(\\Rightarrow\\) 交換可能性が成立"
  },
  {
    "objectID": "slide/matching.html#条件付き独立の仮定とは-3",
    "href": "slide/matching.html#条件付き独立の仮定とは-3",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "ID (i)\nZi\nTi\nY0, i\nY1, i\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\n\n\n条件付き独立が成立するということは\n\n交換可能性が成立\n処置群を統制群に、統制群を処置群にしても同じ結果が得られること"
  },
  {
    "objectID": "slide/matching.html#重回帰分析との比較",
    "href": "slide/matching.html#重回帰分析との比較",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "重回帰分析における回帰係数の解釈\n\n他の変数すべてが同じ場合、ある変数が1単位変化する時の応答変数の変化量\nマッチングと同じ?\n\n重回帰分析とマッチングの結果が近似することも \\(\\bigcirc\\)\n\n参考）手計算マッチングの結果：約191.6万円\n\n計算時に小数点を切り捨てたため誤差あり\n\n\n\n\n\n# df1 は matching_data1.csv\n# 単回帰分析\nFit1 &lt;- lm(Income ~ Rishu, data = df1)\n# 重回帰分析\nFit2 &lt;- lm(Income ~ Rishu + Yaruki, data = df1)\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                単回帰分析\n                重回帰分析\n              \n        \n        \n        \n                \n                  (Intercept)\n                  260.400 (36.459)\n                  198.595 (32.737)\n                \n                \n                  Rishu      \n                  265.333 (51.561)\n                  191.167 (44.915)\n                \n                \n                  Yaruki     \n                                  \n                  185.415 (45.015)\n                \n                \n                  Num.Obs.   \n                  30              \n                  30              \n                \n                \n                  R2         \n                  0.486           \n                  0.684"
  },
  {
    "objectID": "slide/matching.html#重回帰分析との比較-1",
    "href": "slide/matching.html#重回帰分析との比較-1",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "実質的にマッチングと回帰分析は同じという見解も (Angrist and Pischke 2009)\n\n具体的に言えば、回帰分析はマッチングの特殊な形態\n\n強い仮定を置いたマッチング\n回帰分析は \\(Y = \\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k\\) の関数型を仮定 (parametric)\n\n回帰分析において誤差項の平均値は必ず0を仮定 ( \\(\\mathbb{E}(\\varepsilon|T, X) = 0\\) )\n\nマッチングの場合、( \\(\\mathbb{E}(\\varepsilon|T = 0, X) = \\mathbb{E}(\\varepsilon|T = 1, X)\\) )\n\n回帰分析はオーバーラップ条件を無視する\n\nマッチングされないケースでも、線形関数によって予測されてしまう\nマッチングはオーバーラップされないケースを分析から除外する\n\n結論: 回帰分析より柔軟、拡張性がある"
  },
  {
    "objectID": "slide/matching.html#ate-att-atc",
    "href": "slide/matching.html#ate-att-atc",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "3種類の因果効果\n\nATE (Average Treatment Effect): 平均処置効果\nATT (ATE for the Treated): 処置群における平均処置効果\n\n潜在結果: 処置群が処置を受けなかった場合の応答変数\n\nATC (ATE for the Control): 統制群における平均処置効果\n\n潜在結果: 統制群が処置を受けた場合の応答変数\n\n\n\n\n因果効果は一般的に母集団ではなく、サンプルから推定されるため、「SATE/SATT/SATC」と呼ばれる場合も\n他にもRIE (Retrospective Intervention Effect) なども (Samii et al. 2016)\nRCTでは主にATEが推定対象（マッチングでは区分するケースが多い）\n統計ソフトウェアによってはATTを因果効果の推定値として表示する場合もある。"
  },
  {
    "objectID": "slide/matching.html#att-処置群における平均処置効果",
    "href": "slide/matching.html#att-処置群における平均処置効果",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "処置群の潜在的結果を統制群から割り当てる。\n処置群は \\(Y_i(T_i = 1)\\) が観察済みであり、潜在的結果は \\(Y_i(T_i = 0)\\)\nやる気のない学生の \\(Y_i(T_i = 0)\\) は193.5、ある学生は394.2\n\n\n\n\n\n\n\n\n\nID (i)\nYarukii\nYi(Ti = 1)\nYi(Ti = 0)\nITEi\n\n\n\n\n1\n0\n659\n193.5\n465.5\n\n\n2\n1\n587\n394.2\n192.8\n\n\n3\n1\n628\n394.2\n233.8\n\n\n4\n1\n563\n394.2\n168.8\n\n\n5\n1\n531\n394.2\n136.8\n\n\n7\n0\n356\n193.5\n162.5\n\n\n...\n...\n...\n...\n...\n\n\n20\n1\n648\n394.2\n253.8\n\n\n22\n1\n768\n394.2\n373.8\n\n\n26\n1\n408\n394.2\n13.8\n\n\n28\n1\n516\n394.2\n121.8\n\n\n平均\n\n\n\n185.1"
  },
  {
    "objectID": "slide/matching.html#atc-統制群における平均処置効果",
    "href": "slide/matching.html#atc-統制群における平均処置効果",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "統制群の潜在的結果を処置群から割り当てる。\n統制群は \\(Y_i(T_i = 0)\\) が観察済みであり、潜在的結果は \\(Y_i(T_i = 1)\\)\nやる気のない学生の \\(Y_i(T_i = 1)\\) は402.5、ある学生は570.5\n\n\n\n\n\n\n\n\n\nID (i)\nYarukii\nYi(Ti = 1)\nYi(Ti = 0)\nITEi\n\n\n\n\n6\n0\n402.5\n79\n323.5\n\n\n8\n0\n402.5\n176\n226.5\n\n\n9\n0\n402.5\n339\n63.5\n\n\n11\n0\n402.5\n239\n163.5\n\n\n12\n1\n570.5\n276\n294.5\n\n\n14\n0\n402.5\n254\n148.5\n\n\n...\n...\n...\n...\n...\n\n\n25\n0\n402.5\n304\n98.5\n\n\n27\n0\n402.5\n259\n143.5\n\n\n29\n1\n570.5\n476\n94.5\n\n\n30\n0\n402.5\n110\n292.5\n\n\n平均\n\n\n\n198.1"
  },
  {
    "objectID": "slide/matching.html#ate-平均処置効果",
    "href": "slide/matching.html#ate-平均処置効果",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "ATTとATCの加重平均\n今回は処置群と統制群が15:15 \\(\\rightarrow\\) 単純平均でOK\n\n\\(\\frac{1}{2}(185.1 + 198.1) = 191.6\\)\n手計算マッチングとと同じ結果\n\n\n\\[\\text{ATE} = \\frac{N_{\\text{treated}}}{N_{\\text{all}}} \\text{ATT} + \\frac{N_{\\text{controlled}}}{N_{\\text{all}}} \\text{ATC}.\\]"
  },
  {
    "objectID": "slide/matching.html#マッチングいろいろ",
    "href": "slide/matching.html#マッチングいろいろ",
    "title": "方法論特殊講義III",
    "section": "マッチングいろいろ",
    "text": "マッチングいろいろ\n\nExact Matching\nNearest-neighbor Matching\n\nk-nearest Neighbor Matching\nCaliper Matching (Radius Matching)\n\nCoarsened Exact Matching\nPropensity Score Matching\n\nInverse Probability Weighting\nEnsemble Matching"
  },
  {
    "objectID": "slide/matching.html#exact-matching",
    "href": "slide/matching.html#exact-matching",
    "title": "方法論特殊講義III",
    "section": "Exact Matching",
    "text": "Exact Matching\n\n「正確マッチング」、「厳格なマッチング」などで訳される\nこれまで見てきた方法が Exact Matching\n\nデータ内の共変量 (交絡要因) が完全に一致するケース同士の比較\n\n共変量が少数、かつ、名目or順序変数の場合、使用可\n共変量が多数、または連続変数の場合は実質的に無理\n\n次元の呪い or 次元爆発"
  },
  {
    "objectID": "slide/matching.html#nearest-neighbor-matching",
    "href": "slide/matching.html#nearest-neighbor-matching",
    "title": "方法論特殊講義III",
    "section": "Nearest-neighbor Matching",
    "text": "Nearest-neighbor Matching\nNearest-neighbor Matching\n\n「最近傍マッチング」と訳される。\n共変量が連続変数、多次元の場合、「完全に一致」ケースはない場合がほとんど\n\n\\(\\rightarrow\\) 「一致」ではなく、「最も似ている」ケース同士と比較\n共変量を座標（超）平面に位置づけた場合、最も近いケースをマッチング\n\n\n\n「近さ」の基準\n\nManhattan Distance\nStandardized Euclidean Distance\nMahalanobis Distance (\\(\\leftarrow\\) 最もよく使われる基準)"
  },
  {
    "objectID": "slide/matching.html#マンハッタン距離manhattan-distance-city-block-distance",
    "href": "slide/matching.html#マンハッタン距離manhattan-distance-city-block-distance",
    "title": "方法論特殊講義III",
    "section": "マンハッタン距離（Manhattan Distance; City-block Distance）",
    "text": "マンハッタン距離（Manhattan Distance; City-block Distance）\n\\[d(i, j) = |X_i - X_j| + |Y_i - Y_j| \\text{ where } i \\neq j.\\]"
  },
  {
    "objectID": "slide/matching.html#標準化ユークリッド距離standardized-euclidean-distance",
    "href": "slide/matching.html#標準化ユークリッド距離standardized-euclidean-distance",
    "title": "方法論特殊講義III",
    "section": "標準化ユークリッド距離（Standardized Euclidean Distance）",
    "text": "標準化ユークリッド距離（Standardized Euclidean Distance）\n\\[d(i, j) = \\sqrt{\\Bigg(\\frac{X_i - X_j}{\\sigma_X}\\Bigg)^2 + \\Bigg(\\frac{Y_i - Y_j}{\\sigma_Y}\\Bigg)^2} \\text{ where } i \\neq j.\\]"
  },
  {
    "objectID": "slide/matching.html#マハラノビス距離mahalanobis-distance",
    "href": "slide/matching.html#マハラノビス距離mahalanobis-distance",
    "title": "方法論特殊講義III",
    "section": "マハラノビス距離（Mahalanobis Distance）",
    "text": "マハラノビス距離（Mahalanobis Distance）\n\n共変量間の相関が0（\\(\\rho = 0\\)）の場合、Standardized Euclidean Distanceと同じ\n\n\\[d(i, j) = \\sqrt{\\frac{1}{1 - \\rho^2_{X, Y}} \\Bigg[\\Bigg(\\frac{X_i - X_j}{\\sigma_X}\\Bigg)^2 + \\Bigg(\\frac{Y_i - Y_j}{\\sigma_Y}\\Bigg)^2 - 2\\rho_{X,Y}\\Bigg(\\frac{X_i - X_j}{\\sigma_X}\\Bigg) \\Bigg(\\frac{Y_i - Y_j}{\\sigma_Y}\\Bigg)\\Bigg]} \\text{ where } i \\neq j.\\]"
  },
  {
    "objectID": "slide/matching.html#マッチング方法",
    "href": "slide/matching.html#マッチング方法",
    "title": "方法論特殊講義III",
    "section": "マッチング方法",
    "text": "マッチング方法\nATTの場合、処置群のケースに統制群の中で最も近いケース1個を割当\n\n近さの測定はマハラノビス距離が一般的\n処置群内の1ケースに複数の統制群ケースを割り当てる場合も\n\nk-nearest Neighbor Matching\nCaliper Matching\n\n復元マッチングと非復元マッチング"
  },
  {
    "objectID": "slide/matching.html#k-nearest-neighbor-matching",
    "href": "slide/matching.html#k-nearest-neighbor-matching",
    "title": "方法論特殊講義III",
    "section": "k-nearest Neighbor Matching",
    "text": "k-nearest Neighbor Matching\nk-最近傍マッチング\n\n最も近い1個ケースを潜在的結果として使うのではなく、最も近い \\(k\\) 個のケースの平均値を潜在的結果として用いる。\n\n\\(j(m)\\) : \\(i\\) から \\(m\\) 番目に近いケース \\(j\\)\n\n\n\\[Y_i(T_i = 0) = \\begin{cases}Y_i & \\text{ if } T_i = 0\\\\ \\frac{1}{K} \\sum_{m = 1}^K Y_{j(m)} & \\text{ if } T_i = 1\\end{cases}\\]\n\n最適 \\(k\\) を決める理論的基準は無し\n\n\\(k\\) を大きくすると、モデルの分散が小さくなる\nただし、モデルの分散が小さい = バイアスが拡大\n\nBias–variance trade-off\n\n\\(k\\) を変化させることによって結果がどのように変わるか観察"
  },
  {
    "objectID": "slide/matching.html#caliper-matching",
    "href": "slide/matching.html#caliper-matching",
    "title": "方法論特殊講義III",
    "section": "Caliper Matching",
    "text": "Caliper Matching\n「カリパーマッチング」と訳される（訳されてない…?）\n\n半径 \\(h\\) の中にある全てのケースの平均値を潜在的結果として使用\n\n\n\n\\[Y_i(T_i = 0) = \\begin{cases}Y_i & \\text{ if } T_i = 0\\\\ \\frac{\\sum_{j=1}^N I(T_j = 0, d(i, j) &lt; h)\\cdot Y_i}{\\sum_{j=1}^N I(T_j = 0, d(i, j) &lt; h)} & \\text{ if } T_i = 1\\end{cases}\\]"
  },
  {
    "objectID": "slide/matching.html#復元マッチングと非復元マッチング",
    "href": "slide/matching.html#復元マッチングと非復元マッチング",
    "title": "方法論特殊講義III",
    "section": "復元マッチングと非復元マッチング",
    "text": "復元マッチングと非復元マッチング\n\n1:1マッチングの場合に生じる問題：マッチング済みの統制群（or 処置群）をどう扱うか\n\n他にも近い処置群のケースがあればマッチング \\(\\rightarrow\\) 復元マッチング\n他にも近い処置群のケースがあっても使わない \\(\\rightarrow\\) 非復元マッチング\n\n復元マッチングの場合、統制群の各ケースに重みが付与される。\n\n加重平均 or 重み付け回帰分析が必要\n\n多くのパッケージは非復元がデフォルトとなっているが、推定ごとに結果が変化することも（図BとC）\n\n復元マッチングはバランスが改善されやすいが、サンプルサイズが小さくなる。\n\n正しい方法はなく、分析者の判断が必要。\n下の例はATT推定の例（赤が処置群、青は統制群）\n\n\n\n\n\n\n\n\n\n\nA) 復元マッチング\n\n\n\n\n\n\n\nB) 非復元マッチング (1)\n\n\n\n\n\n\n\nC) 非復元マッチング (2)"
  },
  {
    "objectID": "slide/matching.html#coarsened-exact-matching",
    "href": "slide/matching.html#coarsened-exact-matching",
    "title": "方法論特殊講義III",
    "section": "Coarsened Exact Matching",
    "text": "Coarsened Exact Matching\nCoarsened Exact Matching (Iacus, King, and Porro 2011)\n\n定訳はなく、「CEM」で呼ばれる(粗い正確マッチング?)\nアルゴリズムは簡単\n\n共変量をいくつかの層 (strata) へ分割する。\n各層にそれぞれ該当する処置・統制ユニットを入れる。\n最低一つ以上の処置・統制ユニットがない層は捨てる。\n各層の処置・統制ユニットの結果変数の差分を計算し、すべての層に対して加重平均\n\n層を細かくするほどExact Matchingへ近づく\n\nただし、マッチングされないケースが多くなり、分析に使えるケースが減少\nバイアス\\(\\downarrow\\); 分散\\(\\uparrow\\)"
  },
  {
    "objectID": "slide/matching.html#cemの例",
    "href": "slide/matching.html#cemの例",
    "title": "方法論特殊講義III",
    "section": "CEMの例",
    "text": "CEMの例\nmatching_data2.csvの例\n\n年齢は10歳刻み、学歴は大卒以上・未満に層化\n\n\n\n\n\n\n\n\n\nID\n年齢\n教育\n処置\n結果\n　\nID\n年齢\n教育\n処置\n結果\n\n\n\n\n1\n29\n院\n0\n6\n\n13\n57\n高\n0\n4\n\n\n2\n41\n大\n0\n3\n\n14\n25\n院\n1\n5\n\n\n3\n31\n院\n1\n7\n\n15\n55\n中\n1\n9\n\n\n4\n39\n院\n0\n5\n\n16\n48\n院\n0\n2\n\n\n5\n53\n大\n0\n6\n\n17\n23\n専\n0\n2\n\n\n6\n59\n大\n0\n1\n\n18\n34\n大\n1\n4\n\n\n7\n37\n高\n1\n8\n\n19\n42\n大\n1\n9\n\n\n8\n44\n中\n0\n4\n\n20\n23\n高\n0\n4\n\n\n9\n51\n中\n0\n2\n\n21\n22\n高\n1\n8\n\n\n10\n59\n小\n1\n8\n\n22\n49\n大\n0\n9\n\n\n11\n21\n大\n1\n4\n\n23\n45\n高\n1\n6\n\n\n12\n24\n中\n1\n6\n\n24\n33\n大\n0\n8"
  },
  {
    "objectID": "slide/matching.html#cemの例-1",
    "href": "slide/matching.html#cemの例-1",
    "title": "方法論特殊講義III",
    "section": "CEMの例",
    "text": "CEMの例\n年齢は10歳刻み、学歴は大卒以上・未満に層化\n\nカテゴリが少なくなり、マッチングしやすくなる\n\n\n\n\n\n\n\n\n\nID\n年齢\n教育\n処置\n結果\n　\nID\n年齢\n教育\n処置\n結果\n\n\n\n\n1\n20代\nH\n0\n6\n\n13\n50代\nL\n0\n4\n\n\n2\n40代\nH\n0\n3\n\n14\n20代\nH\n1\n5\n\n\n3\n30代\nH\n1\n7\n\n15\n50代\nL\n1\n9\n\n\n4\n30代\nH\n0\n5\n\n16\n40代\nH\n0\n2\n\n\n5\n50代\nH\n0\n6\n\n17\n20代\nL\n0\n2\n\n\n6\n50代\nH\n0\n1\n\n18\n30代\nH\n1\n4\n\n\n7\n30代\nL\n1\n8\n\n19\n40代\nH\n1\n9\n\n\n8\n40代\nL\n0\n4\n\n20\n20代\nL\n0\n4\n\n\n9\n50代\nL\n0\n2\n\n21\n20代\nL\n1\n8\n\n\n10\n50代\nL\n1\n8\n\n22\n40代\nH\n0\n9\n\n\n11\n20代\nH\n1\n4\n\n23\n40代\nL\n1\n6\n\n\n12\n20代\nL\n1\n6\n\n24\n30代\nH\n0\n8"
  },
  {
    "objectID": "slide/matching.html#cemの例-2",
    "href": "slide/matching.html#cemの例-2",
    "title": "方法論特殊講義III",
    "section": "CEMの例",
    "text": "CEMの例\n\n\n層ごとにケースをマッチング\n\nペアが組めない層が存在\n\n30代 & L\n50代 & H\n\n\n\n\n\n\n\n\n\n\n\n年齢\n教育\n処置群\n統制群\n\n\nID\n処置\n結果\nID\n処置\n結果\n\n\n\n\n20代\nH\n11\n1\n5\n1\n0\n6\n\n\n20代\nH\n14\n1\n5\n\n\n\n\n\n20代\nL\n12\n1\n6\n17\n0\n2\n\n\n20代\nL\n21\n1\n8\n20\n0\n4\n\n\n30代\nH\n3\n1\n7\n4\n0\n5\n\n\n30代\nH\n18\n1\n4\n24\n0\n8\n\n\n30代\nL\n7\n1\n8\n\n\n\n\n\n40代\nH\n19\n1\n9\n2\n0\n3\n\n\n40代\nH\n\n\n\n16\n0\n2\n\n\n40代\nH\n\n\n\n22\n0\n9\n\n\n40代\nL\n23\n1\n6\n8\n0\n4\n\n\n50代\nH\n\n\n\n5\n0\n6\n\n\n50代\nH\n\n\n\n6\n0\n1\n\n\n50代\nL\n10\n1\n8\n9\n0\n2\n\n\n50代\nL\n15\n1\n9\n13\n0\n4"
  },
  {
    "objectID": "slide/matching.html#cemの例-3",
    "href": "slide/matching.html#cemの例-3",
    "title": "方法論特殊講義III",
    "section": "CEMの例",
    "text": "CEMの例\nペアが組めない層を除外（30代Lと50代H）\n\n\n\n\n\n\n\n\n年齢\n教育\n処置群\n統制群\n\n\nID\n処置\n結果\nID\n処置\n結果\n\n\n\n\n20代\nH\n11\n1\n5\n1\n0\n6\n\n\n20代\nH\n14\n1\n5\n\n\n\n\n\n20代\nL\n12\n1\n6\n17\n0\n2\n\n\n20代\nL\n21\n1\n8\n20\n0\n4\n\n\n30代\nH\n3\n1\n7\n4\n0\n5\n\n\n30代\nH\n18\n1\n4\n24\n0\n8\n\n\n40代\nH\n19\n1\n9\n2\n0\n3\n\n\n40代\nH\n\n\n\n16\n0\n2\n\n\n40代\nH\n\n\n\n22\n0\n9\n\n\n40代\nL\n23\n1\n6\n8\n0\n4\n\n\n50代\nL\n10\n1\n8\n9\n0\n2\n\n\n50代\nL\n15\n1\n9\n13\n0\n4"
  },
  {
    "objectID": "slide/matching.html#cemの例-4",
    "href": "slide/matching.html#cemの例-4",
    "title": "方法論特殊講義III",
    "section": "CEMの例",
    "text": "CEMの例\n各ユニットの重みを計算\n\n\n\\[w_i = \\begin{cases} 1 & \\text{ if } T_i = 1, \\\\ \\frac{m_C}{m_T} \\cdot \\frac{m^s_T}{m^s_C} & \\text{ if } T_i = 0.\\end{cases}\\]\n\n\\(m_{C,T}\\): 統制・処置ケースの数\n\nペアを組めなかったケースはカウントしない\n\n\\(m^s_{C,T}\\): 層 \\(s\\) 内の統制・処置ケースの数\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n年齢\n教育\n処置群\n統制群\n\n\nID\n処置\n結果\n重み\nID\n処置\n結果\n重み\n\n\n\n\n20代\nH\n11\n1\n5\n1\n1\n0\n6\n2.2\n\n\n20代\nH\n14\n1\n5\n1\n\n\n\n\n\n\n\n20代\nL\n12\n1\n6\n1\n17\n0\n2\n1.1\n\n\n20代\nL\n21\n1\n8\n1\n20\n0\n4\n1.1\n\n\n30代\nH\n3\n1\n7\n1\n4\n0\n5\n1.1\n\n\n30代\nH\n18\n1\n4\n1\n24\n0\n8\n1.1\n\n\n40代\nH\n19\n1\n9\n1\n2\n0\n3\n0.367\n\n\n40代\nH\n\n\n\n\n16\n0\n2\n0.367\n\n\n40代\nH\n\n\n\n\n22\n0\n9\n0.367\n\n\n40代\nL\n23\n1\n6\n1\n8\n0\n4\n1.1\n\n\n50代\nL\n10\n1\n8\n1\n9\n0\n2\n1.1\n\n\n50代\nL\n15\n1\n9\n1\n13\n0\n4\n1.1"
  },
  {
    "objectID": "slide/matching.html#cemの例-5",
    "href": "slide/matching.html#cemの例-5",
    "title": "方法論特殊講義III",
    "section": "CEMの例",
    "text": "CEMの例\n重み付け回帰分析\n\n\\(W = \\{2.200, 0.367, 1.000, 1.100, 0.000, 0.000, ..., 1.100\\}^{\\top}\\)\n\nマッチングされないケースの重みは0にする（= 分析から除外される）\n\\(\\beta = (X^{\\prime}WX)^{-1}X^{\\prime}WY\\)\n\nRの場合、lm(formula, data, weight = ...)で推定可能\n\n{cem} or {MatchIt}パッケージならもっと簡単\n\n\\(\\widehat{\\text{Outcome}} = 4.567 + 2.033 \\cdot \\text{Treat}\\)\n\n処置群における因果効果（ATT）= 2.033\nATCの場合、重み付けが逆（統制群の重みを1とする）"
  },
  {
    "objectID": "slide/matching.html#傾向スコアとは",
    "href": "slide/matching.html#傾向スコアとは",
    "title": "方法論特殊講義III",
    "section": "傾向スコアとは",
    "text": "傾向スコアとは\nPropensity Score\n\n簡単にいうと「あるユニット\\(i\\)が処置を受ける確率」\n\n主に\\(e\\)と表記する。\n\\(e_i = Pr(T_i = 1 | X_i)\\)"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの計算",
    "href": "slide/matching.html#傾向スコアの計算",
    "title": "方法論特殊講義III",
    "section": "傾向スコアの計算",
    "text": "傾向スコアの計算\n処置変数（\\(T_i\\)）を応答変数とし、共変量（\\(X_i\\)）を説明変数とする。\n\n一般的に、ロジットやプロビット回帰分析で推定する。\n\n他にも色々ある\n\nSupport Vector Machine, Decision Tree, Neural Network, …\n\n色んな手法で算出した傾向スコアを重み付けして合成することも可能\n\nEnsemble Method（Samii, Paler, and Zukerman 2016）\n\n\n\n\n\n推定された予測確率 \\(\\rightarrow\\) 傾向スコア\n\nRではオブジェクト名$fitted.valueで抽出可\n傾向スコアは多くの共変量を一つの変数に集約したもの\n\\(\\rightarrow\\) 傾向スコアを統制した回帰分析で因果効果を推定\n\\(\\rightarrow\\) 傾向スコアを用いて最近傍マッチング"
  },
  {
    "objectID": "slide/matching.html#傾向スコアマッチングの手順",
    "href": "slide/matching.html#傾向スコアマッチングの手順",
    "title": "方法論特殊講義III",
    "section": "傾向スコア・マッチングの手順",
    "text": "傾向スコア・マッチングの手順\n割り当てメカニズムを仮定\n\n\n\\[Pr(\\text{処置}) \\propto \\beta_0 + \\beta_1 \\cdot \\text{年齢} + \\beta_2 \\cdot \\text{教育}\\]\n\n参考）教育水準\n\n1：小\n2：中\n3：高\n4：専\n5：大\n6：院\n\n\n\n\n\n\n\n\n\n\n\nID\n年齢\n教育\n処置\n結果\n　\nID\n年齢\n教育\n処置\n結果\n\n\n\n\n1\n29\n6\n0\n6\n\n13\n57\n3\n0\n4\n\n\n2\n41\n5\n0\n3\n\n14\n25\n6\n1\n5\n\n\n3\n31\n6\n1\n7\n\n15\n55\n2\n1\n9\n\n\n4\n39\n6\n0\n5\n\n16\n48\n6\n0\n2\n\n\n5\n53\n5\n0\n6\n\n17\n23\n4\n0\n2\n\n\n6\n59\n5\n0\n1\n\n18\n34\n5\n1\n4\n\n\n7\n37\n3\n1\n8\n\n19\n42\n5\n1\n9\n\n\n8\n44\n2\n0\n4\n\n20\n23\n3\n0\n4\n\n\n9\n51\n2\n0\n2\n\n21\n22\n3\n1\n8\n\n\n10\n59\n1\n1\n8\n\n22\n49\n5\n0\n9\n\n\n11\n21\n5\n1\n4\n\n23\n45\n3\n1\n6\n\n\n12\n24\n2\n1\n6\n\n24\n33\n5\n0\n8"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの算出",
    "href": "slide/matching.html#傾向スコアの算出",
    "title": "方法論特殊講義III",
    "section": "傾向スコアの算出",
    "text": "傾向スコアの算出\n傾向スコアの算出\n\nPS_Fit &lt;- glm(処置 ~ 年齢 + 学歴, data = データ, family = binomial(\"logit\"))\nsummary(PS_Fit)\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  3.839 (2.364) \n                \n                \n                  Age        \n                  -0.059 (0.039)\n                \n                \n                  Edu        \n                  -0.420 (0.304)\n                \n                \n                  Num.Obs.   \n                  24            \n                \n                \n                  AIC        \n                  35.5          \n                \n                \n                  F          \n                  1.486         \n                \n        \n      \n    \n\n\n\n予測確率の抽出\n\nPS_Fit$fitted.value\n\n        1         2         3         4         5         6         7         8 \n0.4057364 0.3393856 0.3777795 0.2751913 0.2025844 0.1515735 0.6006657 0.6028218 \n        9        10        11        12        13        14        15        16 \n0.5016153 0.4891956 0.6242461 0.8307399 0.3174741 0.4633432 0.4431796 0.1829360 \n       17        18        19        20        21        22        23        24 \n0.6921133 0.4365297 0.3263554 0.7737818 0.7838885 0.2431492 0.4847003 0.4510136"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの算出-1",
    "href": "slide/matching.html#傾向スコアの算出-1",
    "title": "方法論特殊講義III",
    "section": "傾向スコアの算出",
    "text": "傾向スコアの算出\n傾向スコアの抽出\n\n\n\nデータ$PS &lt;- PS_Fit$fitted.value\n\n\n\n\n\n\n\n\n\n\nID\n年齢\n教育\n処置\n結果\nPS\n　\nID\n年齢\n教育\n処置\n結果\nPS\n\n\n\n\n1\n29\n6\n0\n6\n0.406\n\n13\n57\n3\n0\n4\n0.317\n\n\n2\n41\n5\n0\n3\n0.339\n\n14\n25\n6\n1\n5\n0.463\n\n\n3\n31\n6\n1\n7\n0.378\n\n15\n55\n2\n1\n9\n0.443\n\n\n4\n39\n6\n0\n5\n0.275\n\n16\n48\n6\n0\n2\n0.183\n\n\n5\n53\n5\n0\n6\n0.203\n\n17\n23\n4\n0\n2\n0.692\n\n\n6\n59\n5\n0\n1\n0.152\n\n18\n34\n5\n1\n4\n0.437\n\n\n7\n37\n3\n1\n8\n0.601\n\n19\n42\n5\n1\n9\n0.326\n\n\n8\n44\n2\n0\n4\n0.603\n\n20\n23\n3\n0\n4\n0.774\n\n\n9\n51\n2\n0\n2\n0.502\n\n21\n22\n3\n1\n8\n0.784\n\n\n10\n59\n1\n1\n8\n0.489\n\n22\n49\n5\n0\n9\n0.243\n\n\n11\n21\n5\n1\n4\n0.624\n\n23\n45\n3\n1\n6\n0.485\n\n\n12\n24\n2\n1\n6\n0.831\n\n24\n33\n5\n0\n8\n0.451"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの算出-2",
    "href": "slide/matching.html#傾向スコアの算出-2",
    "title": "方法論特殊講義III",
    "section": "傾向スコアの算出",
    "text": "傾向スコアの算出\n\n\nATT: 傾向スコアが最も近い統制群を割り当てる\n\n復元マッチングの例\n\n\n\n\n\n\n\n\n\n\n処置群\n　\n統制群\n差分\n\n\nID\n結果\nPS\nID\n結果\nPS\n\n\n\n\n3\n7\n0.378\n\n1\n6\n0.406\n1\n\n\n7\n8\n0.601\n\n8\n4\n0.603\n4\n\n\n10\n8\n0.489\n\n9\n2\n0.502\n6\n\n\n11\n4\n0.624\n\n8\n4\n0.603\n0\n\n\n12\n6\n0.831\n\n20\n4\n0.774\n2\n\n\n14\n5\n0.463\n\n24\n8\n0.451\n-3\n\n\n15\n9\n0.443\n\n24\n8\n0.451\n1\n\n\n18\n4\n0.437\n\n24\n8\n0.451\n-4\n\n\n19\n9\n0.326\n\n13\n4\n0.317\n5\n\n\n21\n8\n0.784\n\n20\n4\n0.774\n4\n\n\n23\n6\n0.485\n\n9\n2\n0.502\n4\n\n\n\n差分の平均値 (ATT): 1.818"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの算出-3",
    "href": "slide/matching.html#傾向スコアの算出-3",
    "title": "方法論特殊講義III",
    "section": "傾向スコアの算出",
    "text": "傾向スコアの算出\n\n\nATC: 傾向スコアが最も近い処置群を割り当てる\n\n\n\n\n\n\n\n\n\n処置群\n　\n統制群\n差分\n\n\nID\n結果\nPS\nID\n結果\nPS\n\n\n\n\n3\n7\n0.378\n\n1\n6\n0.406\n1\n\n\n19\n9\n0.326\n\n2\n3\n0.339\n6\n\n\n19\n9\n0.326\n\n4\n5\n0.275\n4\n\n\n19\n9\n0.326\n\n5\n6\n0.203\n3\n\n\n19\n9\n0.326\n\n6\n1\n0.152\n8\n\n\n7\n8\n0.601\n\n8\n4\n0.603\n4\n\n\n10\n8\n0.489\n\n9\n2\n0.502\n6\n\n\n19\n9\n0.326\n\n13\n4\n0.317\n5\n\n\n19\n9\n0.326\n\n16\n2\n0.183\n7\n\n\n11\n4\n0.624\n\n17\n2\n0.692\n2\n\n\n21\n8\n0.784\n\n20\n4\n0.774\n4\n\n\n19\n9\n0.326\n\n22\n9\n0.243\n0\n\n\n15\n9\n0.443\n\n24\n8\n0.451\n1\n\n\n\n差分の平均値 (ATC): 3.923"
  },
  {
    "objectID": "slide/matching.html#傾向スコアの算出-4",
    "href": "slide/matching.html#傾向スコアの算出-4",
    "title": "方法論特殊講義III",
    "section": "傾向スコアの算出",
    "text": "傾向スコアの算出\nATE: ATTとATCの加重平均\n\\[\\begin{align}\\text{ATE} & = \\frac{N_\\text{Treat}}{N_\\text{All}}\\text{ATT} + \\frac{N_\\text{Control}}{N_\\text{All}}\\text{ATC} \\\\ & = \\frac{11}{24} 1.818 + \\frac{13}{24} 3.923 = 2.958\\end{align}\\]\n\n# 第1引数は平均値を求める値のベクトル、第2引数は重みのベクトル\n# 重みは合計1になるように c(0.4583333, 0.5416667) でもOK\nweighted.mean(c(1.818, 3.923), c(11, 13))\n\n[1] 2.958208"
  },
  {
    "objectID": "slide/matching.html#処置を受ける確率の計算",
    "href": "slide/matching.html#処置を受ける確率の計算",
    "title": "方法論特殊講義III",
    "section": "処置を受ける確率の計算",
    "text": "処置を受ける確率の計算\n処置を受ける確率 = 傾向スコア\n\n一般的にはロジスティック/プロビット回帰分析が使われる\nただし、確率が予測できるなら他の手法でも良い\n\nCovariate Balancing Propensity Score\nEntropy Balancing\nNeural Network\nSupport Vector Machine（SVM）\nRandom Forest（RF）など\n\n\n\n\n複数の手法を組み合わせる(= ensemble)することも可能\n\n\\(\\rightarrow\\) Super Learner Algorithm"
  },
  {
    "objectID": "slide/matching.html#傾向スコアのもう一つの使い方",
    "href": "slide/matching.html#傾向スコアのもう一つの使い方",
    "title": "方法論特殊講義III",
    "section": "傾向スコアのもう一つの使い方",
    "text": "傾向スコアのもう一つの使い方\nIPW: Inverse Probability Weighting (Rubin 1985)\n\n「逆確率重み付け」と訳される\n実際に処置を受けた( \\(T_i = 1\\) )にもかかわらず、処置を受ける傾向が 小さい場合は分析において大きい重み\n\n傾向スコアを重み変数として用いる。\n\\(e_i\\) が1または0に近い場合、一部のケースに非常に大きい重みを付け ることになるため、注意が必要\n\n\n\\[w_i = \\begin{cases}\\frac{1}{e_i} & \\text{ if } T_i = 1, \\\\ \\frac{1}{1 - e_i} & \\text{ if } T_i = 0.\\end{cases}\\]\n\n\\(e_i\\) : \\(i\\) の傾向スコア\n\\(T_i\\) : \\(i\\) の処置有無 ( \\(T_i \\in \\{0, 1\\}\\) )"
  },
  {
    "objectID": "slide/matching.html#傾向スコアのもう一つの使い方-1",
    "href": "slide/matching.html#傾向スコアのもう一つの使い方-1",
    "title": "方法論特殊講義III",
    "section": "傾向スコアのもう一つの使い方",
    "text": "傾向スコアのもう一つの使い方\nIPW: Inverse Probability Weighting (Rubin 1985)\n\n「逆確率重み付け」と訳される\n実際に処置を受けた( \\(T_i = 1\\) )にもかかわらず、処置を受ける傾向が 小さい場合は分析において大きい重み\n\n傾向スコアを重み変数として用いる。\n\\(e_i\\) が1または0に近い場合、一部のケースに非常に大きい重みを付け ることになるため、注意が必要\n\n\n\\[w_i = T_i \\frac{1}{e_i} + (1 - T_i) \\frac{1}{1 - e_i}.\\]\n\n\\(e_i\\) : \\(i\\) の傾向スコア\n\\(T_i\\) : \\(i\\) の処置有無 ( \\(T_i \\in \\{0, 1\\}\\) )"
  },
  {
    "objectID": "slide/matching.html#ipw-の考え方",
    "href": "slide/matching.html#ipw-の考え方",
    "title": "方法論特殊講義III",
    "section": "IPW の考え方",
    "text": "IPW の考え方\n\n\n\n\n\n\n\n\n\n\nID (i)\nZi\nTi\nY0, i\nY1, i\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\n条件付き独立の例のデータ（matching_data3.csv）\n\n\\(Pr(Z = 0) = 0.4\\) 、 \\(Pr(Z = 1) = 0.6\\)\n\\(Z = 0\\) の場合\n\n\\(Pr(T = 0) = 0.5\\) 、 \\(Pr(T = 1) = 0.5\\)\n\n\\(Z = 1\\) の場合\n\n\\(Pr(T = 0) = 0.25\\) 、 \\(Pr(T = 1) = 0.75\\)\n\n観察されたデータからは約0.1の処置効果が推定されるが、本当の処置効果は0"
  },
  {
    "objectID": "slide/matching.html#ipwの考え方",
    "href": "slide/matching.html#ipwの考え方",
    "title": "方法論特殊講義III",
    "section": "IPWの考え方",
    "text": "IPWの考え方"
  },
  {
    "objectID": "slide/matching.html#他の考え方",
    "href": "slide/matching.html#他の考え方",
    "title": "方法論特殊講義III",
    "section": "他の考え方",
    "text": "他の考え方\n\n\n\n\n\n\n\n\n\n\nID (i)\nZi\nTi\nY0, i\nY1, i\nei\nWi\n\n\n\n\n1\n0\n0\n0\n?\n0.50\n2.00\n\n\n2\n0\n0\n1\n?\n0.50\n2.00\n\n\n3\n0\n0\n0\n?\n0.50\n2.00\n\n\n4\n0\n0\n0\n?\n0.50\n2.00\n\n\n5\n0\n1\n?\n0\n0.50\n\n\n\n6\n0\n1\n?\n0\n0.50\n\n\n\n7\n0\n1\n?\n0\n0.50\n\n\n\n8\n0\n1\n?\n1\n0.50\n\n\n\n9\n1\n0\n1\n?\n0.75\n4.00\n\n\n10\n1\n0\n1\n?\n0.75\n4.00\n\n\n11\n1\n0\n0\n?\n0.75\n4.00\n\n\n12\n1\n1\n?\n1\n0.75\n\n\n\n13\n1\n1\n?\n1\n0.75\n\n\n\n14\n1\n1\n?\n1\n0.75\n\n\n\n15\n1\n1\n?\n1\n0.75\n\n\n\n16\n1\n1\n?\n1\n0.75\n\n\n\n17\n1\n1\n?\n1\n0.75\n\n\n\n18\n1\n1\n?\n0\n0.75\n\n\n\n19\n1\n1\n?\n0\n0.75\n\n\n\n20\n1\n1\n?\n0\n0.75\n\n\n\n\n\n\n\n\n\nもし、全ケースが統制群なら?\n\n\\(Z = 0\\) の統制群は4ケース（ID = 1, 2, 3, 4）\n\\(Z = 0\\) は全部で8ケース（2倍）\n\\(\\rightarrow\\) ケース1〜4の重みを2倍に（\\(W = 2\\)）\n\n\n\n\\(Z = 1\\) の統制群は3ケース（ID = 9, 10, 11）\n\\(Z = 1\\) は全部で12ケース（4倍）\n\\(\\rightarrow\\) ケース9〜11の重みを4倍に（\\(W = 4\\)）"
  },
  {
    "objectID": "slide/matching.html#他の考え方-1",
    "href": "slide/matching.html#他の考え方-1",
    "title": "方法論特殊講義III",
    "section": "他の考え方",
    "text": "他の考え方\n\n\n\n\n\n\n\n\n\n\nID (i)\nZi\nTi\nY0, i\nY1, i\nei\nWi\n\n\n\n\n1\n0\n0\n0\n?\n0.50\n\n\n\n2\n0\n0\n1\n?\n0.50\n\n\n\n3\n0\n0\n0\n?\n0.50\n\n\n\n4\n0\n0\n0\n?\n0.50\n\n\n\n5\n0\n1\n?\n0\n0.50\n2.00\n\n\n6\n0\n1\n?\n0\n0.50\n2.00\n\n\n7\n0\n1\n?\n0\n0.50\n2.00\n\n\n8\n0\n1\n?\n1\n0.50\n2.00\n\n\n9\n1\n0\n1\n?\n0.75\n\n\n\n10\n1\n0\n1\n?\n0.75\n\n\n\n11\n1\n0\n0\n?\n0.75\n\n\n\n12\n1\n1\n?\n1\n0.75\n1.33\n\n\n13\n1\n1\n?\n1\n0.75\n1.33\n\n\n14\n1\n1\n?\n1\n0.75\n1.33\n\n\n15\n1\n1\n?\n1\n0.75\n1.33\n\n\n16\n1\n1\n?\n1\n0.75\n1.33\n\n\n17\n1\n1\n?\n1\n0.75\n1.33\n\n\n18\n1\n1\n?\n0\n0.75\n1.33\n\n\n19\n1\n1\n?\n0\n0.75\n1.33\n\n\n20\n1\n1\n?\n0\n0.75\n1.33\n\n\n\n\n\n\n\n\nもし、全ケースが処置群なら?\n\n\\(Z = 0\\) の処置群は4ケース（ID = 5, 6, 7, 8）\n\\(Z = 0\\) は全部で8ケース（2倍）\n\\(\\rightarrow\\) ケース5〜8の重みを2倍に（\\(W = 2\\)）\n\n\n\n\\(Z = 1\\) の処置群は9ケース（ID = 12, 13, 14, … 20）\n\\(Z = 1\\) は全部で12ケース（1.333倍）\n\\(\\rightarrow\\) ケース12〜20の重みを1.333倍に（\\(W = 1.333\\)）"
  },
  {
    "objectID": "slide/matching.html#他の考え方-2",
    "href": "slide/matching.html#他の考え方-2",
    "title": "方法論特殊講義III",
    "section": "他の考え方",
    "text": "他の考え方\n\n\n\n\n\n\n\n\n\n\nID (i)\nZi\nTi\nY0, i\nY1, i\nei\nWi\n\n\n\n\n1\n0\n0\n0\n?\n0.50\n2.00\n\n\n2\n0\n0\n1\n?\n0.50\n2.00\n\n\n3\n0\n0\n0\n?\n0.50\n2.00\n\n\n4\n0\n0\n0\n?\n0.50\n2.00\n\n\n5\n0\n1\n?\n0\n0.50\n2.00\n\n\n6\n0\n1\n?\n0\n0.50\n2.00\n\n\n7\n0\n1\n?\n0\n0.50\n2.00\n\n\n8\n0\n1\n?\n1\n0.50\n2.00\n\n\n9\n1\n0\n1\n?\n0.75\n4.00\n\n\n10\n1\n0\n1\n?\n0.75\n4.00\n\n\n11\n1\n0\n0\n?\n0.75\n4.00\n\n\n12\n1\n1\n?\n1\n0.75\n1.33\n\n\n13\n1\n1\n?\n1\n0.75\n1.33\n\n\n14\n1\n1\n?\n1\n0.75\n1.33\n\n\n15\n1\n1\n?\n1\n0.75\n1.33\n\n\n16\n1\n1\n?\n1\n0.75\n1.33\n\n\n17\n1\n1\n?\n1\n0.75\n1.33\n\n\n18\n1\n1\n?\n0\n0.75\n1.33\n\n\n19\n1\n1\n?\n0\n0.75\n1.33\n\n\n20\n1\n1\n?\n0\n0.75\n1.33\n\n\n\n\n\n\n\n\n\n統制群におけるWの和: 20\n処置群におけるWの和: 20\n\\(\\rightarrow\\) 各群におけるWの和はサンプルサイズと一致する\n\\(\\rightarrow\\) 全サンプルが統制/処置群の場合の結果変数の期待値を計算（加重平均）"
  },
  {
    "objectID": "slide/matching.html#他の考え方-3",
    "href": "slide/matching.html#他の考え方-3",
    "title": "方法論特殊講義III",
    "section": "他の考え方",
    "text": "他の考え方\n\n\n\n\n\n\n\n\n\n\nID (i)\nZi\nTi\nY0, i\nY1, i\nei\nWi\n\n\n\n\n1\n0\n0\n0\n?\n0.50\n2.00\n\n\n2\n0\n0\n1\n?\n0.50\n2.00\n\n\n3\n0\n0\n0\n?\n0.50\n2.00\n\n\n4\n0\n0\n0\n?\n0.50\n2.00\n\n\n5\n0\n1\n?\n0\n0.50\n2.00\n\n\n6\n0\n1\n?\n0\n0.50\n2.00\n\n\n7\n0\n1\n?\n0\n0.50\n2.00\n\n\n8\n0\n1\n?\n1\n0.50\n2.00\n\n\n9\n1\n0\n1\n?\n0.75\n4.00\n\n\n10\n1\n0\n1\n?\n0.75\n4.00\n\n\n11\n1\n0\n0\n?\n0.75\n4.00\n\n\n12\n1\n1\n?\n1\n0.75\n1.33\n\n\n13\n1\n1\n?\n1\n0.75\n1.33\n\n\n14\n1\n1\n?\n1\n0.75\n1.33\n\n\n15\n1\n1\n?\n1\n0.75\n1.33\n\n\n16\n1\n1\n?\n1\n0.75\n1.33\n\n\n17\n1\n1\n?\n1\n0.75\n1.33\n\n\n18\n1\n1\n?\n0\n0.75\n1.33\n\n\n19\n1\n1\n?\n0\n0.75\n1.33\n\n\n20\n1\n1\n?\n0\n0.75\n1.33\n\n\n\n\n\n\n\n\n\n統制群の加重平均\n\n\\(0 \\cdot 2 + 1 \\cdot 2 + 0 \\cdot 2 + 0 \\cdot 2 + \\dots + 0 \\cdot 4\\)\n\\(\\mathbb{E}^w[Y_0] = 10\\)\n\n処置群の加重平均\n\n\\(0 \\cdot 2 + 0 \\cdot 2 + 0 \\cdot 2 + 1 \\cdot 2 + \\dots + 0 \\cdot 1.33\\)\n\\(\\mathbb{E}^w[Y_1] = 10\\)\n\n\n\n\\[\\mathbb{E}^w[Y_1] - \\mathbb{E}^w[Y_0] = 0\\]"
  },
  {
    "objectID": "slide/matching.html#共変量の選択-1",
    "href": "slide/matching.html#共変量の選択-1",
    "title": "方法論特殊講義III",
    "section": "共変量の選択",
    "text": "共変量の選択\n共変量選択の基準は (星野 2009; Imbens and Rubin 2015など)\n\n処置変数と結果変数、両方と連関があること\n\nOVBと関係\n\n処置前変数と処置後変数の区別\n\n処置変数に時間的に先行しているか否か\n\n処置前変数 (pre-treatment variable) は必ず投入する\n処置後変数 (post-treatment variable) は目的による\n\nというものの、基本的に投入しない\n応答変数よりも時間的に後なら絶対に投入しない"
  },
  {
    "objectID": "slide/matching.html#共変量の選択-2",
    "href": "slide/matching.html#共変量の選択-2",
    "title": "方法論特殊講義III",
    "section": "共変量の選択",
    "text": "共変量の選択\nVanderWeele (2019) のmodified disjunctive cause criterion\n\n処置変数と応答変数どちらかの原因となる変数\n処置変数と応答変数両方の原因となる変数\n操作変数は共変量として投入しない\n上記の基準を満たさない場合でも、観察されていない共変量の代理変数は統制しても良い\n\nしかし、慎重に選択しないとバイアスが拡大\n2.の該当する変数の代理変数が望ましい\n\n\n\n\n詳細はhttps://www.slideshare.net/tintstyle/ss-141543274を参照"
  },
  {
    "objectID": "slide/matching.html#ダイアグラムを使った例",
    "href": "slide/matching.html#ダイアグラムを使った例",
    "title": "方法論特殊講義III",
    "section": "ダイアグラムを使った例",
    "text": "ダイアグラムを使った例\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(T \\rightarrow Y\\)の効果は11\n\\(Z\\): \\(T\\)と\\(Y\\)の原因 \\(\\leftarrow\\) 投入\n\\(A\\): 操作変数 \\(\\leftarrow\\) 除外\n\\(X\\): \\(Y\\)の原因 \\(\\leftarrow\\) 投入\n\\(V\\): \\(T\\)の結果 \\(\\leftarrow\\) 除外\n\\(W\\)は…?"
  },
  {
    "objectID": "slide/matching.html#ダイアグラムを使った例-1",
    "href": "slide/matching.html#ダイアグラムを使った例-1",
    "title": "方法論特殊講義III",
    "section": "ダイアグラムを使った例",
    "text": "ダイアグラムを使った例\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(T \\rightarrow Y\\): 直接効果\n\\(T \\rightarrow W \\rightarrow Y\\): 間接効果\n\n\\(W\\)は中間変数（mediate variable）\n\n因果推論では主に全効果 (total effect) に関心があるため\\(W\\)は投入しない\n\n全効果: 直接効果 + 間接効果\n\\(T\\)が変動したら\\(W\\)も必ず変わるため、\\(T\\)のみの効果はあまり意味なし\n直接効果のみ推定する場合、\\(W\\)も統制\n\n例) 就職市場における人種差別の例\n\n\n結論: \\(Z\\)と\\(X\\)のみ統制\n\n実は\\(X\\)は入れなくてもOK"
  },
  {
    "objectID": "slide/matching.html#ダイアグラムのツール",
    "href": "slide/matching.html#ダイアグラムのツール",
    "title": "方法論特殊講義III",
    "section": "ダイアグラムのツール",
    "text": "ダイアグラムのツール\nDAGitty — draw and analyze causal diagrams\n\nウェーブページ or Rパッケージ{dagitty}\n\nhttp://www.dagitty.net/\n\n\n\n\n\npacman::p_load(ggdag)\nDAG1 &lt;- dagitty(\n  \"dag {\n  T -&gt; Y\n  T -&gt; W -&gt; Y\n  T &lt;- Z -&gt; Y\n  A -&gt; T\n  X -&gt; Y\n  T -&gt; V\n  }\"\n)\n\n\n\n# Total Effect推定のための共変量\nadjustmentSets(DAG1, \n               exposure = \"T\", outcome = \"Y\",\n               effect = \"total\")\n\n{ Z }\n\n# Direct Effect推定のための共変量\nadjustmentSets(DAG1, \n               exposure = \"T\", outcome = \"Y\",\n               effect = \"direct\")\n\n{ W, Z }"
  },
  {
    "objectID": "slide/matching.html#ダイアグラムのツール-1",
    "href": "slide/matching.html#ダイアグラムのツール-1",
    "title": "方法論特殊講義III",
    "section": "ダイアグラムのツール",
    "text": "ダイアグラムのツール\n{ggdag}を用いた可視化\n\n詳細は『私たちのR』第22章を参照\n\n\n\n\ncoordinates(DAG1) &lt;- list(\n  x = c(T = 1, Y = 5, Z = 3, W = 3, \n        A = 2, V = 2, X = 4),\n  y = c(T = 2, Y = 2, Z = 3, W = 4, \n        A = 1, V = 4, X = 1)\n)\nggdag(DAG1, stylized = TRUE) +\n  theme_dag_blank()"
  },
  {
    "objectID": "slide/matching.html#実習内容",
    "href": "slide/matching.html#実習内容",
    "title": "方法論特殊講義III",
    "section": "実習内容",
    "text": "実習内容\n\nマッチングの実装: {MatchIt}、{WeightIt}パッケージ\n\n線形回帰分析\n最近傍マッチング（Mahalanobis Matching）\nCEM\n傾向スコアマッチング\nIPW\n\nバランスチェック: {cobalt}パッケージ\n\n標準化差分\nヒストグラム\nQQ Plotなど\n\nマッチング手法間の比較"
  },
  {
    "objectID": "slide/matching.html#実習用データ-lalonde職業訓練と所得",
    "href": "slide/matching.html#実習用データ-lalonde職業訓練と所得",
    "title": "方法論特殊講義III",
    "section": "実習用データ: lalonde（職業訓練と所得）",
    "text": "実習用データ: lalonde（職業訓練と所得）\nlalondeは様々なパッケージがサンプルデータとして提供しているが、本講義では{cobalt}のlalondeデータセットを利用\n\n\n\ndata(\"lalonde\", package = \"cobalt\")で読み込み\n\nその前に{cobalt}パッケージを読み込む\n\n\n\ndata(\"lalonde\", package = \"cobalt\")\nla_df &lt;- as_tibble(lalonde) # tibble構造へ変換\nla_df\n\n# A tibble: 614 × 9\n   treat   age  educ race   married nodegree  re74  re75   re78\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt;    &lt;int&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1    37    11 black        1        1     0     0  9930.\n 2     1    22     9 hispan       0        1     0     0  3596.\n 3     1    30    12 black        0        0     0     0 24909.\n 4     1    27    11 black        0        1     0     0  7506.\n 5     1    33     8 black        0        1     0     0   290.\n 6     1    22     9 black        0        1     0     0  4056.\n 7     1    23    12 black        0        0     0     0     0 \n 8     1    32    11 black        0        1     0     0  8472.\n 9     1    22    16 black        0        0     0     0  2164.\n10     1    33    12 white        1        0     0     0 12418.\n# ℹ 604 more rows\n\n\n\n\n\n\n\n変数名\n説明\n\n\n\n\n1\ntreat\n職業訓練の履修有無\n\n\n2\nage\n年齢\n\n\n3\neduc\n教育年数\n\n\n4\nrace\n人種\n\n\n5\nmarried\n結婚有無\n\n\n6\nnodegree\n学位有無\n\n\n7\nre74\n1974年の所得\n\n\n8\nre75\n1975年の所得\n\n\n9\nre78\n1978年の所得\n\n\n\n\n\n\n\n\n\n\nLalonde, Robert. 1984. “Evaluating the Econometric Evaluations of Training Programs with Experimental Data,” American Economic Review, 76 (4): 604-620."
  },
  {
    "objectID": "slide/rdd.html#回帰不連続デザイン-1",
    "href": "slide/rdd.html#回帰不連続デザイン-1",
    "title": "方法論特殊講義III",
    "section": "回帰不連続デザイン",
    "text": "回帰不連続デザイン\nRegression Discontinuity Design\n\nThistlewaite and Campbell (1960) で紹介\n「RDD」と呼ばれる場合が多い\n\n「かいきふれんぞくでざいん」は長すぎる\n\nある点 (閾値)を超えることで処置を受けるか否かが決まる\n\n例) 人口によって選挙制度が決まる場合 (0 = 多数代表制; 1 = 比例代表制)\n\n\n\\[\nT_i = \\begin{cases}\n   0 & \\text{ if } & \\text{Population} &lt; 3500, \\\\\n   1 & \\text{ if } & \\text{Population} \\geq 3500.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slide/rdd.html#rddの考え方",
    "href": "slide/rdd.html#rddの考え方",
    "title": "方法論特殊講義III",
    "section": "RDDの考え方",
    "text": "RDDの考え方\n比例代表制と多数代表制の投票率の比較\n\n選挙制度は国レベルで異なるため国家間比較になる\n国固有の文脈により単純比較は困難\nフランスの場合、同一国家、レベルの選挙内で制度が異なる\n\n国固有の政治的文脈はコントロールされる\n\nしかし、人口が多いところは都市部が多いし、投票率の低い都市部の特徴により、比例代表制の投票率は過小評価される可能性\n\n「都市化度」という交絡要因が残存している\n\n人口が3450人と村と3550人の村なら「都市化度」はほぼ同じなのでは …?\n\nほぼ同条件で選挙制度だけが異なる状況\n\\(\\rightarrow\\) 交絡要因が除去されているため、因果推論が可能に"
  },
  {
    "objectID": "slide/rdd.html#rddの考え方-1",
    "href": "slide/rdd.html#rddの考え方-1",
    "title": "方法論特殊講義III",
    "section": "RDDの考え方",
    "text": "RDDの考え方\n比例代表制と多数代表制の投票率の比較（架空データ）\n\n人口が多くなるにつれ、投票率が減少傾向"
  },
  {
    "objectID": "slide/rdd.html#rddの考え方-2",
    "href": "slide/rdd.html#rddの考え方-2",
    "title": "方法論特殊講義III",
    "section": "RDDの考え方",
    "text": "RDDの考え方\n比例代表制と多数代表制の投票率の比較\n\n比例代表制は投票率を低下する制度だと解釈されてしまう"
  },
  {
    "objectID": "slide/rdd.html#rddの考え方-3",
    "href": "slide/rdd.html#rddの考え方-3",
    "title": "方法論特殊講義III",
    "section": "RDDの考え方",
    "text": "RDDの考え方\n比例代表制と多数代表制の投票率の比較 (架空データ)\n\n人口3500で分けてみると…"
  },
  {
    "objectID": "slide/rdd.html#rddの考え方-4",
    "href": "slide/rdd.html#rddの考え方-4",
    "title": "方法論特殊講義III",
    "section": "RDDの考え方",
    "text": "RDDの考え方\n比例代表制と多数代表制の投票率の比較 (架空データ)\n\n人口3500で分けてみると…\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n                (2)\n              \n        \n        \n        \n                \n                  切片              \n                  59.650 \n                  59.939 \n                \n                \n                                    \n                  (0.478)\n                  (0.453)\n                \n                \n                  人口              \n                  -0.001 \n                  -0.002 \n                \n                \n                                    \n                  (0.000)\n                  (0.000)\n                \n                \n                  人口3500以上ダミー\n                         \n                  6.561  \n                \n                \n                                    \n                         \n                  (0.831)\n                \n                \n                  Num.Obs.          \n                  500    \n                  500    \n                \n                \n                  R2                \n                  0.338  \n                  0.411  \n                \n                \n                  R2 Adj.           \n                  0.336  \n                  0.409  \n                \n                \n                  RMSE              \n                  5.27   \n                  4.97"
  },
  {
    "objectID": "slide/rdd.html#つのrdd",
    "href": "slide/rdd.html#つのrdd",
    "title": "方法論特殊講義III",
    "section": "2つのRDD",
    "text": "2つのRDD\n異なる割当メカニズムを想定した2つのRDD\n\n本講義で解説するのはSRDのみ\n\n\nSharp Regression Discontinuity (SRD)\n\n強制変数 (running variable) が閾値 (cut point) を超えると必ず処置を受ける。\nもっとも単純明快な RDD。実際、多く使われている。\n例) 人口と選挙制度\n\nFuzzy Regression Discontinuity (FRD)\n\n強制変数が閾値を超えると、処置を受ける確率が高まる。\n操作変数法の理解が必要 (実例もあまり見ないような . . . )\n例) 入試 (一定点数を超えると合格する可能性がある)"
  },
  {
    "objectID": "slide/rdd.html#割当メカニズムの比較",
    "href": "slide/rdd.html#割当メカニズムの比較",
    "title": "方法論特殊講義III",
    "section": "割当メカニズムの比較",
    "text": "割当メカニズムの比較"
  },
  {
    "objectID": "slide/rdd.html#rddの仮定",
    "href": "slide/rdd.html#rddの仮定",
    "title": "方法論特殊講義III",
    "section": "RDDの仮定",
    "text": "RDDの仮定\nMoscoe and Barninnghausen (2015)\n\n閾値周辺において交絡要因が変化しないこと\n\n飲酒年齢の事故の例: 20歳になった瞬間、アルコールを分解する酵素が劇的に増加するような悲しい現象は起きない\n\n閾値のルールが明確であり、既知であること\n\nSRDの場合、閾値は制度に起因するものが多いため、問題になるケースは少ない\n\n強制変数が閾値周辺において連続であること\n\n閾値周辺において強制変数の操作が行われていない\n密度検定 (density test)で検定可能\n\n潜在的結果が閾値周辺において連続であること"
  },
  {
    "objectID": "slide/rdd.html#パラメトリック推定方法",
    "href": "slide/rdd.html#パラメトリック推定方法",
    "title": "方法論特殊講義III",
    "section": "パラメトリック推定方法",
    "text": "パラメトリック推定方法\n（非）線形回帰分析による推定\n\nフランス地方議会選挙の例\n\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\beta_1 \\mbox{Population} + \\rho \\mathbf{I}(\\mbox{Population} \\geq 3500)\\]\n\n推定されるパラメータは \\(\\beta_0, \\beta_1, \\rho\\) (+ 誤差項 ( \\(\\varepsilon\\) )の分散)\n\n\\(\\mathbf{I}(\\cdot)\\) は指示関数 (indicator function)\nカッコ内の条件が満たされたら1、それ以外の場合は0を返す関数\n\\(1(\\cdot)\\) と表現する場合もあり\n\n要は、処置変数 (=ダミー変数) を投入し、強制変数を統制した線形回帰モデル"
  },
  {
    "objectID": "slide/rdd.html#パラメトリック推定の例",
    "href": "slide/rdd.html#パラメトリック推定の例",
    "title": "方法論特殊講義III",
    "section": "パラメトリック推定の例",
    "text": "パラメトリック推定の例\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\beta_1 \\mbox{Population} + \\rho \\mathbf{I}(\\mbox{Population} \\geq 3500)\\]\n\n\\(\\rho\\) = 制度が投票率に与える効果 (因果効果)"
  },
  {
    "objectID": "slide/rdd.html#非線形の場合",
    "href": "slide/rdd.html#非線形の場合",
    "title": "方法論特殊講義III",
    "section": "非線形の場合",
    "text": "非線形の場合\n\n強制変数の二乗、三乗、… を投入\n\nどこまで多項式にするかはモデル比較などを通じて分析者が決める\nR2、 \\(F\\) 統計量、AIC、BIC、WAIC、LOOなど\n\nモデルにおけるバイアス—分散のトレードオフ関係\n\nHigh-order: バイアス \\(\\downarrow\\) & 分散 \\(\\uparrow\\)\n\nHigh-orderは直感に反する推定値が得られる場合も(Gelman and Imbens 2019)\n\nnoisy estimates\nsensitivity to the degree of the polynomial\npoor coverage of confidence intervals"
  },
  {
    "objectID": "slide/rdd.html#非線形回帰の例-rdd_data2.csv",
    "href": "slide/rdd.html#非線形回帰の例-rdd_data2.csv",
    "title": "方法論特殊講義III",
    "section": "非線形回帰の例 (rdd_data2.csv)",
    "text": "非線形回帰の例 (rdd_data2.csv)\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\rho \\mathbf{I}(\\mbox{X} \\geq 0) + \\beta_1 \\mbox{X}\\]"
  },
  {
    "objectID": "slide/rdd.html#非線形回帰の例",
    "href": "slide/rdd.html#非線形回帰の例",
    "title": "方法論特殊講義III",
    "section": "非線形回帰の例",
    "text": "非線形回帰の例\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\rho \\mathbf{I}(\\mbox{X} \\geq 0) + \\beta_1 X + \\beta_2 X^2\\]"
  },
  {
    "objectID": "slide/rdd.html#非線形回帰の例-1",
    "href": "slide/rdd.html#非線形回帰の例-1",
    "title": "方法論特殊講義III",
    "section": "非線形回帰の例",
    "text": "非線形回帰の例\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\rho \\mathbf{I}(\\mbox{X} \\geq 0) + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3\\]"
  },
  {
    "objectID": "slide/rdd.html#非線形回帰の例-2",
    "href": "slide/rdd.html#非線形回帰の例-2",
    "title": "方法論特殊講義III",
    "section": "非線形回帰の例",
    "text": "非線形回帰の例\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\rho \\mathbf{I}(\\mbox{X} \\geq 0) + \\beta_1 X + \\beta_2 X^2 + \\beta_3 X^3 + \\beta_4 X^4\\]"
  },
  {
    "objectID": "slide/rdd.html#非線形回帰の例-3",
    "href": "slide/rdd.html#非線形回帰の例-3",
    "title": "方法論特殊講義III",
    "section": "非線形回帰の例",
    "text": "非線形回帰の例\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\rho \\mathbf{I}(\\mbox{X} \\geq 0) + \\beta_1 X + \\beta_2 X^2 + \\dots + \\beta_5 X^5\\]"
  },
  {
    "objectID": "slide/rdd.html#非線形回帰の例-4",
    "href": "slide/rdd.html#非線形回帰の例-4",
    "title": "方法論特殊講義III",
    "section": "非線形回帰の例",
    "text": "非線形回帰の例\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\rho \\mathbf{I}(\\mbox{X} \\geq 0) + \\beta_1 X + \\beta_2 X^2 + \\dots + \\beta_6 X^6\\]"
  },
  {
    "objectID": "slide/rdd.html#非線形回帰の例-5",
    "href": "slide/rdd.html#非線形回帰の例-5",
    "title": "方法論特殊講義III",
    "section": "非線形回帰の例",
    "text": "非線形回帰の例\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\rho \\mathbf{I}(\\mbox{X} \\geq 0) + \\beta_1 X + \\beta_2 X^2 + \\dots + \\beta_7 X^7\\]"
  },
  {
    "objectID": "slide/rdd.html#非線形回帰の例-6",
    "href": "slide/rdd.html#非線形回帰の例-6",
    "title": "方法論特殊講義III",
    "section": "非線形回帰の例",
    "text": "非線形回帰の例\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\rho \\mathbf{I}(\\mbox{X} \\geq 0) + \\beta_1 X + \\beta_2 X^2 + \\dots + \\beta_8 X^8\\]"
  },
  {
    "objectID": "slide/rdd.html#非線形回帰の例-7",
    "href": "slide/rdd.html#非線形回帰の例-7",
    "title": "方法論特殊講義III",
    "section": "非線形回帰の例",
    "text": "非線形回帰の例\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\rho \\mathbf{I}(\\mbox{X} \\geq 0) + \\beta_1 X + \\beta_2 X^2 + \\dots + \\beta_9 X^9\\]"
  },
  {
    "objectID": "slide/rdd.html#非線形回帰の例-8",
    "href": "slide/rdd.html#非線形回帰の例-8",
    "title": "方法論特殊講義III",
    "section": "非線形回帰の例",
    "text": "非線形回帰の例\n\\[\\widehat{\\mbox{Turnout}} = \\beta_0 + \\rho \\mathbf{I}(\\mbox{X} \\geq 0) + \\beta_1 X + \\beta_2 X^2 + \\dots + \\beta_{10} X^{10}\\]"
  },
  {
    "objectID": "slide/rdd.html#推定値の変化",
    "href": "slide/rdd.html#推定値の変化",
    "title": "方法論特殊講義III",
    "section": "推定値の変化",
    "text": "推定値の変化"
  },
  {
    "objectID": "slide/rdd.html#調整済み決定係数の変化",
    "href": "slide/rdd.html#調整済み決定係数の変化",
    "title": "方法論特殊講義III",
    "section": "調整済み決定係数の変化",
    "text": "調整済み決定係数の変化"
  },
  {
    "objectID": "slide/rdd.html#閾値周辺で傾きが変化する場合",
    "href": "slide/rdd.html#閾値周辺で傾きが変化する場合",
    "title": "方法論特殊講義III",
    "section": "閾値周辺で傾きが変化する場合",
    "text": "閾値周辺で傾きが変化する場合\n\n単純に\\(\\mathbf{I}(X &gt; c)\\)のみを回帰式に投入することは連続した回帰直線において切片のみが変化するという前提\n回帰直線が連続し、切片のみ変化 (jump) しているため、バイアスが生じうる\n\\(\\rightarrow\\) 交差項を投入することで解決\n\n\\[\\hat{Y} = \\beta_0 + \\beta_1 X + \\rho \\mathbf{I}(X \\geq 3) + \\gamma X \\cdot \\mathbf{I}(X \\geq 3).\\]\n\n\\(\\beta_0 = 3, \\beta_1 = 1, \\rho = 1.5, \\gamma = 2\\) の場合\n\n因果効果は \\(X = 3\\) の場合に生じるため、 \\(1.5 \\cdot \\mathbf{I}(X \\geq 3) + 2 \\cdot 3 \\cdot \\mathbf{I}(X \\geq 3) = 7.5 \\cdot \\mathbf{I}(X \\geq 3)\\)\n\\(\\rightarrow\\) 因果効果は 7.5"
  },
  {
    "objectID": "slide/rdd.html#交互作用の例-rdd_data3.csv",
    "href": "slide/rdd.html#交互作用の例-rdd_data3.csv",
    "title": "方法論特殊講義III",
    "section": "交互作用の例 (rdd_data3.csv)",
    "text": "交互作用の例 (rdd_data3.csv)\n\n交差項なしの処置効果: 11.730\n交差項ありの処置効果: 7.173\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                交差項なし\n                交差項あり\n              \n        \n        \n        \n                \n                  \\(\\beta_0\\)\n                  3.981  \n                  3.028  \n                \n                \n                                \n                  (0.701)\n                  (0.665)\n                \n                \n                  \\(\\beta_1\\)\n                  1.273  \n                  1.029  \n                \n                \n                                \n                  (0.123)\n                  (0.121)\n                \n                \n                  \\(\\rho\\)   \n                  11.730 \n                  0.699  \n                \n                \n                                \n                  (1.519)\n                  (2.305)\n                \n                \n                  \\(\\gamma\\) \n                         \n                  2.158  \n                \n                \n                                \n                         \n                  (0.358)\n                \n                \n                  Num.Obs.      \n                  200    \n                  200    \n                \n                \n                  R2 Adj.       \n                  0.824  \n                  0.851  \n                \n                \n                  F             \n                  467.822\n                  379.750\n                \n                \n                  RMSE          \n                  5.76   \n                  5.29"
  },
  {
    "objectID": "slide/rdd.html#交互作用の例-rdd_data3.csv-1",
    "href": "slide/rdd.html#交互作用の例-rdd_data3.csv-1",
    "title": "方法論特殊講義III",
    "section": "交互作用の例 (rdd_data3.csv)",
    "text": "交互作用の例 (rdd_data3.csv)\n\n交差項なしの処置効果: 11.730\n交差項ありの処置効果: 7.173"
  },
  {
    "objectID": "slide/rdd.html#解釈をより分かりやすくするためには",
    "href": "slide/rdd.html#解釈をより分かりやすくするためには",
    "title": "方法論特殊講義III",
    "section": "解釈をより分かりやすくするためには",
    "text": "解釈をより分かりやすくするためには\n強制変数を閾値で中心化 (centering) する\n\\[\\hat{Y} = \\beta_0 + \\beta_1 X + \\rho \\mathbf{I}(X \\geq 3) + \\gamma X \\cdot \\mathbf{I}(X \\geq 3).\\]\n\n交差項がない場合、因果効果は \\(\\rho\\)\n交差項が含まれている場合、因果効果は \\(\\rho + \\gamma \\cdot c\\)\n\n\\(c\\) は閾値 (cut point)\n\n強制変数 (X) を \\(c\\) で中心化すると …"
  },
  {
    "objectID": "slide/rdd.html#解釈をより分かりやすくするためには-1",
    "href": "slide/rdd.html#解釈をより分かりやすくするためには-1",
    "title": "方法論特殊講義III",
    "section": "解釈をより分かりやすくするためには",
    "text": "解釈をより分かりやすくするためには\n強制変数を閾値で中心化 (centering) する\n\\[\\begin{align}\\hat{Y} & = \\beta_0 + \\beta_1 X^c + \\rho \\mathbf{I}(X^c \\geq 0) + \\gamma X \\cdot \\mathbf{I}(X^c \\geq 0), \\\\ X^c & = X - c.\\end{align}\\]\n\n閾値が0になるため、閾値での因果効果は\n\n\\(\\rho + \\gamma \\cdot 0 = \\rho\\)\n\n\\(\\rho\\) を因果効果として解釈することが可能に\n交差項が含まれていないモデルの場合、閾値で中心化してもしなくても \\(\\rho\\) は同じ\n\n\\(\\rightarrow\\) とりあえず、入れてみる\n\nパッケージで分析する際、中心化は気にしなくても良いが、パッケージを使う前に自分で探索的に分析をしてみよう"
  },
  {
    "objectID": "slide/rdd.html#中心化前の-rho",
    "href": "slide/rdd.html#中心化前の-rho",
    "title": "方法論特殊講義III",
    "section": "中心化前の \\(\\rho\\)",
    "text": "中心化前の \\(\\rho\\)\n\\[\\hat{Y} = \\beta_0 + \\beta_1 X + \\rho \\mathbf{I}(X \\geq 3) + \\gamma X \\cdot \\mathbf{I}(X \\geq 3).\\]"
  },
  {
    "objectID": "slide/rdd.html#中心化後の-rho",
    "href": "slide/rdd.html#中心化後の-rho",
    "title": "方法論特殊講義III",
    "section": "中心化後の \\(\\rho\\)",
    "text": "中心化後の \\(\\rho\\)\n\\[\\hat{Y} = \\beta_0 + \\beta_1 X^c + \\rho \\mathbf{I}(X^c \\geq 0) + \\gamma X \\cdot \\mathbf{I}(X^c \\geq 0).\\]"
  },
  {
    "objectID": "slide/rdd.html#パラメトリック推定の問題点",
    "href": "slide/rdd.html#パラメトリック推定の問題点",
    "title": "方法論特殊講義III",
    "section": "パラメトリック推定の問題点",
    "text": "パラメトリック推定の問題点\n強制変数と応答変数間の関数 (functional form) が正しく設定できるか\n\n閾値は制度などによって決まることが多いため、明確な場合が多い\nモデルが既知ならこれまでのようにパラメトリックな推定が効率的\n\nしかし、強制変数と応答変数間の関数は、ほとんどの場合において未知\nモデルの誤設定 (misspecification) はバイアスの原因になりうる\n例) 多項式モデルの1〜2次項モデルの場合、因果効果が逆転\n\n\n\nノンパラメトリック / セミパラメトリック推定\n\nモデルと全く無関係ではないが、より柔軟な推定方法\n\nノンパラメトリックはモデルを使用しない\n\nモデルの特定が多少間違っても、そこまで大きく問題にならない推定法"
  },
  {
    "objectID": "slide/rdd.html#ノンパラメトリック推定法-1",
    "href": "slide/rdd.html#ノンパラメトリック推定法-1",
    "title": "方法論特殊講義III",
    "section": "ノンパラメトリック推定法",
    "text": "ノンパラメトリック推定法\n閾値（\\(c\\)）から\\(h\\)以上離れているケースは分析から除外\n\n分析対象は\\(c - h \\leq X \\leq c + h\\)のみ\n\n閾値を中心に中心化済みなら\\(−h \\leq X^c \\leq h\\)\n\n\\(h\\)は「バンド幅（bandwidth）」と呼ばれる\n\nバンド幅内のデータのみが対象となるため、局所ATE（LATE; Local ATE）が推定対象\n\n\n\n推定方法\n\nノンパラメトリック: 局所平均（Local Average）\n\n\\(\\mathbb{E}[Y|0 \\leq X^c \\leq h] - \\mathbb{E}[Y|-h \\leq X^c &lt; 0]\\)\n\nセミパラメトリック: 局所回帰分析（Local Linear Regression）\n\n\\(−h \\leq X^c \\leq h\\)の範囲内で交差項を含むカーネル回帰分析\n定番のカーネル関数は三角形（triangular）カーネル関数\n\nカーネル関数が一様（uniform or rectangular）なら線形回帰分析"
  },
  {
    "objectID": "slide/rdd.html#ノンセミパラメトリック推定法",
    "href": "slide/rdd.html#ノンセミパラメトリック推定法",
    "title": "方法論特殊講義III",
    "section": "ノン/セミパラメトリック推定法",
    "text": "ノン/セミパラメトリック推定法\n\\(−h \\leq X^c \\leq h\\)範囲内のデータのみ使用"
  },
  {
    "objectID": "slide/rdd.html#局所平均-rdd_data2.csv",
    "href": "slide/rdd.html#局所平均-rdd_data2.csv",
    "title": "方法論特殊講義III",
    "section": "局所平均 (rdd_data2.csv)",
    "text": "局所平均 (rdd_data2.csv)\n\\(h = 5\\) の場合"
  },
  {
    "objectID": "slide/rdd.html#局所平均-rdd_data2.csv-1",
    "href": "slide/rdd.html#局所平均-rdd_data2.csv-1",
    "title": "方法論特殊講義III",
    "section": "局所平均 (rdd_data2.csv)",
    "text": "局所平均 (rdd_data2.csv)\n\\(h = 3\\) の場合"
  },
  {
    "objectID": "slide/rdd.html#局所平均-rdd_data2.csv-2",
    "href": "slide/rdd.html#局所平均-rdd_data2.csv-2",
    "title": "方法論特殊講義III",
    "section": "局所平均 (rdd_data2.csv)",
    "text": "局所平均 (rdd_data2.csv)\n\\(h = 1\\) の場合"
  },
  {
    "objectID": "slide/rdd.html#局所平均-rdd_data2.csv-3",
    "href": "slide/rdd.html#局所平均-rdd_data2.csv-3",
    "title": "方法論特殊講義III",
    "section": "局所平均 (rdd_data2.csv)",
    "text": "局所平均 (rdd_data2.csv)\nバンド幅の調整による因果効果の推定値の変化"
  },
  {
    "objectID": "slide/rdd.html#局所平均-rdd_data1.csv",
    "href": "slide/rdd.html#局所平均-rdd_data1.csv",
    "title": "方法論特殊講義III",
    "section": "局所平均 (rdd_data1.csv)",
    "text": "局所平均 (rdd_data1.csv)\n参考) 選挙制度と投票率の例 (真の因果効果は 5)\n\n傾きが緩やかな場合、バイアス小"
  },
  {
    "objectID": "slide/rdd.html#限界",
    "href": "slide/rdd.html#限界",
    "title": "方法論特殊講義III",
    "section": "限界",
    "text": "限界\nパラメトリック推定に比べてバイアスが大きい場合も\n\nバンド幅内のデータのみが分析対象になるため、必然的にサンプル・サイズが小さくなる\n\n少数のケースによって平均値の変動が大きい (モデルの分散が大きい)\nバンド幅内に十分に大きいサンプルサイズが確保されている必要\n\n平均値を用いることは、バンド幅内のデータにおいて強制変数の傾きが0という非常に強い仮定を置く。\n\nrdd_data2.csvのように \\(c\\) 周辺で変化が大きい場合、局所平均は向いていない\n\n\n\nより前提を緩めた推定法\n\n局所回帰分析 (local regression)"
  },
  {
    "objectID": "slide/rdd.html#局所平均-vs.-局所回帰-rdd_data2.csv",
    "href": "slide/rdd.html#局所平均-vs.-局所回帰-rdd_data2.csv",
    "title": "方法論特殊講義III",
    "section": "局所平均 vs. 局所回帰 (rdd_data2.csv)",
    "text": "局所平均 vs. 局所回帰 (rdd_data2.csv)\n\\(h = 3\\) の場合"
  },
  {
    "objectID": "slide/rdd.html#局所回帰分析",
    "href": "slide/rdd.html#局所回帰分析",
    "title": "方法論特殊講義III",
    "section": "局所回帰分析",
    "text": "局所回帰分析\nバンド幅内データを対象にした線形回帰分析 (Hahn et al. 2001, Poter 2003, Imbens and Lemieux 2008)\n\nパラメトリック推定と同様、交差項や多項式も投入可能\n\nRの{rdd}パッケージの場合、交差項\\(\\bigcirc\\) & 多項式\\(\\times\\)\n\n\n\n\n閾値（\\(c\\)）に近いほど、ケースに重みを付ける\n\n重み関数はカーネル関数を用いる\nImbens and Lemieux（2008）は一様（uniform; rectangular） カーネル関数を用いたが、この場合、重みを付けない普通の回帰分析と一致\n\nバンド幅内の全てのケースに同じ重みを付ける\n\n三角形（triangular）カーネル関数が統計学的観点からは最適（optimal）とも（Fan and Gijbels 1996）\n\nほとんどのパッケージは三角形カーネル関数がデフォルト"
  },
  {
    "objectID": "slide/rdd.html#様々なカーネル関数",
    "href": "slide/rdd.html#様々なカーネル関数",
    "title": "方法論特殊講義III",
    "section": "様々なカーネル関数",
    "text": "様々なカーネル関数"
  },
  {
    "objectID": "slide/rdd.html#局所回帰-一様カーネルh-5",
    "href": "slide/rdd.html#局所回帰-一様カーネルh-5",
    "title": "方法論特殊講義III",
    "section": "局所回帰 & 一様カーネル（\\(h = 5\\)）",
    "text": "局所回帰 & 一様カーネル（\\(h = 5\\)）"
  },
  {
    "objectID": "slide/rdd.html#局所回帰-一様カーネルh-3",
    "href": "slide/rdd.html#局所回帰-一様カーネルh-3",
    "title": "方法論特殊講義III",
    "section": "局所回帰 & 一様カーネル（\\(h = 3\\)）",
    "text": "局所回帰 & 一様カーネル（\\(h = 3\\)）"
  },
  {
    "objectID": "slide/rdd.html#局所回帰-一様カーネルh-1",
    "href": "slide/rdd.html#局所回帰-一様カーネルh-1",
    "title": "方法論特殊講義III",
    "section": "局所回帰 & 一様カーネル（\\(h = 1\\)）",
    "text": "局所回帰 & 一様カーネル（\\(h = 1\\)）"
  },
  {
    "objectID": "slide/rdd.html#バント幅とlate",
    "href": "slide/rdd.html#バント幅とlate",
    "title": "方法論特殊講義III",
    "section": "バント幅とLATE",
    "text": "バント幅とLATE"
  },
  {
    "objectID": "slide/rdd.html#バンド幅の話",
    "href": "slide/rdd.html#バンド幅の話",
    "title": "方法論特殊講義III",
    "section": "バンド幅の話",
    "text": "バンド幅の話\nノンパラメトリック推定の場合、バンド幅の設定が大事\n\n一般的に、 \\(h\\) が大きいほどバイアスが大きい\n\nデータによっては逆の傾向や凹関数の形をしている場合もある\n分散とバイアスのトレード・オフ関係\n\n理想としては分散とバイアスの最小化が望ましい\n\n\n\n\n\n最適バンド幅 (optimal bandwidth)\n\n残念ながら、バンド幅を決めるルールは存在しない\nバンド幅を決めるのは分析者の仕事\nいろいろと \\(h\\) を変えながら分析を繰り返す\n多く使われているバンド幅の決め方\n\\(\\Rightarrow\\) Imbens-Kalyanaraman Optimal Bandwidth"
  },
  {
    "objectID": "slide/rdd.html#ik-optimal-bandwidth",
    "href": "slide/rdd.html#ik-optimal-bandwidth",
    "title": "方法論特殊講義III",
    "section": "IK Optimal Bandwidth",
    "text": "IK Optimal Bandwidth\n簡単に計算可能な最適バンド幅の一つ (Imbens and Kalyanaraman 2009)\n\n他に CCT バンド幅 (Calonico, Cattaneo, and Titiunik 2014)、CV バンド幅 (Ludwig, and Mill 2007) など\n\n\n\\[h_{\\text{opt}} = C_K \\cdot \\Bigg(\\frac{2 \\hat{\\sigma}^2(c) / \\hat{f}(c)}{\\big(m_{+}^{(2)}(c) - m_{-}^{(2)}(c)\\big)^2 + (\\hat{r}_{+} + \\hat{r}_{-})}\\Bigg)^{\\frac{1}{5}} \\cdot N^{-\\frac{1}{5}}\\]\n\n非常に簡単!\n\n\n\n\n\n\n\n\n\nパソコンが勝手に計算してくれるので安心して良い"
  },
  {
    "objectID": "slide/rdd.html#カーネルとの関係",
    "href": "slide/rdd.html#カーネルとの関係",
    "title": "方法論特殊講義III",
    "section": "カーネルとの関係",
    "text": "カーネルとの関係\nカーネル選択は推定値に大きな影響を与えない (Lee and Lemieux 2010)\n\n\n\n\n\n\n\n\nkernel\nBW\nLATE\nHalf BW\nDouble BW\n\n\n\n\ntriangular\n3.860\n25.527\n30.865\n6.479\n\n\nrectangular\n6.068\n10.566\n24.551\n-40.634\n\n\nepanechnikov\n3.593\n24.570\n30.955\n7.702\n\n\nquartic\n4.103\n25.317\n30.860\n7.323\n\n\ntriweight\n4.560\n25.478\n31.020\n7.443\n\n\ntricube\n4.141\n25.001\n30.834\n7.697\n\n\ngaussian\n1.413\n25.878\n31.318\n6.687\n\n\ncosine\n3.659\n24.640\n30.891\n7.395"
  },
  {
    "objectID": "slide/rdd.html#実習用データ",
    "href": "slide/rdd.html#実習用データ",
    "title": "方法論特殊講義III",
    "section": "実習用データ",
    "text": "実習用データ\n講師が作成した架空データ\n\nrdd_data1.csv: スライド5ページ\n\n真の因果効果: 約5\n\nrdd_data2.csv: スライド15ページ\n\n真の因果効果: 約25\n\nrdd_data3.csv: スライド29ページ\n\n真の因果効果: 約7.5\n\n\n\n実習用データ\n\nrdd_data4.dta"
  },
  {
    "objectID": "slide/rdd.html#アメリカにおける現職効果-1",
    "href": "slide/rdd.html#アメリカにおける現職効果-1",
    "title": "方法論特殊講義III",
    "section": "アメリカにおける現職効果 (1)",
    "text": "アメリカにおける現職効果 (1)"
  },
  {
    "objectID": "slide/rdd.html#アメリカにおける現職効果-2",
    "href": "slide/rdd.html#アメリカにおける現職効果-2",
    "title": "方法論特殊講義III",
    "section": "アメリカにおける現職効果 (2)",
    "text": "アメリカにおける現職効果 (2)\n\n\n\nCall:\nRDestimate(formula = vote ~ margin, data = rdrobust_RDsenate)\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|) \nLATE        7.550     347            9.645    2.115       4.559    5.135e-06\nHalf-BW     3.775     186           12.664    2.803       4.517    6.258e-06\nDouble-BW  15.100     610            7.477    1.561       4.789    1.678e-06\n              \nLATE       ***\nHalf-BW    ***\nDouble-BW  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F      Num. DoF  Denom. DoF  p        \nLATE       23.66  3         343         1.226e-13\nHalf-BW    17.05  3         182         1.674e-09\nDouble-BW  51.45  3         606         0.000e+00"
  },
  {
    "objectID": "slide/rdd.html#ariga-et-al.-データについて",
    "href": "slide/rdd.html#ariga-et-al.-データについて",
    "title": "方法論特殊講義III",
    "section": "Ariga et al. データについて",
    "text": "Ariga et al. データについて\n詳細は以下の論文を参照\n\nKenichi Ariga, Yusaku Horiuchi, Roland Mansilla, and Michio Umeda. 2016. “No Sorting, No Advantage: Regression Discontinuity Estimates of Incumbency Advantage in Japan,” Electoral Studies, 43: 21–31.\n\n\n変数の説明\n\nvm1: \\(t\\) 期選挙における自民党候補者のvote margin\n\nvote margin: 自分の得票率 - 非自民候補の最高得票率\n\nF_ldpv_smd: \\(t+1\\) 期選挙における自民党候補者の得票率\nldp_LCF: \\(t-1\\)から\\(t+1\\)期まで選挙区割が変化せず、自民党候補者がいる選挙区ダミー"
  },
  {
    "objectID": "slide/rdd.html#散布図",
    "href": "slide/rdd.html#散布図",
    "title": "方法論特殊講義III",
    "section": "散布図",
    "text": "散布図\n全ケースの散布図"
  },
  {
    "objectID": "slide/rdd.html#散布図-1",
    "href": "slide/rdd.html#散布図-1",
    "title": "方法論特殊講義III",
    "section": "散布図",
    "text": "散布図\n区間ごとの平均値の散布図 (点が多い時に便利)"
  },
  {
    "objectID": "slide/rdd.html#処置効果",
    "href": "slide/rdd.html#処置効果",
    "title": "方法論特殊講義III",
    "section": "処置効果",
    "text": "処置効果\n現職効果は見られない"
  },
  {
    "objectID": "slide/rdd.html#頑健性チェック-1",
    "href": "slide/rdd.html#頑健性チェック-1",
    "title": "方法論特殊講義III",
    "section": "頑健性チェック (1)",
    "text": "頑健性チェック (1)\nバンド幅を動かしても推定値は大きく変化しない"
  },
  {
    "objectID": "slide/rdd.html#頑健性チェック-2",
    "href": "slide/rdd.html#頑健性チェック-2",
    "title": "方法論特殊講義III",
    "section": "頑健性チェック (2)",
    "text": "頑健性チェック (2)\n多項式回帰でも推定値は大きく変化しない (バンド幅は固定)"
  },
  {
    "objectID": "slide/rdd.html#仮定の確認",
    "href": "slide/rdd.html#仮定の確認",
    "title": "方法論特殊講義III",
    "section": "仮定の確認",
    "text": "仮定の確認\n強制変数の密度が閾値周辺において連続しているか否かを確認\n\n出力される\\(p\\)値が0.05を下回る場合、閾値周辺において操作が行われている可能性を示唆\n{rdd}のDCdensity()、または{rddensity}のrddensity()で検定可能\n\n\n\n\nDCdensity(ariga_df$vm1, plot = FALSE)\n\n[1] 0.3002424\n\nrddensity(X = ariga_df$vm1) |&gt;\n  summary()\n\n\nManipulation testing using local polynomial density estimation.\n\nNumber of obs =       1266\nModel =               unrestricted\nKernel =              triangular\nBW method =           estimated\nVCE method =          jackknife\n\nc = 0                 Left of c           Right of c          \nNumber of obs         479                 787                 \nEff. Number of obs    259                 289                 \nOrder est. (p)        2                   2                   \nOrder bias (q)        3                   3                   \nBW est. (h)           6.112               6.078               \n\nMethod                T                   P &gt; |T|             \nRobust                -0.818              0.4134              \n\n\nP-values of binomial tests (H0: p=0.5).\n\nWindow Length / 2          &lt;c     &gt;=c    P&gt;|T|\n0.448                      20      24    0.6516\n0.896                      41      41    1.0000\n1.343                      65      59    0.6536\n1.791                      89      79    0.4876\n2.239                     108      98    0.5307\n2.687                     129     116    0.4434\n3.134                     151     135    0.3751\n3.582                     168     163    0.8260\n4.030                     188     185    0.9175\n4.478                     200     204    0.8814\n\n\n\n\nrddensity(X = ariga_df$vm1) |&gt;\n  rdplotdensity(X = ariga_df$vm1)\n\n\n\n\n\n\n\n\n\n\n\n\n{rddensity}の場合、デフォルトはjacknifeで分散共分散行列を算出\njacknife: ケースを1個ずつ抜いたデータセットをN個作成する(LOOに似ている)。常に同じ結果が得られる\nbootstrap: ランダムにサンプルを作成する。パソコンのPowerが必要\n\n\n\n\n\nhttps://www.jaysong.net/kobe-ci/"
  },
  {
    "objectID": "slide/did.html#マッチングの限界",
    "href": "slide/did.html#マッチングの限界",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "条件付き独立の仮定 (Conditional Independent Assumption; CIA)\n\n処置変数（\\(T\\)）と応答変数（\\(Y\\)）の間に存在する交絡要因（\\(W\\)）が全て観察されている場合\n\n\\({Y_i (T_i = 1), Y_i (T_i = 0) \\perp T_i | W_i}\\)\n\\(\\rightarrow\\) 交絡変数を共変量として統制する場合、観察データからも因果効果の推定が可能\n\nしかし、全ての交絡要因がデータに含まれる場合もほぼゼロ\n\n\\(\\rightarrow\\) 仮定としては強すぎるため、（回帰分析を含む）マッチングによる厳密な因果推論は困難\nただし、単純に処置変数と応答変数の単回帰分析よりは望ましい。\n\nより緩い仮定の下で可能な因果推論の手法\n\n\\(\\rightarrow\\) 自然実験（Natural Experiment）"
  },
  {
    "objectID": "slide/did.html#自然実験とは",
    "href": "slide/did.html#自然実験とは",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "RCTの3つの特徴（Freedman, Pisani, and Purves 2007）\n\nThe response of experimental subjects assigned to receive a treatment is compared to the response of subjects assigned to a control group.\nThe assignment of subjects to treatment and control groups is done at random, through a randomizing device such as a coin flip.\nThe manipulation of the treatment—also known as the intervention—is under the control of an experimental researcher.\n\n\n自然実験は（Dunning 2012）\n\n同じ\n処置の有無は無作為のように決まる（as-if random）。\n処置内容などを研究者が操作することは不可能\n\n2と3は自然、制度などによって影響を受ける。"
  },
  {
    "objectID": "slide/did.html#自然実験の例",
    "href": "slide/did.html#自然実験の例",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "処置を受けるか否かが自然、制度、偶然などによって規定される\n\n多数代表制と比例代表制\n\n人口3500未満なら多数代表制、以上なら比例代表制を採用（フランス地方選挙）\n\n軍の経験と所得\n\nベトナム戦争時、徴兵対象がくじによって決まる（アメリカ）\n\n最低賃金の効果\n\n隣接するペンシルベニア州とニュージャージー州の最低賃金の格差\n\n現職効果\n\n惜敗・辛勝の場合、候補者間の質には大差ないはず\n\n選挙区定数の効果\n\n人口によって選挙区定数が決まる\n\nその他"
  },
  {
    "objectID": "slide/did.html#自然実験の方法",
    "href": "slide/did.html#自然実験の方法",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "本講義では1と2を解説\n\n差分の差分法（Difference-in-Difference; Diff-in-Diff/DID/DD）\n回帰不連続デザイン (Regression Discontinuity Design; RDD)\n\n中断時系列デザイン（Interrupted Time-series Design; ITS）\n\nRDDの時系列版であるが、自己相関などの対処が必要であるため本講義では省略\n\n\n操作変数（Instrumental Variable; IV）\n集積分析（Bunching Analysis）など"
  },
  {
    "objectID": "slide/did.html#保育所の整備と母の就労率1",
    "href": "slide/did.html#保育所の整備と母の就労率1",
    "title": "方法論特殊講義III",
    "section": "保育所の整備と母の就労率（1）",
    "text": "保育所の整備と母の就労率（1）\n横軸: \\(\\frac{\\mbox{認可保育所定員}}{\\mbox{5歳以下子供数}}\\); 縦軸: 女性の就労率（元ネタ: Asai, Kambayashi, and Yamaguchi (2015) / データは宋が収集）"
  },
  {
    "objectID": "slide/did.html#保育所の整備と母の就労率2",
    "href": "slide/did.html#保育所の整備と母の就労率2",
    "title": "方法論特殊講義III",
    "section": "保育所の整備と母の就労率（2）",
    "text": "保育所の整備と母の就労率（2）\n保育所が整備されると母は安心して働けるから就労率が上がる\n\n\n\nロジックとして問題はなさそう\n内生性は?\n\n(たとえば、)「県民性」の存在\n母親の就業意識が高く、地域社会もこの意識に好意的なら …\n\n\\(\\rightarrow\\) 就労率が上がる\n\\(\\rightarrow\\) 政治・行政も支持拡大のために保育所整備に力を入れる"
  },
  {
    "objectID": "slide/did.html#差分の差分法",
    "href": "slide/did.html#差分の差分法",
    "title": "方法論特殊講義III",
    "section": "差分の差分法",
    "text": "差分の差分法\nDifference in Difference (Diff-in-Diff, DID, DD)\n\n同一対象に対して複数の観測が前提\n\n保育所の整備と母の就労率を47都道府県に対して4回 (2000, 2005, 2010, 2015年) 観察\n「パネルデータ」\n\n個々の有権者を対象にした場合、パネルデータの収集は高費用\n\n日本の政治学だとJESが代表的\n\n国、自治体、選挙区、団体は集計データが整備され、公表されているため利用しやすい"
  },
  {
    "objectID": "slide/did.html#タバコの値段と消費量",
    "href": "slide/did.html#タバコの値段と消費量",
    "title": "方法論特殊講義III",
    "section": "タバコの値段と消費量",
    "text": "タバコの値段と消費量\n元ネタはカルフォルニア州のProposition99\n\n\\(t+1\\)期において、A州のみタバコの値上げ\n\\(t\\)期におけるA州のタバコ消費量（箱/人）：15\n\\(t+1\\)期におけるA州のタバコ消費量（箱/人）：10\n\n\\(\\rightarrow\\) 値上げ後、タバコの消費量が5箱\\(\\downarrow\\)\n\n\n\n\n実際の分析例は\n\nBreslow, M Johnson. 1993. “California’s Proposition 99 on Tobacco, and its Impact,” Annual Review of Public Health, 14: 585–604.\n他にも Proposition 99 の因果効果に関する研究多数\n\n以下は100%架空データ"
  },
  {
    "objectID": "slide/did.html#タバコの値段と消費量-1",
    "href": "slide/did.html#タバコの値段と消費量-1",
    "title": "方法論特殊講義III",
    "section": "タバコの値段と消費量",
    "text": "タバコの値段と消費量\nタバコ消費量の変化"
  },
  {
    "objectID": "slide/did.html#タバコの値段と消費量-2",
    "href": "slide/did.html#タバコの値段と消費量-2",
    "title": "方法論特殊講義III",
    "section": "タバコの値段と消費量",
    "text": "タバコの値段と消費量\n値上げ後、タバコの消費量が5箱減少\n\n「5箱減」は値上げによる効果か\n\nたまたま全国的な禁煙ブームと重なった?\nA州の喫煙量はもともと減少傾向だったかも?\n\n\\(\\rightarrow\\) 比較対象が必要"
  },
  {
    "objectID": "slide/did.html#b州の登場",
    "href": "slide/did.html#b州の登場",
    "title": "方法論特殊講義III",
    "section": "B州の登場",
    "text": "B州の登場\n値上げを行っていないB州におけるタバコ消費量"
  },
  {
    "objectID": "slide/did.html#潜在的結果枠組みから考える",
    "href": "slide/did.html#潜在的結果枠組みから考える",
    "title": "方法論特殊講義III",
    "section": "潜在的結果枠組みから考える",
    "text": "潜在的結果枠組みから考える\n因果推論の枠組みから考えると …\n\n処置変数 ( \\(T\\) ): タバコの値上げ\n応答変数 ( \\(Y\\) ): タバコの消費量\n\\(i\\) : 観測単位 (人/自治体/国/企業など)\n\\(t\\) : 観測時期\n\n\n\n\n\n\n\n\n\n\nID ( \\(i\\) )\n\\(\\quad t \\quad\\)\n\\(\\quad T_{it} \\quad\\)\n\\(\\quad Y_{it} \\quad\\)\n\n\n\n\n1\n1\n0\n15\n\n\n1\n2\n1\n10\n\n\n2\n1\n0\n17\n\n\n2\n2\n0\n15"
  },
  {
    "objectID": "slide/did.html#潜在的結果枠組みから考える-1",
    "href": "slide/did.html#潜在的結果枠組みから考える-1",
    "title": "方法論特殊講義III",
    "section": "潜在的結果枠組みから考える",
    "text": "潜在的結果枠組みから考える\n\n\\(t = 2\\) において処置を受けた場合、 \\(Z = 1\\) とする\n\\(Z = 1\\) であるA州の変化量 ( \\(\\Delta Y_1\\) ): 10 − 15 = −5\n\\(Z = 0\\) であるB州の変化量 ( \\(\\Delta Y_2\\) ): 15 − 17 = −2\n\n\n\n\nID ( \\(i\\) )\n\\(\\quad Z_{i} \\quad\\)\n\\(\\quad \\Delta Y_{i} \\quad\\)\n\n\n\n\n1\n1\n-5\n\n\n2\n0\n-2"
  },
  {
    "objectID": "slide/did.html#潜在的結果枠組みから考える-2",
    "href": "slide/did.html#潜在的結果枠組みから考える-2",
    "title": "方法論特殊講義III",
    "section": "潜在的結果枠組みから考える",
    "text": "潜在的結果枠組みから考える\n\nA州が処置を受けなかった場合の潜在的結果としてB州のデータを用いる\n因果効果: \\(\\Delta Y(Z = 1) - \\Delta Y(Z = 0)\\)\n\n(−5) − (−2) = −3\n\nタバコ値上げの効果は-3箱\n\n\n\n\n\\(\\quad \\Delta Y(Z = 1) \\quad\\)\n\\(\\quad \\Delta Y(Z = 0) \\quad\\)\n差分\n\n\n\n\n-5\n-2\n-3"
  },
  {
    "objectID": "slide/did.html#潜在的結果枠組みから考える-3",
    "href": "slide/did.html#潜在的結果枠組みから考える-3",
    "title": "方法論特殊講義III",
    "section": "潜在的結果枠組みから考える",
    "text": "潜在的結果枠組みから考える\n数式で表すと\n\\[\\begin{align}\\Delta = & [\\mathbb{E}(Y_{t+1}(Z = 1)) - \\mathbb{E}(Y_t(Z = 1))] \\\\ & - [\\mathbb{E}(Y_{t+1}(Z = 0)) - \\mathbb{E}(Y_t(Z = 0))]\\end{align}\\]\n\n\\(t + 1\\) 期に処置を受けたら \\(Z = 1\\) 、受けなかったら \\(Z = 0\\)\n\\(t\\) 期は誰も処置を受けていない\n\n初期状態は一緒で、一部のユニットだけ処置を受ける"
  },
  {
    "objectID": "slide/did.html#図ならもっと分かりやすい",
    "href": "slide/did.html#図ならもっと分かりやすい",
    "title": "方法論特殊講義III",
    "section": "図なら、もっと分かりやすい",
    "text": "図なら、もっと分かりやすい"
  },
  {
    "objectID": "slide/did.html#並行トレンドの仮定",
    "href": "slide/did.html#並行トレンドの仮定",
    "title": "方法論特殊講義III",
    "section": "並行トレンドの仮定",
    "text": "並行トレンドの仮定\nParallel Trend Assumption\n\n差分の差分法から推定された値が因果効果になるための前提\n\nA州が値上げしなかったらB州並に消費量が減っただろうというのが前提\n\n処置を受けたユニットが、もし処置を受けなかった場合、応答変数の変化は統制群の変化と一致する\n\n処置群の潜在的結果は観測された統制群の動きと並行する\n= A州が値上げしなかったら、B州のように2箱減に留まる"
  },
  {
    "objectID": "slide/did.html#並行トレンドの仮定どう確認するか",
    "href": "slide/did.html#並行トレンドの仮定どう確認するか",
    "title": "方法論特殊講義III",
    "section": "並行トレンドの仮定:どう確認するか",
    "text": "並行トレンドの仮定:どう確認するか\n一般的に2つの方法\n\n他の処置群や統制群を見つけて追加する\n\n同じく値上げをしていないC州を追加\n\n3期以上のデータを用意する\n\n\\(t − 1\\) 期のデータも投入する\nむろん、 \\(t − 1\\) 期のA州は値上げ前\n\n上記2つの方法を組み合わせる\n\n実質的にはこれがメイン"
  },
  {
    "objectID": "slide/did.html#統制群を増やしてみた",
    "href": "slide/did.html#統制群を増やしてみた",
    "title": "方法論特殊講義III",
    "section": "統制群を増やしてみた",
    "text": "統制群を増やしてみた\n並行トレンドの仮定が満たされている場合 \\(\\rightarrow\\) どの州を潜在的結果として使ってもOK"
  },
  {
    "objectID": "slide/did.html#統制群を増やしてみた-1",
    "href": "slide/did.html#統制群を増やしてみた-1",
    "title": "方法論特殊講義III",
    "section": "統制群を増やしてみた",
    "text": "統制群を増やしてみた\n並行トレンドの仮定が満たされていない場合 \\(\\rightarrow\\) どの州を潜在的結果として用いるか"
  },
  {
    "objectID": "slide/did.html#t1のデータを入れてみた",
    "href": "slide/did.html#t1のデータを入れてみた",
    "title": "方法論特殊講義III",
    "section": "\\(t−1\\)のデータを入れてみた",
    "text": "\\(t−1\\)のデータを入れてみた\n並行トレンドの仮定が満たされている場合"
  },
  {
    "objectID": "slide/did.html#t1-のデータを入れてみた",
    "href": "slide/did.html#t1-のデータを入れてみた",
    "title": "方法論特殊講義III",
    "section": "\\(t−1\\) のデータを入れてみた",
    "text": "\\(t−1\\) のデータを入れてみた\n並行トレンドの仮定が満たされていない場合 (1) \\(\\rightarrow\\) 潜在的結果は15、または13"
  },
  {
    "objectID": "slide/did.html#t1-のデータを入れてみた-1",
    "href": "slide/did.html#t1-のデータを入れてみた-1",
    "title": "方法論特殊講義III",
    "section": "\\(t−1\\) のデータを入れてみた",
    "text": "\\(t−1\\) のデータを入れてみた\n並行トレンドの仮定が満たされていない場合 (2) \\(\\rightarrow\\) 潜在的結果は10、または13"
  },
  {
    "objectID": "slide/did.html#回帰分析による差分の差分法",
    "href": "slide/did.html#回帰分析による差分の差分法",
    "title": "方法論特殊講義III",
    "section": "回帰分析による差分の差分法",
    "text": "回帰分析による差分の差分法\nデータが2期のみ \\((t \\in \\{0, 1\\})\\) の場合\n\\[\\hat{Y} = \\beta_0 + \\beta_1 T + \\beta_2 \\mbox{POST} + \\delta T \\cdot \\mbox{Post}\\]\n\nT: 処置群か否か\nPOST: 処置が行われた後か否か\nY: 応答変数\n\n\n\n\nID\nName\nPOST\nT\nY\n\n\n\n\n1\nA州\n0\n1\n15\n\n\n2\nA州\n1\n1\n10\n\n\n3\nB州\n0\n0\n17\n\n\n4\nB州\n1\n0\n15"
  },
  {
    "objectID": "slide/did.html#回帰分析による差分の差分法-1",
    "href": "slide/did.html#回帰分析による差分の差分法-1",
    "title": "方法論特殊講義III",
    "section": "回帰分析による差分の差分法",
    "text": "回帰分析による差分の差分法\nデータが2期のみ \\((t \\in \\{0, 1\\})\\) の場合\n\\[\\hat{Y} = \\beta_0 + \\beta_1 T + \\beta_2 \\mbox{POST} + \\delta T \\cdot \\mbox{Post}\\]\n\n処置群の差分: \\(\\hat{Y}(T = 1, POST = 1) − \\hat{Y}(T = 1,POST = 0)\\)\n\n\\(\\beta_2 + \\delta = \\underbrace{(\\beta_0 + \\beta_1 + \\beta_2 + \\delta)}_{\\hat{Y}(T = 1, POST = 1)} - \\underbrace{(\\beta_0 + \\beta_1)}_{\\hat{Y}(T = 1,POST = 0)}\\)\n\n統制群の差分: \\(\\hat{Y}(T = 0, POST = 1) − \\hat{Y}(T = 0,POST = 0)\\)\n\n\\(\\beta_2 = \\underbrace{(\\beta_0 + \\beta_2)}_{\\hat{Y}(T = 0, POST = 1)} - \\underbrace{(\\beta_0)}_{\\hat{Y}(T = 0,POST = 0)}\\)\n\n差分の差分: \\(\\delta = (\\beta_2 + \\delta) - \\beta_2\\)\n\n\\(\\delta\\) : 処置効果"
  },
  {
    "objectID": "slide/did.html#一般化された回帰モデル",
    "href": "slide/did.html#一般化された回帰モデル",
    "title": "方法論特殊講義III",
    "section": "一般化された回帰モデル",
    "text": "一般化された回帰モデル\n先ほどのモデルの限界\n\n期間が2期のみ\n\n実際にはもっとデータがあるはず\n\n観察されたユニットが2個 (A州とB州)のみ\n\n実際にはもっとデータがあるはず\n\n処置変数が {0, 1} のバイナリー変数\n\n保育所整備の例の場合、処置変数は連続変数( \\(T = [0, 1]\\) )\n\n\n\n以下では、保育所整備の例で解説"
  },
  {
    "objectID": "slide/did.html#一般化された回帰モデル-1",
    "href": "slide/did.html#一般化された回帰モデル-1",
    "title": "方法論特殊講義III",
    "section": "一般化された回帰モデル",
    "text": "一般化された回帰モデル\nより一般化されたモデル\n\\[\\hat{Y}_{pt} = \\beta + \\delta \\mbox{Treat}_{pt} + \\sum_{k = \\mbox{Aomori}}^{\\mbox{Okinawa}}\\gamma_k \\cdot \\mbox{Pref}_{kp} + \\sum_{j = 2005}^{2015} \\psi_j \\cdot \\mbox{Year}_{jt}\\]\n\n\\(Y_{pt}\\) : \\(t\\) 期における \\(p\\) 県の女性就労率 ( \\(= [0, 1]\\) )\n\\(\\mbox{Treat}_{pt}\\) : \\(t\\) 期における \\(p\\) 県の保育所の整備率 ( \\(= [0, 1]\\) )\n\\(\\mbox{Pref}_p\\) : \\(p\\) 県か否かを表す各都道府県ダミー変数 ( \\(\\in \\{0, 1\\}\\) )\n\\(\\mbox{Year}_t\\) : \\(t\\) 期か否かわ表す年ダミー変数 ( \\(\\in \\{0, 1\\}\\) )\n\n\n\n標準誤差はクラスター標準誤差を使用\n\n上記の例だと、都道府県単位でクラスター化"
  },
  {
    "objectID": "slide/did.html#一般化された回帰モデル-2",
    "href": "slide/did.html#一般化された回帰モデル-2",
    "title": "方法論特殊講義III",
    "section": "一般化された回帰モデル",
    "text": "一般化された回帰モデル\n単回帰分析と差分の差分法推定量の比較\n\n保育所の整備率と母の就労率の間に統計的有意な関係が見られない\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model 1\n                Model 2\n              \n        \n        \n        \n                \n                  保育所の整備率\n                  0.358  \n                  -0.003    \n                \n                \n                                \n                  (0.022)\n                  (0.030)   \n                \n                \n                  Num.Obs.      \n                  188    \n                  188       \n                \n                \n                  R2            \n                  0.510  \n                  0.987     \n                \n                \n                  R2 Adj.       \n                  0.508  \n                  0.982     \n                \n                \n                  AIC           \n                  -640.9 \n                  -1222.7   \n                \n                \n                  BIC           \n                  -631.2 \n                  -1054.4   \n                \n                \n                  RMSE          \n                  0.04   \n                  0.01      \n                \n                \n                  Std.Errors    \n                         \n                  by: Pref_J\n                \n                \n                  都道府県ダミー\n                  X      \n                  O         \n                \n                \n                  年ダミー      \n                  X      \n                  O"
  },
  {
    "objectID": "slide/did.html#平行トレンドは",
    "href": "slide/did.html#平行トレンドは",
    "title": "方法論特殊講義III",
    "section": "平行トレンドは?",
    "text": "平行トレンドは?\n回帰モデルでも平行トレンドの仮定は必要\n\n処置変数がバイナリー変数なら平行トレンドの仮定が満たされているか否かを可視化可能\n\n例) 電子投票の導入と投票率 (京都市)"
  },
  {
    "objectID": "slide/did.html#平行トレンドは-1",
    "href": "slide/did.html#平行トレンドは-1",
    "title": "方法論特殊講義III",
    "section": "平行トレンドは?",
    "text": "平行トレンドは?\n回帰モデルでも平行トレンドの仮定は必要\n\n処置変数が連続変数の場合、平行トレンドの仮定を視覚的に確認することは困難\n都道府県ダミーと年ダミー変数を投入したということは…\n\n都道府県ごとに切片のみが異なる\n各年の就労率の変動は全都道府県で共通\n= 平行トレンド\n\n\n\n\n都道府県ごとに切片だけでなく、異なる傾きまで許容するモデル\n\nトレンド変数の投入\n\n簡単だが、都道府県ごとのトレンド効果が線形という仮定\n\n都道府県レベルの共変量の投入\n\n柔軟だが、適切な共変量の発見が重要"
  },
  {
    "objectID": "slide/did.html#トレンド変数",
    "href": "slide/did.html#トレンド変数",
    "title": "方法論特殊講義III",
    "section": "トレンド変数",
    "text": "トレンド変数\n処置を受けていない場合も、傾きが都道府県ごとに異なる場合\n\n都道府県ダミーとトレンド変数 (連続変数としての年など) の交差項を投入\n仮定:都道府県間は平行でなくても、都道府県のトレンドは線形\n\n\n\\[\\hat{Y}_{pt} = \\beta + \\delta \\mbox{Treat}_{pt} + \\sum_{k = \\mbox{Aomori}}^{\\mbox{Okinawa}}\\gamma_k \\cdot \\mbox{Pref}_{kp} + \\sum_{j = 2005}^{2015} \\psi_j \\cdot \\mbox{Year}_{jt} + \\sum_{k = \\mbox{Aomori}}^{\\mbox{Okinawa}}\\theta_k (\\mbox{Pref}_{kp} \\cdot t)\\]\n\n\\(t\\) : トレンド変数 (2000 年: t = 1、2005 年: t = 2、…)\n\n\\(\\mbox{Year}_t\\) はダミー変数であるが、トレンド変数は連続変数"
  },
  {
    "objectID": "slide/did.html#トレンド変数-1",
    "href": "slide/did.html#トレンド変数-1",
    "title": "方法論特殊講義III",
    "section": "トレンド変数",
    "text": "トレンド変数\n結果の比較\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model 1\n                Model 2\n                Model 3\n              \n        \n        \n        \n                \n                  保育所の整備率\n                  0.358  \n                  -0.003    \n                  -0.009    \n                \n                \n                                \n                  (0.022)\n                  (0.030)   \n                  (0.028)   \n                \n                \n                  Num.Obs.      \n                  188    \n                  188       \n                  188       \n                \n                \n                  R2            \n                  0.510  \n                  0.987     \n                  0.997     \n                \n                \n                  R2 Adj.       \n                  0.508  \n                  0.982     \n                  0.995     \n                \n                \n                  AIC           \n                  -640.9 \n                  -1222.7   \n                  -1439.2   \n                \n                \n                  BIC           \n                  -631.2 \n                  -1054.4   \n                  -1122.0   \n                \n                \n                  RMSE          \n                  0.04   \n                  0.01      \n                  0.00      \n                \n                \n                  Std.Errors    \n                         \n                  by: Pref_J\n                  by: Pref_J\n                \n                \n                  都道府県ダミー\n                  X      \n                  O         \n                  O         \n                \n                \n                  年ダミー      \n                  X      \n                  O         \n                  O         \n                \n                \n                  トレンド変数  \n                  X      \n                  X         \n                  O"
  },
  {
    "objectID": "slide/did.html#共変量の投入",
    "href": "slide/did.html#共変量の投入",
    "title": "方法論特殊講義III",
    "section": "共変量の投入",
    "text": "共変量の投入\n\n既存のモデルは年度ごとに就労率の伸びは変化するものの、その変化の度合いは全都道府県において共通していると仮定\n景気が良いと母の就労率が上がる\n\nしかし、都道府県ごとに景気変動の度合いは異なることが一般的\n都道府県の失業率など、各都道府県の景気状況を表す変数を投入\n\n\n\\[\\hat{Y}_{pt} = \\beta + \\delta \\mbox{Treat}_{pt} + \\sum_{k = \\mbox{Aomori}}^{\\mbox{Okinawa}}\\gamma_k \\cdot \\mbox{Pref}_{kp} + \\sum_{j = 2005}^{2015} \\psi_j \\cdot \\mbox{Year}_{jt} + \\theta \\mbox{Unemp}_{pt}\\]\n\n\\(\\mbox{Unemp}_{pt}\\) : \\(t\\) 期における \\(p\\) 県の完全失業率\nトレンド変数は、「同じ都道府県なら、傾きは変わらない」と仮定しているが、共変量を統制する場合、このような仮定は必要としない\n\n適切な共変量の選択はトレンド変数よりも有効\n共変量は母の就労率、保育所の整備率、両方と関係のあるもの"
  },
  {
    "objectID": "slide/did.html#共変量の投入-1",
    "href": "slide/did.html#共変量の投入-1",
    "title": "方法論特殊講義III",
    "section": "共変量の投入",
    "text": "共変量の投入\n結果の比較\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                Model 1\n                Model 2\n                Model 3\n                Model 4\n                Model 5\n              \n        \n        \n        \n                \n                  保育所の整備率\n                  0.358  \n                  -0.003    \n                  -0.009    \n                  0.002     \n                  0.003     \n                \n                \n                                \n                  (0.022)\n                  (0.030)   \n                  (0.028)   \n                  (0.030)   \n                  (0.024)   \n                \n                \n                  Num.Obs.      \n                  188    \n                  188       \n                  188       \n                  188       \n                  188       \n                \n                \n                  R2            \n                  0.510  \n                  0.987     \n                  0.997     \n                  0.987     \n                  0.998     \n                \n                \n                  R2 Adj.       \n                  0.508  \n                  0.982     \n                  0.995     \n                  0.982     \n                  0.995     \n                \n                \n                  AIC           \n                  -640.9 \n                  -1222.7   \n                  -1439.2   \n                  -1322.0   \n                  -1543.8   \n                \n                \n                  BIC           \n                  -631.2 \n                  -1054.4   \n                  -1122.0   \n                  -1312.3   \n                  -1385.2   \n                \n                \n                  RMSE          \n                  0.04   \n                  0.01      \n                  0.00      \n                  0.01      \n                  0.00      \n                \n                \n                  Std.Errors    \n                         \n                  by: Pref_J\n                  by: Pref_J\n                  by: Pref_J\n                  by: Pref_J\n                \n                \n                  都道府県ダミー\n                  X      \n                  O         \n                  O         \n                  O         \n                  O         \n                \n                \n                  年ダミー      \n                  X      \n                  O         \n                  O         \n                  O         \n                  O         \n                \n                \n                  トレンド変数  \n                  X      \n                  X         \n                  O         \n                  X         \n                  O         \n                \n                \n                  共変量        \n                  X      \n                  X         \n                  X         \n                  O         \n                  O"
  },
  {
    "objectID": "slide/did.html#結果の比較",
    "href": "slide/did.html#結果の比較",
    "title": "方法論特殊講義III",
    "section": "結果の比較",
    "text": "結果の比較\n処置効果の点推定値と95%信頼区間\n\n保育所の整備が女性の就労率を上げるとは言えない"
  },
  {
    "objectID": "slide/did.html#並行トレンドのチェック",
    "href": "slide/did.html#並行トレンドのチェック",
    "title": "方法論特殊講義III",
    "section": "並行トレンドのチェック",
    "text": "並行トレンドのチェック\n並行トレンドをどう確認するか\n\nより多くの時点のデータを収集し、プロット\n\n検定 (test) ではなく、診断 (diagnostics)\n\nプラセボ・テスト\n\n方法1： \\(t=3\\)が処置を受けた時期なら、\\(t = 3\\)をデータから除外し、\\(t = 2\\)を処置とコーディングしてDIDを実行（3期以上のデータが必要）\n方法2： 統制群の一部を処置群とコーディング&処置群をデータから除外してDIDを実行（3つ以上の対象が必要）\n検定の結果、DID推定量が統計的有意であったら平行トレンドが満たされていないと判断する（並行トレンドの仮定が満たされていることは示せない）"
  },
  {
    "objectID": "slide/did.html#synthetic-control-method-概要",
    "href": "slide/did.html#synthetic-control-method-概要",
    "title": "方法論特殊講義III",
    "section": "Synthetic Control Method: 概要",
    "text": "Synthetic Control Method: 概要\n並行トレンドを満たすケースを仮想的に作り上げる手法\n\n処置群以外のケースを重み付け&合成\n\n合成に使われるケース: ドナー（Donor）\n\n一つ一つの観察対象が処置群と並行トレンドを満たさない場合でも使用可能\n\n精度を上げるには共変量が必要\nプラセボ・テストも必要\n統制群、処置前のサンプルサイズは大きいほど良い（DIDと同じ）\n\n{Synth}、または{gsynth}パッケージで実装可能\n\nベイジアン・アプローチだと{bpCausal}\n\n\n\n\n参考) Abadie, Alberto, Alexis Diamond, and Jens Hainmueller. 2015. “Comparative Politics and the Synthetic Control Method,” American Journal of Political Science, 59 (2): 495–510."
  },
  {
    "objectID": "slide/did.html#scmの例-事例",
    "href": "slide/did.html#scmの例-事例",
    "title": "方法論特殊講義III",
    "section": "SCMの例: 事例",
    "text": "SCMの例: 事例\nドイツ統一 (1990年) がもたらした経済効果は?"
  },
  {
    "objectID": "slide/did.html#scmの例-事例-1",
    "href": "slide/did.html#scmの例-事例-1",
    "title": "方法論特殊講義III",
    "section": "SCMの例: 事例",
    "text": "SCMの例: 事例\nドイツ統一 (1990年) がもたらした経済効果は?\n\n長期間の場合、並行トレンドが確認されない"
  },
  {
    "objectID": "slide/did.html#scmの例-事例-2",
    "href": "slide/did.html#scmの例-事例-2",
    "title": "方法論特殊講義III",
    "section": "SCMの例: 事例",
    "text": "SCMの例: 事例\nOECDに加盟している16カ国のトレンドから架空の西ドイツ(潜在的結果)を生成\n\nどうしても使えなさそうな国は合成に使わない or 重み \\(\\downarrow\\)\n西ドイツのトレンドと類似している国は重み \\(\\uparrow\\)"
  },
  {
    "objectID": "slide/did.html#scmの例-結果",
    "href": "slide/did.html#scmの例-結果",
    "title": "方法論特殊講義III",
    "section": "SCMの例: 結果",
    "text": "SCMの例: 結果\n5カ国のトレンドを合成し、架空の西ドイツのトレンドを生成\n\n合成に使用されない国の重みは0\n\n\n\n\nドナー国\n重み\nドナー国\n重み\n\n\n\n\nアメリカ\n0.216\nノルウェー\n0.000\n\n\nイギリス\n0.000\nスイス\n0.113\n\n\nオーストリア\n0.402\n日本\n0.161\n\n\nベルギー\n0.000\nギリシャ\n0.000\n\n\nデンマーク\n0.000\nポルトガル\n0.000\n\n\nフランス\n0.000\nスペイン\n0.000\n\n\nイタリア\n0.000\nオーストラリア\n0.000\n\n\nオランダ\n0.107\nニュージーランド\n0.000"
  },
  {
    "objectID": "slide/did.html#scmの例-結果-1",
    "href": "slide/did.html#scmの例-結果-1",
    "title": "方法論特殊講義III",
    "section": "SCMの例: 結果",
    "text": "SCMの例: 結果\nバランスチェックの例\n\n西ドイツと架空の西ドイツ間の共変量比較\n実際の西ドイツと非常に似た架空のケースが生成\n\n\n\n\n\n西ドイツ\n架空の西ドイツ\nドナー国\n\n\n\n\n一人当たりGDP\n15808.9\n15801.4\n13669.4\n\n\n貿易依存度\n56.8\n57.3\n59.8\n\n\nインフレーション率\n2.6\n3.4\n7.6\n\n\n付加価値産業\n34.5\n34.4\n33.8\n\n\n教育水準\n55.5\n54.9\n38.7\n\n\n国内総投資\n27.0\n27.0\n25.9"
  },
  {
    "objectID": "slide/did.html#scmの例-結果-2",
    "href": "slide/did.html#scmの例-結果-2",
    "title": "方法論特殊講義III",
    "section": "SCMの例: 結果",
    "text": "SCMの例: 結果\n\n左側の図: 西ドイツと架空の西ドイツのGDPトレンド\n右側の図: トレンドの差分"
  },
  {
    "objectID": "slide/did.html#実習用データ",
    "href": "slide/did.html#実習用データ",
    "title": "方法論特殊講義III",
    "section": "実習用データ",
    "text": "実習用データ\nスライドで使ったデータ\n\ndid_data1.csv: 保育所の整備と母の就労率\ndid_data2.csv: 電子投票の導入と投票率\nOECD諸国の経済指標データ: https://doi.org/10.7910/DVN/24714\n\n実習用データ\n\ndid_data4.csv: 学校内銃撃事件と政治参加\n\nLaura García-Montoya, Ana Arjona, and Matthew Lacombe. 2022. “Violence and Voting in the United States: How School Shootings Affect Elections,” American Political Science Review, 116 (3): 807-826.\n\ndid_data5.csv: 参院選投票率（都道府県）"
  },
  {
    "objectID": "slide/did.html#データの説明",
    "href": "slide/did.html#データの説明",
    "title": "方法論特殊講義III",
    "section": "データの説明",
    "text": "データの説明\nGarcía-Montoya, Arjona, and Lacombe (2022)のFigure 3&4の一部を再現\n\n銃撃事件は前回の選挙から今回の選挙の間に発生した場合1とし、今後続く。\n銃撃事件の深刻さは死者の有無で判定\n\n\n\n\n変数名\n説明\n\n\n\n\ncounty\nカウンティー（郡）のID\n\n\nstate\n州ID\n\n\nyear\n年\n\n\nshooting\n学校内銃撃事件の発生\n\n\nfatal_shooting\n深刻な学校内銃撃事件の発生\n\n\nnon_fatal_shooting\n軽微な学校内銃撃事件の発生\n\n\nturnout\n大統領選挙の投票率\n\n\ndemvote\n民主党候補者の得票率\n\n\npopulation\n人口（カウンティー）\n\n\nnon_white\n非白人の割合（カウンティー）\n\n\nchange_unem_rate\n失業率の変化（カウンティー）"
  },
  {
    "objectID": "slide/did.html#実習内容",
    "href": "slide/did.html#実習内容",
    "title": "方法論特殊講義III",
    "section": "実習内容",
    "text": "実習内容\n\n{estimatr}パッケージ（lm_robust()関数）の使い方\n推定結果の可視化\nSynthetic Control Methodの実装 ({gsynth})"
  },
  {
    "objectID": "slide/intro_rct.html#講師紹介",
    "href": "slide/intro_rct.html#講師紹介",
    "title": "方法論特殊講義III",
    "section": "講師紹介",
    "text": "講師紹介\n\n\n\n\n\n\n\nLINEスタンプ絶賛販売中!\n\n\n\n\n\n\n宋(そん)  財泫(じぇひょん) (SONG JAEHYUN)\n\n関西大学総合情報学部 准教授\n博士（政治学）\n\n専門は政治行動論、選挙研究、政治学方法論\n趣味はゲームとラーメン屋巡り\n\n好きなラーメンは家系と二郎インスパイア、汁なし全般\n最近やっているゲームはFF XIV\n\n\n\n\n song@kansai-u.ac.jp\n https://www.jaysong.net"
  },
  {
    "objectID": "slide/intro_rct.html#内容",
    "href": "slide/intro_rct.html#内容",
    "title": "方法論特殊講義III",
    "section": "内容",
    "text": "内容\n各講義は以下の内容に関する理論と実習を5:5で行う予定。また、履修者の理解・進捗状況に応じて変更の可能性がある。\n\n1日目：8月26日（木）\n\n因果推論の考え方\nランダム化比較試験\n\n2日目：8月27日（火）\n\nLab Session（Rの使い方）\n2日目にLab Sessionを行わない場合は、以下の内容を繰り上げ、5日目は操作変数を解説\n\n3日目：8月28日（水）\n\n回帰分析とマッチング、その応用\n\n4日目：8月29日（木）\n\n差分の差分法とその応用\n\n5日目：8月30日（金）\n\n回帰不連続デザイン"
  },
  {
    "objectID": "slide/intro_rct.html#実習",
    "href": "slide/intro_rct.html#実習",
    "title": "方法論特殊講義III",
    "section": "実習",
    "text": "実習\n実習はRで行う。1・2日目はRの導入および使い方についても解説（復習レベル）する。\n\n本講義の分析はExcel, SPSS, Stata, Julia, Pythonなどでも可能\nJared P. Lander. 2017. R for Everyone: Advanced Analytics and Graphics (2nd Edition), Addison-Wesley Professional.（邦訳有り）\n宋財泫・矢内勇生.『私たちのR: ベストプラクティスの探究』Web-book\n\n無料のR入門書：Rを広く、深く勉強したい人におすすめ\n\n\n\n\n宋のR環境\n\nmacOS Sonoma 14.6.1\nR version 4.4.1 (2024-06-14)\n\nR &gt; 4.3ならOK\n\nRStudio 2024.04.2+764\nスライド、サポートページ、実習用資料の執筆環境\n\nQuarto 1.5.56\nR package {quarto} 1.4.4"
  },
  {
    "objectID": "slide/intro_rct.html#rの学習資料",
    "href": "slide/intro_rct.html#rの学習資料",
    "title": "方法論特殊講義III",
    "section": "Rの学習資料",
    "text": "Rの学習資料\n計量政治学とR\n\n浅野正彦・矢内勇生. 2019『Rによる計量政治学』オーム社.\n飯田健. 2013.『計量政治分析』共立出版.\nKosuke Imai. 2017. Quantitative Social Science: An Introduction, Princeton University Press. (邦訳あり[上/下])\n\nR全般\n\nWickham, Hadley and Grolemund, Garrett. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, O’Reilly. (邦訳あり/原著はインターネットから無料で閲覧可)\n松村優哉 他. 2021. 『改訂2版 Rユーザのための RStudio[実践] 入門—tidyverseによるモダンな分析フローの世界—』技術評論社.\nWickham, Hadley. 2019. Advanced R (Second Edition), O’Reilly. (邦訳あり/原著はインターネットから無料で閲覧可)"
  },
  {
    "objectID": "slide/intro_rct.html#discordについて",
    "href": "slide/intro_rct.html#discordについて",
    "title": "方法論特殊講義III",
    "section": "Discordについて",
    "text": "Discordについて\n\nDiscordに登録し、Discordを起動する（アプリ版、Web版、どちらでも良い）。\n宋をフレンドとして追加\n\n宋のIDとタグは_jaysong_（前後にアンダースコア「_」あり） \n\n自分の学籍番号と氏名をDiscordメッセージで伝える。\n宋からの招待が届けば、サーバーに登録する。\n\nDiscord上の表示名（ニックネーム）は宋が実名へ変更する。任意の表示名に変更しないこと。"
  },
  {
    "objectID": "slide/intro_rct.html#評価",
    "href": "slide/intro_rct.html#評価",
    "title": "方法論特殊講義III",
    "section": "評価",
    "text": "評価\n平常点と期末レポート\n\n平常点: 30% 100%\n\n授業への参加度（質問/発言）\nDiscordでの参加度も含む\n\n期末レポート: 70%\n\n提出方法、期限は講義最終日に告知"
  },
  {
    "objectID": "slide/intro_rct.html#レポート",
    "href": "slide/intro_rct.html#レポート",
    "title": "方法論特殊講義III",
    "section": "レポート",
    "text": "レポート\n研究のプロポーザル\n\n本講義で紹介した手法を用いた分析のプロポーザルを作成\n実現可能性（予算、倫理など）があること\n\n架空の予算は100万円を上限とする\n\n分量の制限（下限/上限）なし\n提出期限および提出方法の詳細はDiscordにて案内"
  },
  {
    "objectID": "slide/intro_rct.html#前提知識",
    "href": "slide/intro_rct.html#前提知識",
    "title": "方法論特殊講義III",
    "section": "前提知識",
    "text": "前提知識\n統計学\n自分で計算できなくても、結果の読み方が分かるレベル\n\n仮説検定\n統計的有意性検定\n回帰分析\n\nR\n\nデータクリーニング、回帰分析、可視化などができるならベスト\n2日目にRの解説は行うが、深入りはしない（できない）\n\n全員が以下の資料レベルの内容を知っていれば2日目の内容を省略し、代わりに操作変数法について解説\nhttps://www.jaysong.net/r4ps/\n\n『私たちのR』を読もう！"
  },
  {
    "objectID": "slide/intro_rct.html#社会科学における因果推論の意味",
    "href": "slide/intro_rct.html#社会科学における因果推論の意味",
    "title": "方法論特殊講義III",
    "section": "社会科学における因果推論の意味",
    "text": "社会科学における因果推論の意味\nMorgan and Winship (2014) Counterfactuals and Causal Inference: Methods And Principles For Social Research. Cambridge.\n\nMore has been learned about causal inference in the last few decades than sum total of everything that had been learned about it in all prior recorded history. (Gary King)"
  },
  {
    "objectID": "slide/intro_rct.html#相関から因果へ",
    "href": "slide/intro_rct.html#相関から因果へ",
    "title": "方法論特殊講義III",
    "section": "相関から因果へ",
    "text": "相関から因果へ\n原因（\\(X\\)）と結果（\\(Y\\)）の関係\n\n\n\n\n\n\n\n\n\n\n\n\n年齢（世代）と投票率の関係（架空の例）\n\n年齢が上がると高い投票率\n\n相関関係\n統計分析から得られる結果は相関関係のみ\n\n理論/デザインを用いて相関関係が因果関係であることを説得\n「相関関係\\(\\rightarrow\\)因果関係」における障害物\n\nSelection Bias\nSimultaneity\nSpurious Correlation\nReverse Causality\nOmitted Variable Biasなど"
  },
  {
    "objectID": "slide/intro_rct.html#同時性",
    "href": "slide/intro_rct.html#同時性",
    "title": "方法論特殊講義III",
    "section": "同時性",
    "text": "同時性\nSimultaneity\n\n\n\n\n\n\n\n\n原因と結果の間に双方向の因果関係が存在\n\n例）お酒（原因; \\(X\\)）とストレス（結果; \\(Y\\)）の関係\n\n酒を飲むとストレスが貯まる\nストレス解消のために酒を飲む\n酒を飲むとストレスが貯まる\nストレス解消のために酒を飲む\n酒を飲むとストレスが貯まる\n…\n\n\\(\\rightarrow\\) 地獄のような無限ループ\n\n\\(\\Rightarrow\\) 酒がストレスに与える影響は?"
  },
  {
    "objectID": "slide/intro_rct.html#見かけ上の相関",
    "href": "slide/intro_rct.html#見かけ上の相関",
    "title": "方法論特殊講義III",
    "section": "見かけ上の相関",
    "text": "見かけ上の相関\nSpurious Correlation、擬似相関\n\nたまたま相関関係がある場合\n\n例) メイン州の離婚率一人当たりマーガリンの消費量"
  },
  {
    "objectID": "slide/intro_rct.html#見かけ上の相関-1",
    "href": "slide/intro_rct.html#見かけ上の相関-1",
    "title": "方法論特殊講義III",
    "section": "見かけ上の相関",
    "text": "見かけ上の相関\nSpurious Correlation、擬似相関\n\n共通の要因からの影響\n\n例) ビール消費量とアイスクリーム消費量"
  },
  {
    "objectID": "slide/intro_rct.html#見かけ上の相関-2",
    "href": "slide/intro_rct.html#見かけ上の相関-2",
    "title": "方法論特殊講義III",
    "section": "見かけ上の相関",
    "text": "見かけ上の相関\nSpurious Correlation、擬似相関\n\n共通の要因からの影響\n\n例) ゲームをやると身長が伸びる説"
  },
  {
    "objectID": "slide/intro_rct.html#逆の因果",
    "href": "slide/intro_rct.html#逆の因果",
    "title": "方法論特殊講義III",
    "section": "逆の因果",
    "text": "逆の因果\nReverse Causality\n\n例) 心臓移植と生存率の例\n\n\n\n\n\n\n5年後に死亡\n5年後に生存\n\n\n\n\n心臓移植を\n受けた\n10名\n5名\n\n\n\n受けなかった\n5名\n10名\n\n\n\n\n心臓移植を受けたら死亡確率が上がる?\n死亡確率が高い人が心臓移植を受ける?"
  },
  {
    "objectID": "slide/intro_rct.html#逆の因果-1",
    "href": "slide/intro_rct.html#逆の因果-1",
    "title": "方法論特殊講義III",
    "section": "逆の因果",
    "text": "逆の因果\nReverse Causality\n\n「人気だから4文字に略されるのか、4文字に略せるからヒットす るのか、どっちなんでしょうね」"
  },
  {
    "objectID": "slide/intro_rct.html#欠落変数バイアス",
    "href": "slide/intro_rct.html#欠落変数バイアス",
    "title": "方法論特殊講義III",
    "section": "欠落変数バイアス",
    "text": "欠落変数バイアス\nOmitted Variable Bias\n例) 真のモデルが\\(Y = \\beta_0 + \\beta_1 \\cdot X + \\beta_2 \\cdot Z + e\\)の場合\n\n\n\n\n\n\n\n\n\n\n\n\n\nモデルに\\(Z\\)が含まれていなくても\\(\\beta_1\\)の推定値は変化\\(\\times\\)\n\n\\(X\\)と\\(Z\\)は独立（\\(X \\perp Z\\)）\n=\\(X\\)と\\(Z\\)の共分散が0（\\(\\sigma_{X, Z} = 0\\)）"
  },
  {
    "objectID": "slide/intro_rct.html#欠落変数バイアス-1",
    "href": "slide/intro_rct.html#欠落変数バイアス-1",
    "title": "方法論特殊講義III",
    "section": "欠落変数バイアス",
    "text": "欠落変数バイアス\nOmitted Variable Bias\n例) 真のモデルが\\(Y = \\beta_0 + \\beta_1 \\cdot X + \\beta_2 \\cdot Z + e\\)の場合\n\n\n\n\n\n\n\n\n\n\n\n\n\nモデルに\\(Z\\)が含まれていない場合、\\(\\beta_1\\)の推定値にバイアス\n\n\\(Z \\rightarrow X\\)の関係が存在\n\\(\\sigma_{X, Z} \\neq 0\\)\n\n\\(\\beta_1\\)の真の値（=不偏推定量）を推定するためには\\(X\\)と\\(Y\\)両方と相関する変数すべてが必要\n\nそもそも、「真の値」とは？\n\\(X\\)と\\(Y\\)両方と相関するすべての変数は特定可能? 測定可能?\n\n\\(\\rightarrow\\) データ分析から得られた結果はあくまでも「分析モデルが想定している世界」のものに過ぎない\n\n定量的手法は反証可能性を高めやすい手法（=科学的な手法になりやすい）であって、科学そのものを保障するものでもなく、得られた結果が真理であることを保障するものでもない。"
  },
  {
    "objectID": "slide/intro_rct.html#自己選択バイアス",
    "href": "slide/intro_rct.html#自己選択バイアス",
    "title": "方法論特殊講義III",
    "section": "自己選択バイアス",
    "text": "自己選択バイアス\n(Self-)Selection Bias\n\n例1) 職業訓練と期待収入\n\n\n\n\n\n\n3年後の収入\n\n\n\n\n職業訓練を\n受けた\n6349ドル\n\n\n\n受けなかった\n6984ドル\n\n\n\n\n職業訓練を受けたら収入が上がる?\nもともと低収入の人が職業訓練を受けようとする?\n参考) 心臓移植の例も自己選択のバイアスとして解釈可能\n参考) 交絡因子の不在として解釈可能（就労意欲など）"
  },
  {
    "objectID": "slide/intro_rct.html#内生性",
    "href": "slide/intro_rct.html#内生性",
    "title": "方法論特殊講義III",
    "section": "内生性",
    "text": "内生性\nこれまでの多くの例は内生性（endogeneity）の問題\n\n内生性: 説明変数と誤差項間に相関が存在\n\n誤差項と相関のある説明変数: 内生変数（endogenous variable）\n\n内生性がある場合、推定値は一致推定量でも、不偏推定量でもはない\n\nサンプルサイズ（\\(N\\)）をいくら増やしても無駄\n\n内生性の原因\n\n同時性\n欠落変数バイアス\n測定誤差\n自己選択バイアス\n\n最近の教科書はこれはすべてを自己選択バイアスや欠落変数バイアスでまとめる傾向\n\n\n\n 内生性の除外 \\(\\rightarrow\\) 因果効果の推定"
  },
  {
    "objectID": "slide/intro_rct.html#因果関係の例",
    "href": "slide/intro_rct.html#因果関係の例",
    "title": "方法論特殊講義III",
    "section": "因果関係の例",
    "text": "因果関係の例\nソンさんの講義を履修することで期待年収が上がるか\n\n藤村君の場合：ソンさんの講義を履修し、年収が5000万円に\n\nソンさんの授業のおかげで富裕層になった（次は社交界進出）\n友達に教えてあげよう\n\n\n講義履修の効果\n\n処置：ソンさんの講義を履修するか否か\n効果：履修した場合の年収 − 履修しなかった場合の年収"
  },
  {
    "objectID": "slide/intro_rct.html#因果関係の例-1",
    "href": "slide/intro_rct.html#因果関係の例-1",
    "title": "方法論特殊講義III",
    "section": "因果関係の例",
    "text": "因果関係の例\nソンさんの講義を履修することで期待年収が上がるか\n\n藤村君の場合：ソンさんの講義を履修し、年収が5000万円に\n\nソンさんの授業のおかげで富裕層になった（次は社交界進出）\n友達に教えてあげよう\n\n\n講義履修の効果（ケース1）\n\n藤村君がソンさんの授業を履修しなくても年収5000万円なら\n\nソンさんの講義の因果効果は0\n\n\n\n\n\n\n履修しなかった場合の年収(A)\n履修した場合の年収(B)\n効果(B-A)\n\n\n\n\nケース1\n5000万\n5000万\n0万"
  },
  {
    "objectID": "slide/intro_rct.html#因果関係の例-2",
    "href": "slide/intro_rct.html#因果関係の例-2",
    "title": "方法論特殊講義III",
    "section": "因果関係の例",
    "text": "因果関係の例\nソンさんの講義を履修することで期待年収が上がるか\n\n藤村君の場合：ソンさんの講義を履修し、年収が5000万円に\n\nソンさんの授業のおかげで富裕層になった（次は社交界進出）\n友達に教えてあげよう\n\n\n講義履修の効果（ケース2）\n\n藤村君がソンさんの授業を履修しなかった場合、年収1000万円なら\n\nソンさんの講義の因果効果は4000万円\n一生ソンさんには頭が上がらない\n\n\n\n\n\n\n履修しなかった場合の年収(A)\n履修した場合の年収(B)\n効果(B-A)\n\n\n\n\nケース2\n1000万\n5000万\n4000万"
  },
  {
    "objectID": "slide/intro_rct.html#因果関係の例-3",
    "href": "slide/intro_rct.html#因果関係の例-3",
    "title": "方法論特殊講義III",
    "section": "因果関係の例",
    "text": "因果関係の例\nソンさんの講義を履修することで期待年収が上がるか\n\n藤村君の場合: ソンさんの講義を履修し、年収が5000万円に\n\nソンさんの授業のおかげで富裕層になった（次は社交界進出）\n友達に教えてあげよう\n\n\n講義履修の効果（ケース3）\n\n藤村君がソンさんの授業を履修しなかった場合、年収8000万円なら\n\nソンさんの講義の因果効果は-3000万\nソンさんは悪くない\n\n\n\n\n\n\n履修しなかった場合の年収(A)\n履修した場合の年収(B)\n効果(B-A)\n\n\n\n\nケース3\n8000万\n5000万\n-3000万"
  },
  {
    "objectID": "slide/intro_rct.html#因果関係の例-4",
    "href": "slide/intro_rct.html#因果関係の例-4",
    "title": "方法論特殊講義III",
    "section": "因果関係の例",
    "text": "因果関係の例\nソンさんの講義を履修することで期待年収が上がるか\n\n藤村君の場合：ソンさんの講義を履修し、年収が5000万円に\n\nソンさんの授業のおかげで富裕層になった（次は社交界進出）\n友達に教えてあげよう\n\n\n講義履修の効果\n\nソンさんの講義を履修しなかった場合の藤村君の年収は…?\n\n個人（藤村君）における処置効果を推定する際にはこれが不可欠\n\n\n\n\n\n\n履修しなかった場合の年収(A)\n履修した場合の年収(B)\n効果(B-A)\n\n\n\n\nケース1\n5000万\n5000万\n0万\n\n\nケース2\n1000万\n5000万\n4000万\n\n\nケース3\n8000万\n5000万\n-3000万"
  },
  {
    "objectID": "slide/intro_rct.html#潜在的結果枠組み",
    "href": "slide/intro_rct.html#潜在的結果枠組み",
    "title": "方法論特殊講義III",
    "section": "潜在的結果枠組み",
    "text": "潜在的結果枠組み\nNeyman-Rubin-HollandのPotential Outcome Framework\n\n\\(i\\)：学生ID（\\(i = 1,2,3,...,N\\)）\n\\(T\\)：処置\n\n学生\\(i\\)が謎の薬を飲んだ（\\(T_i = 1\\)）\n学生\\(i\\)が謎の薬を飲まなかった（\\(T_i = 0\\)）\n\n\\(Y_i(T_i = 1)\\)：学生\\(i\\)が謎の薬を飲んだ場合の数学成績\n\\(Y_i(T_i = 0)\\)：学生\\(i\\)が謎の薬を飲まなかった場合の数学成績\n\\(ITE_i = Y_i(T_i = 1) − Y_i(T_i = 0)\\)：学生\\(i\\)における薬の処置効果\n\nITE：Individual Treatment Effect（個人における処置効果）\n\n= UTE：Unit Treatment Effect\n\n全く同じ個人において薬を飲んだ場合と飲まなかった場合の数学成績の差 = 謎の薬の因果効果"
  },
  {
    "objectID": "slide/intro_rct.html#薬の効果は",
    "href": "slide/intro_rct.html#薬の効果は",
    "title": "方法論特殊講義III",
    "section": "薬の効果は?",
    "text": "薬の効果は?\nITEの平均値は-4であり、個人差はあるものの、全体的に薬は成績に負の影響\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(ITE_i\\)\n\n\n\n\n1\n1\n77\n85\n8\n\n\n2\n1\n49\n59\n10\n\n\n3\n1\n60\n66\n6\n\n\n4\n0\n61\n44\n-17\n\n\n5\n0\n50\n39\n-11\n\n\n6\n0\n75\n55\n-20\n\n\n平均\n\n62\n58\n-4"
  },
  {
    "objectID": "slide/intro_rct.html#因果推論の根本問題-1",
    "href": "slide/intro_rct.html#因果推論の根本問題-1",
    "title": "方法論特殊講義III",
    "section": "因果推論の根本問題",
    "text": "因果推論の根本問題\nしかし、各ケースにおいて観察できるのは\\(Y_i(T_i = 1)\\)か\\(Y_i(T_i = 0)\\)、片方のみ\n\n\\(Y_{i \\in \\{1, 2, 3\\}}(T_{i \\in \\{1, 2, 3\\}} = 0)\\)は反実仮想（counterfactual）であり、観察不可\n\\(Y_{i \\in \\{4, 5, 6\\}}(T_{i \\in \\{4, 5, 6\\}} = 1)\\)も反実仮想\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(\\mbox{ITE}_i\\)\n\n\n\n\n1\n1\n観察不可\n85\n計算不可\n\n\n2\n1\n観察不可\n59\n計算不可\n\n\n3\n1\n観察不可\n66\n計算不可\n\n\n4\n0\n61\n観察不可\n計算不可\n\n\n5\n0\n50\n観察不可\n計算不可\n\n\n6\n0\n75\n観察不可\n計算不可\n\n\n平均\n\n62\n70\n8\n\n\n\n\n\n「みんなで薬やろうぜ」って言っていいのか"
  },
  {
    "objectID": "slide/intro_rct.html#世界一受けたいソンさんの授業",
    "href": "slide/intro_rct.html#世界一受けたいソンさんの授業",
    "title": "方法論特殊講義III",
    "section": "世界一受けたいソンさんの授業",
    "text": "世界一受けたいソンさんの授業\n履修者5名と非履修者5名の年収の比較\n\nITEは分からないが、平均値の差分を見ると、+100万円の効果\nソンさんはマジ神なのか\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(\\mbox{ITE}_i\\)\n\n\n\n\n1\n1\n?\n700\n?\n\n\n2\n1\n?\n1000\n?\n\n\n3\n1\n?\n550\n?\n\n\n4\n1\n?\n350\n?\n\n\n5\n1\n?\n400\n?\n\n\n6\n0\n400\n?\n?\n\n\n7\n0\n500\n?\n?\n\n\n8\n0\n350\n?\n?\n\n\n9\n0\n750\n?\n?\n\n\n10\n0\n500\n?\n?\n\n\n平均\n\n500\n600\n100"
  },
  {
    "objectID": "slide/intro_rct.html#世界一受けたいソンさんの授業-1",
    "href": "slide/intro_rct.html#世界一受けたいソンさんの授業-1",
    "title": "方法論特殊講義III",
    "section": "世界一受けたいソンさんの授業",
    "text": "世界一受けたいソンさんの授業\n履修者5名と非履修者5名の年収の比較（ケース1）\n\nITEの平均値：80万円\n80万円の価値があるソンさんの講義、みんなで履修しよう!\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(\\mbox{ITE}_i\\)\n\n\n\n\n1\n1\n550\n700\n150\n\n\n2\n1\n650\n1000\n350\n\n\n3\n1\n600\n550\n-50\n\n\n4\n1\n300\n350\n50\n\n\n5\n1\n300\n400\n100\n\n\n6\n0\n400\n300\n-100\n\n\n7\n0\n500\n700\n200\n\n\n8\n0\n350\n600\n250\n\n\n9\n0\n750\n700\n-50\n\n\n10\n0\n500\n400\n-100\n\n\n平均\n\n490\n570\n80"
  },
  {
    "objectID": "slide/intro_rct.html#世界一受けたいソンさんの授業-2",
    "href": "slide/intro_rct.html#世界一受けたいソンさんの授業-2",
    "title": "方法論特殊講義III",
    "section": "世界一受けたいソンさんの授業",
    "text": "世界一受けたいソンさんの授業\n履修者5名と非履修者5名の年収の比較（ケース2）\n\nITEの平均値：-20万円\nソンさんは悪くない\n\n\n\n\n\\(i\\)\n\\(T_i\\)\n\\(Y_i(T_i = 0)\\)\n\\(Y_i(T_i = 1)\\)\n\\(\\mbox{ITE}_i\\)\n\n\n\n\n1\n1\n800\n700\n-100\n\n\n2\n1\n650\n1000\n350\n\n\n3\n1\n600\n550\n-50\n\n\n4\n1\n400\n350\n-50\n\n\n5\n1\n350\n400\n50\n\n\n6\n0\n400\n300\n-100\n\n\n7\n0\n500\n500\n0\n\n\n8\n0\n350\n400\n50\n\n\n9\n0\n750\n500\n-250\n\n\n10\n0\n500\n400\n-100\n\n\n平均\n\n530\n510\n-20"
  },
  {
    "objectID": "slide/intro_rct.html#因果推論の根本問題-2",
    "href": "slide/intro_rct.html#因果推論の根本問題-2",
    "title": "方法論特殊講義III",
    "section": "因果推論の根本問題",
    "text": "因果推論の根本問題\n\n\\(Y_i(T_i = 1)\\)か\\(Y_i(T_i = 0)\\)、片方のみしか観察できない状態においてITEから因果効果を推定することは不可能\n\n因果推論の根本問題（The Fundamental Problem of Causal Inference）\n\n\n\n\n解決方法\n\nもう一回、過去に戻って異なる処置を行う"
  },
  {
    "objectID": "slide/intro_rct.html#因果推論の根本問題-3",
    "href": "slide/intro_rct.html#因果推論の根本問題-3",
    "title": "方法論特殊講義III",
    "section": "因果推論の根本問題",
    "text": "因果推論の根本問題\n\n\\(Y_i(T_i = 1)\\)か\\(Y_i(T_i = 0)\\)、片方のみしか観察できない状態において、ITEから因果効果を推定することは不可能\n\nただし、ドラえもんが存在する世界線を除く\n因果推論の根本問題（The Fundamental Problem of Causal Inference）\n\n\n\n\n潜在的結果を直接観察する方法\n\nただし、個々人の潜在的結果ではなく、集団における潜在的結果\n平均処置効果（ATE; Average Treatment Effect）\n\n平均値の差分から平均的な因果効果を推定\nしかし、通常、「平均値の差分 \\(\\neq\\) ATE」\n\n\\(\\Rightarrow\\) 無作為割当の重要性"
  },
  {
    "objectID": "slide/intro_rct.html#信頼できるateの条件",
    "href": "slide/intro_rct.html#信頼できるateの条件",
    "title": "方法論特殊講義III",
    "section": "信頼できるATEの条件",
    "text": "信頼できるATEの条件\nATE 推定値の信頼性を損なう敵: 内生性（しかも、常に存在する）\n例) やる気のある学生だけがソンさんの講義を履修した場合\n\n自己選択バイアス\n\nソンさんの講義は鬼畜すぎるため、やる気満々の学生には役に立つものの、やる気のない学生にとってはむしろ学習意欲が低下\n\n疑似相関\n\nやる気のある学生はいろんな方面で頑張るから、将来年収が高くなる。\n\n測定誤差\n\n履修者の年収がジンバブエ・ドルで測定されている可能性も（これはないか）\n\n\n\n\n内生性は因果推論の敵! どうすれば…?\n\\(\\downarrow\\)\n無作為割当"
  },
  {
    "objectID": "slide/intro_rct.html#無作為割当とは",
    "href": "slide/intro_rct.html#無作為割当とは",
    "title": "方法論特殊講義III",
    "section": "無作為割当とは",
    "text": "無作為割当とは\n無作為割当（random assignment）\n\n処置を受けるかどうかを無作為に割り当てる方法\n\n完全無作為割当：全ての被験者において、どのグループに属するかの確率が等しい\n\\(Pr(T_i = 1) = Pr(T_j = 1) \\mbox{ where } i \\neq j\\)\n\\(Pr(T_i = 0) = Pr(T_j = 0) \\mbox{ where } i \\neq j\\)\n無作為割当の方法は色々\n\n無作為に割り当てると、処置を受けないグループと処置を受けるグループは「集団」として同質なグループになる。\n\n受けないグループ: 統制群（Control Group）\n受けるグループ: 処置群（Treatment Group）\n\n一つの集団を一人の個人として扱い、ITEを測定 \\(\\Rightarrow\\) ATE"
  },
  {
    "objectID": "slide/intro_rct.html#無作為割当の力",
    "href": "slide/intro_rct.html#無作為割当の力",
    "title": "方法論特殊講義III",
    "section": "無作為割当の力",
    "text": "無作為割当の力\nコインを投げ、表（\\(H\\)）なら統制群、裏（\\(T\\)）なら処置群に割当\n\n女性比率が55%、平均年齢が38歳の集団の例\n\n\n\n\nset.seed(19861008)\nData &lt;- tibble(\n   ID = 1:20,\n   Female = sample(0:1, 20, replace = TRUE, \n                   prob = c(0.4, 0.6)),\n   Age    = round(rnorm(20, 38, 10), 0))\n\nData |&gt; \n   summarise(Female = mean(Female),\n             Age    = mean(Age))\n\n# A tibble: 1 × 2\n  Female   Age\n   &lt;dbl&gt; &lt;dbl&gt;\n1   0.55    38\n\n\n\n\n\n\n\n\n\n\n\nID\nFemale\nAge\n　\nID\nFemale\nAge\n\n\n\n\n1\n1\n31\n\n11\n0\n38\n\n\n2\n1\n41\n\n12\n1\n29\n\n\n3\n0\n31\n\n13\n0\n21\n\n\n4\n1\n46\n\n14\n0\n26\n\n\n5\n1\n37\n\n15\n1\n36\n\n\n6\n1\n37\n\n16\n1\n40\n\n\n7\n0\n30\n\n17\n0\n50\n\n\n8\n1\n46\n\n18\n0\n42\n\n\n9\n1\n56\n\n19\n0\n29\n\n\n10\n0\n47\n\n20\n1\n47"
  },
  {
    "objectID": "slide/intro_rct.html#無作為割当の力-1",
    "href": "slide/intro_rct.html#無作為割当の力-1",
    "title": "方法論特殊講義III",
    "section": "無作為割当の力",
    "text": "無作為割当の力\nコイン投げの結果\n\nset.seed(19861008)\nCoin &lt;- sample(c(\"H\", \"T\"), 20, replace = TRUE)\nData$Coin &lt;- Coin\n\n\n\n\n\n\n\n\n\nID\nFemale\nAge\nCoin\n　\nID\nFemale\nAge\nCoin\n\n\n\n\n1\n1\n31\nH\n\n11\n0\n38\nH\n\n\n2\n1\n41\nT\n\n12\n1\n29\nT\n\n\n3\n0\n31\nT\n\n13\n0\n21\nH\n\n\n4\n1\n46\nT\n\n14\n0\n26\nT\n\n\n5\n1\n37\nH\n\n15\n1\n36\nH\n\n\n6\n1\n37\nH\n\n16\n1\n40\nT\n\n\n7\n0\n30\nH\n\n17\n0\n50\nT\n\n\n8\n1\n46\nT\n\n18\n0\n42\nT\n\n\n9\n1\n56\nH\n\n19\n0\n29\nH\n\n\n10\n0\n47\nH\n\n20\n1\n47\nH"
  },
  {
    "objectID": "slide/intro_rct.html#無作為割当の力-2",
    "href": "slide/intro_rct.html#無作為割当の力-2",
    "title": "方法論特殊講義III",
    "section": "無作為割当の力",
    "text": "無作為割当の力\n統制群と処置群が比較的同質的なグループに\n\n統制群（11名）: 女性比率が54.5%、平均年齢が37.2歳\n処置群 (9名): 女性比率が55.6%、平均年齢が39歳\n\n\nData |&gt;\n  group_by(Coin) |&gt;\n  summarise(Female = mean(Female),\n            Age    = mean(Age),\n            N      = n())\n\n# A tibble: 2 × 4\n  Coin  Female   Age     N\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 H      0.545  37.2    11\n2 T      0.556  39       9"
  },
  {
    "objectID": "slide/intro_rct.html#無作為割当の力-3",
    "href": "slide/intro_rct.html#無作為割当の力-3",
    "title": "方法論特殊講義III",
    "section": "無作為割当の力",
    "text": "無作為割当の力\n集団として処置群と統制群は、母集団とほぼ同質\n\n母集団:女性率が55%、平均年齢が38歳\n統制群:女性率が54.5%、平均年齢が37.2歳\n処置群:女性率が55.6%、平均年齢が39歳\n\\(n \\rightarrow \\infty\\) なら2つのグループはより同質的に（大数の弱法則）\n\n\n\n統制群と処置群、母集団はそれぞれ交換可能（exchangeable）\n\n処置群に処置を与えること = 母集団全体に処置を与えること\n統制群に処置を与えないこと = 母集団全体に処置を与えないこと\n\n\n\n\n統制群と処置群の比較で集団を一つの単位としたITE（= ATE）が推定可能\n\n処置を与えた母集団 vs. 処置を与えなかった母集団"
  },
  {
    "objectID": "slide/intro_rct.html#無作為割当の力-4",
    "href": "slide/intro_rct.html#無作為割当の力-4",
    "title": "方法論特殊講義III",
    "section": "無作為割当の力",
    "text": "無作為割当の力\n無作為割当は均質な複数のグループを作る手法\n\n講義履修と年収の例だと、無作為割当をすることによって …\n\n各グループにやる気のある学生とない学生が均等に\n\n自己選択バイアス、擬似相関の除去\n\nジンバブエ・ドルで測定される学生も均等に（これはないか）\n\n測定誤差の除去\n\n\n\n\n\n内生性:処置変数（講義の履修）と誤差項（やる気など）間の相関\n\nコイン投げの結果は被験者（学生）の性質と無関係に行われるため、誤差項と相関がない。\n外生変数（Exogenous variable）\n学生の性質（\\(X\\)）と処置変数（\\(T\\)）は独立している \\(\\Rightarrow\\) \\(X \\perp T\\)\n\n\n\n\n無作為割当は内生性を除去する最良の手法"
  },
  {
    "objectID": "slide/intro_rct.html#無作為抽出と無作為割当",
    "href": "slide/intro_rct.html#無作為抽出と無作為割当",
    "title": "方法論特殊講義III",
    "section": "無作為抽出と無作為割当",
    "text": "無作為抽出と無作為割当\n\n無作為抽出によってサンプル（標本）と母集団が交換可能（実はここが難しい）\n無作為割当によって各グループとサンプルに交換可能（= 各グループ間で交換可能）\n無作為抽出&無作為割当によって各グループと母集団が交換可能（グループへの刺激 = 母集団への刺激）"
  },
  {
    "objectID": "slide/intro_rct.html#ランダム化比較試験とは",
    "href": "slide/intro_rct.html#ランダム化比較試験とは",
    "title": "方法論特殊講義III",
    "section": "ランダム化比較試験とは",
    "text": "ランダム化比較試験とは\nRandomized Controlled Trial（RCT）\n\n無作為割当で複数のグループを作り上げた上で、異なる刺激・処置を与え、結果を観察する手法\n\n社会科学でいう「実験」の多くはこれを指す\n因果推論の王道（best practice）\n\n因果効果をもたらす（と考えられる）処置変数が外生的\n\nグループ間における応答変数の差 = 因果効果\n\nデータ生成過程（Data Generating Process; DGP）への直接介入\n\n「真のモデル」が分かる\n\n\n実験の方法\n\nフィールド実験\n実験室実験\nサーベイ実験\n\nSONG Jaehyun・秦正樹. 2020. 「オンライン・サーベイ実験の方法: 理論編」『理論と方法』35 (1): 92-108.\n秦正樹・SONG Jaehyun. 2020. 「オンライン・サーベイ実験の方法: 実践編」『理論と方法』35 (1): 109-127."
  },
  {
    "objectID": "slide/intro_rct.html#データ生成過程への介入",
    "href": "slide/intro_rct.html#データ生成過程への介入",
    "title": "方法論特殊講義III",
    "section": "データ生成過程への介入",
    "text": "データ生成過程への介入\n以下のデータ生成過程を仮定\n\\[\n\\mbox{Income} = \\beta_0 + \\beta_1 \\cdot \\mbox{Quant} + \\varepsilon\n\\]\n\nIncome：10年後の年収（\\(\\mbox{Income} \\in [0, \\infty)\\)）\nQuant：ソンさんの講義を履修したか否か（\\(\\mbox{Quant} \\in \\{0, 1\\})\\)）\n誤差項（\\(\\varepsilon\\)）には「やる気」や「真面目さ」が含まれるため、Quantと相関がある（\\(\\rightarrow\\) 内生性）\n無作為割当で受講有無を決めると、「やる気」や「真面目さ」はQunatと無関係（= 独立）になる\n\n例) 受講有無をコイン投げ（\\(W\\)）で決める場合、コインの結果は誤差項（やる気や真面目さ）と独立（ただし、全員がコイン投げの結果に従うと仮定）\n\\(\\Rightarrow\\) 内生性がなくなる!"
  },
  {
    "objectID": "slide/intro_rct.html#rctの例",
    "href": "slide/intro_rct.html#rctの例",
    "title": "方法論特殊講義III",
    "section": "RCTの例",
    "text": "RCTの例\nBertand and Mullainathan（2004）\n\n労働市場における人種差別\n約5000人分の架空の履歴書を求人中の会社へ送る\n\n履歴書の内容（性別、人種、能力など）は完全無作為\n履歴書に人種は記入できないため、白人っぽい名前（Emilyなど）、黒人っぽい名前（Jamalなど）を記入\n\n後は、返事を待つだけ\n\n処置変数: 人種（\\(\\in \\{\\mbox{black}, \\mbox{white}\\}\\)）\n応答変数: 連絡の有無（\\(\\in \\{0, 1\\}\\)）"
  },
  {
    "objectID": "slide/intro_rct.html#内生性の可能性",
    "href": "slide/intro_rct.html#内生性の可能性",
    "title": "方法論特殊講義III",
    "section": "内生性の可能性",
    "text": "内生性の可能性\n\n\n\n\n\n\n\n\n\n\n\n\n誤差項（\\(\\varepsilon\\)）には教育水準、親の所得、居住地などが含まれる可能性\n\n実際に人種と上記の要因には相関あり\n人種（処置）と誤差項（\\(\\varepsilon\\)）間の相関関係 \\(\\rightarrow\\) 内生性\n\n黒人が採用されなかった場合…\n\n黒人だから? \\(\\leftarrow\\) 人種差別\\(\\bigcirc\\)\n教育水準が低いから \\(\\leftarrow\\) 人種差別\\(\\times\\)\n\n\n\n \\(\\Rightarrow\\) 内生性がある限り、因果効果の識別は困難  \\(\\Rightarrow\\) ケースによって政策的含意が変わる。"
  },
  {
    "objectID": "slide/intro_rct.html#rctの力",
    "href": "slide/intro_rct.html#rctの力",
    "title": "方法論特殊講義III",
    "section": "RCTの力",
    "text": "RCTの力\n\n\n\n\n白人の名前\n黒人の名前\n\n\n\n\nFemale\n76.42%\n77.45%\n\n\nHighQuality\n50.23%\n50.23%\n\n\nCall Rate\n9.65%\n6.45%\n\n\n計（人）\n2435\n2435\n\n\n\n\n無作為割当の結果、人種と性別・能力の相関がほぼ0に\n\n内生性のない状態\nこの場合、労働市場における人種の因果効果は\n\nATE = 黒人の平均連絡率 − 白人の平均連絡率\n黒人という理由だけで会社から連絡が来る確率が3.2%p\\(\\downarrow\\)\n-3.2%p：人種の因果効果 or 処置効果（treatment effect）"
  },
  {
    "objectID": "slide/intro_rct.html#バランスチェック",
    "href": "slide/intro_rct.html#バランスチェック",
    "title": "方法論特殊講義III",
    "section": "バランスチェック",
    "text": "バランスチェック\n無作為割当が行われているか否かを確認\n\n\n\n\n\n\n\n\n\n\n\n\n標準化差分を使用\n\nStandardized Bias（Standardized Difference）\n\nサンプルサイズの影響\\(\\times\\)\n統計的検定ではない\n\n\\(t\\)検定、ANOVA、 \\(\\chi^2\\)検定は\\(\\times\\)\n\nバランスチェックに統計的有意性検定は使わない\n\n{cobalt}、{BalanceR}など"
  },
  {
    "objectID": "slide/intro_rct.html#標準化差分について",
    "href": "slide/intro_rct.html#標準化差分について",
    "title": "方法論特殊講義III",
    "section": "標準化差分について",
    "text": "標準化差分について\n連続変数\n\\[\n\\mbox{SB}_{T-C} = 100 \\cdot \\frac{\\bar{X}_T - \\bar{X}_C}{\\sqrt{0.5 \\cdot (s_T^2 + s_C^2)}}\n\\]\n二値変数\n\\[\n\\mbox{SB}_{T-C} = 100 \\cdot \\frac{\\bar{X}_T - \\bar{X}_C}{\\sqrt{0.5 \\cdot (\\bar{X}_T(1-\\bar{X}_T) + \\bar{X}_C(1-\\bar{X}_C))}}\n\\]\n\n\\(\\bar{X}_T\\)：処置群におけるXの平均値\n\\(s_T^2\\)：処置群におけるXの分散\n\\(|\\mbox{SB}|\\)が小さいほどバランス\n\n明確な基準はないが、3、5、10、25などを使用\n\nグループが3つ以上の場合、それぞれのペアで実行"
  },
  {
    "objectID": "slide/intro_rct.html#因果効果の推定",
    "href": "slide/intro_rct.html#因果効果の推定",
    "title": "方法論特殊講義III",
    "section": "因果効果の推定",
    "text": "因果効果の推定\n\n方法1： グループ間の応答変数の差分の検定（\\(t\\)検定; 応答変数の尺度に応じてノンパラメトリック分析）\n\n因果効果（ATE)）：\\(\\mathbb{E}[\\mbox{Call}|\\mbox{Race = Black}] - \\mathbb{E}[\\mbox{Call}|\\mbox{Race = White}] = -0.032\\)\nATE = 0の帰無仮説の検定\n\n\\(t = −4.117\\)（\\(\\mbox{df}\\) = 4711.7）; \\(p\\) &lt; 0.001; 95% CI = [−0.047, −0.017]\n\n\n方法2： 単回帰分析（線形、ロジスティックス、プロビットなど）\n\n\n\n\n\n\n\n\n\n\n線形回帰分析（LPM）\nロジスティック回帰分析\nプロビット回帰分析\n\n\n\n\nIntercept\n0.064 (0.006)\n-2.675 (0.083)\n-1.518 (0.040)\n\n\nWhite\n0.032 (0.008)\n0.438 (0.107)\n0.217 (0.053)\n\n\nNum.Obs.\n4870\n4870\n4870\n\n\nAIC\n1130.5\n2713.9\n2713.9\n\n\nF\n16.931\n16.669\n16.836\n\n\n\n\n\n\n\n\n\n\nFreedman, David A. 2008. “Randomization Does Not Justify Logistic Regression,” Statistical Science Statistical Science, 23(2): 237-249.\n\nLogit：一致推定量\\(\\times\\) & 不偏推定量\\(\\times\\)\nLinear：一致推定量\\(\\bigcirc\\) & 不偏推定量\\(\\times\\)\n一致性と不偏性の違いについて"
  },
  {
    "objectID": "slide/intro_rct.html#因果効果の推定-重回帰分析は",
    "href": "slide/intro_rct.html#因果効果の推定-重回帰分析は",
    "title": "方法論特殊講義III",
    "section": "因果効果の推定: 重回帰分析は?",
    "text": "因果効果の推定: 重回帰分析は?\n無作為割当のおかげですべての変数が互いに独立\n\n重回帰分析をしても人種のATEは変化しない（OVBがない）\n\n無作為割当の場合、回帰はしてもしなくても良い\n\n現実的に完全にバランスが取れていないため、若干の変化はある\n\n\n\n\n\n\n\n\n\n\nCoef. (SE)\n\n\n\n\nIntercept\n0.060 (0.023)\n\n\nWhite\n0.032 (0.008)\n\n\nFemale\n0.007 (0.009)\n\n\nMilitary\n-0.027 (0.014)\n\n\nEducation\n-0.002 (0.005)\n\n\nHigh Quality\n0.019 (0.008)\n\n\nNum.Obs.\n4870\n\n\nAIC\n1130.3\n\n\nF\n5.025"
  },
  {
    "objectID": "slide/intro_rct.html#因果効果の不均一性",
    "href": "slide/intro_rct.html#因果効果の不均一性",
    "title": "方法論特殊講義III",
    "section": "因果効果の不均一性",
    "text": "因果効果の不均一性\n因果効果が下位グループによって異なる場合\n\n因果効果の不均一性（heterogeneous treatment effects）\n\n例) 性別によって薬の効果が異なる場合\n薬の効果が男性なら 1、女性なら 2 の場合\n\n男女比が1:1なら、ATEは1.5に\n\n薬の効果が男性なら 4、女性なら-1 の場合\n\n男女比が1:1なら、ATEは1.5だが…\n\n\n方法1: 男女に分けてATEを推定\n方法2: 性別と処置有無の交差項を投入した重回帰分析\n参考) Bryan, Christopher J., Elizabeth Tipton and David S. Yeager. 2021. “Behavioural science is unlikely to change the world without a heterogeneity revolution,” Nature Human Behaviour. 5: 980–989."
  },
  {
    "objectID": "slide/intro_rct.html#因果効果の不均一性-1",
    "href": "slide/intro_rct.html#因果効果の不均一性-1",
    "title": "方法論特殊講義III",
    "section": "因果効果の不均一性",
    "text": "因果効果の不均一性\n\nintro_data2.csvの例\n\n\n\n\ndata2 &lt;- read_csv(\"data/intro_data2.csv\")\n\ndata2 &lt;- data2 |&gt;\n  rename(Treatment = T, Female = F)\n\ndata2\n\n\n\n\n# A tibble: 500 × 4\n      ID      Y Treatment Female\n   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1     1 1.09           0      1\n 2     2 0.0281         0      1\n 3     3 1.65           0      0\n 4     4 3.83           1      1\n 5     5 2.65           1      1\n 6     6 1.24           1      1\n 7     7 0.136          1      0\n 8     8 0.507          0      1\n 9     9 2.99           1      1\n10    10 4.34           1      1\n11    11 0.436          0      0\n12    12 0.696          1      0\n13    13 0.855          0      0\n14    14 0.616          1      0\n15    15 0.420          0      1\n# ℹ 485 more rows"
  },
  {
    "objectID": "slide/intro_rct.html#因果効果の不均一性-2",
    "href": "slide/intro_rct.html#因果効果の不均一性-2",
    "title": "方法論特殊講義III",
    "section": "因果効果の不均一性",
    "text": "因果効果の不均一性\n方法1: 男女に分けてATEを推定\n\n比較コード1コード2コード3\n\n\n\n\n\n\n統制群\n処置群\nATE\n\\(t\\)\n\\(p\\)\n\n\n\n\n男性のみ\n0.611\n1.561\n0.951\n-7.521\n&lt; 0.001\n\n\n女性のみ\n0.493\n2.480\n1.987\n-15.573\n&lt; 0.001\n\n\n全体\n0.551\n2.057\n1.506\n-15.945\n&lt; 0.001\n\n\n\n\n\n男性のみ\n\ndata2 |&gt; \n  filter(Female == 0) |&gt;\n  t.test(Y ~ Treatment, data = _)\n\n\n    Welch Two Sample t-test\n\ndata:  Y by Treatment\nt = -7.5211, df = 235.95, p-value = 1.132e-12\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -1.1996845 -0.7016501\nsample estimates:\nmean in group 0 mean in group 1 \n      0.6105137       1.5611810 \n\n\n\n\n女性のみ\n\ndata2 |&gt;\n  filter(Female == 1) |&gt;\n  t.test(Y ~ Treatment, data = _)\n\n\n    Welch Two Sample t-test\n\ndata:  Y by Treatment\nt = -15.573, df = 259.72, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -2.238053 -1.735599\nsample estimates:\nmean in group 0 mean in group 1 \n      0.4931905       2.4800169 \n\n\n\n\n全体\n\ndata2 |&gt; \n  t.test(Y ~ Treatment, data = _)\n\n\n    Welch Two Sample t-test\n\ndata:  Y by Treatment\nt = -15.945, df = 494.24, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -1.692061 -1.320817\nsample estimates:\nmean in group 0 mean in group 1 \n      0.5509135       2.0573524"
  },
  {
    "objectID": "slide/intro_rct.html#因果効果の不均一性-3",
    "href": "slide/intro_rct.html#因果効果の不均一性-3",
    "title": "方法論特殊講義III",
    "section": "因果効果の不均一性",
    "text": "因果効果の不均一性\n方法2: 性別と処置有無の交差項を投入した重回帰分析\n\n\n\nlm(Y ~ Treatment * Female, data = data2) |&gt;\n   summary()\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)       \n                  0.611 (0.091) \n                \n                \n                  Treatment         \n                  0.951 (0.131) \n                \n                \n                  Female            \n                  -0.117 (0.127)\n                \n                \n                  Treatment × Female\n                  1.036 (0.180) \n                \n                \n                  Num.Obs.          \n                  500           \n                \n                \n                  R2 Adj.           \n                  0.398         \n                \n                \n                  F                 \n                  110.905       \n                \n        \n      \n    \n\n\n\n\n\\[\n\\begin{align}\n\\hat{y} & = \\beta_0 + \\beta_1 \\mbox{Treatment} + \\beta_2 \\mbox{Female} + \\beta_3 \\mbox{Treatment} \\cdot \\mbox{Female} \\\\\n& = \\beta_0 + (\\beta_1 + \\beta_3 \\mbox{Female}) \\mbox{Treatment} + \\beta_2 \\mbox{Female}.\n\\end{align}\n\\]\n\n処置効果はTreatmentの係数\n\n\\(\\beta_1 + \\beta_3 \\mbox{Female}\\)\n\\(\\Rightarrow\\) 処置効果がFemaleの値にも依存\n\n男性のATE: \\(\\beta_1 + \\beta_3 \\cdot 0 = \\beta_1\\) = 0.951\n女性のATE: \\(\\beta_1 + \\beta_3 \\cdot 1 = \\beta_1 + \\beta_3\\) = 1.987"
  },
  {
    "objectID": "slide/intro_rct.html#因果推論の前提sutva",
    "href": "slide/intro_rct.html#因果推論の前提sutva",
    "title": "方法論特殊講義III",
    "section": "因果推論の前提:SUTVA",
    "text": "因果推論の前提:SUTVA\nStable Unit Treatment Value Assumption\n\n非干渉性処置の無分散性\n\n\n非干渉性: 他人の処置・統制有無が処置効果に影響を与えないこと\n\n例）AさんITEは…\n\n例1）Bさんが統制群の場合は10、処置群の場合は5 \\(\\leftarrow\\) \n例2）Bさんが統制群の場合も、処置群の場合も、5 \\(\\leftarrow\\) \n\n\n\n\n\n\n\n\n\n\n例1\n\n\n\nAさんが統制群\nAさんが処置群\n\n\n\n\nBさんが統制群\n0\n10\n\n\nBさんが処置群\n15\n20\n\n\n\n\n\n\n例2\n\n\n\nAさんが統制群\nAさんが処置群\n\n\n\n\nBさんが統制群\n5\n10\n\n\nBさんが処置群\n15\n20\n\n\n\n\n\n\n\n\n\n処置の無分散性: 同じグループに属する対象は同じ処置を受けること\n\n手術の場合：医者、設備、手順、環境など\n投票参加：当日、期日前など\n\n\n\n\n\nサーベイ実験では問題にならない場合が多い\n\n実験室実験、フィールド実験の場合、「非干渉性」には気をつける。\n例）隣の人が見てるのとと私が見てるのが違いますが…?"
  },
  {
    "objectID": "slide/intro_rct.html#二重盲検法",
    "href": "slide/intro_rct.html#二重盲検法",
    "title": "方法論特殊講義III",
    "section": "二重盲検法",
    "text": "二重盲検法\n二重盲検法（Double Blind Test）\n\n「ある被験者がどのような処置を受けているか」について、研究者と被験者両方において不明な状態で実験を行う。\n\n\n二重盲検法を使えば以下の問題点に対処することが可能\n\nプラセボ効果（placebo effect）：偽薬が与えられても、薬だと信じ込む 事によって何らかの効果が生じる。\nホーソン効果（Hawthorne effect）：自分が観察されていることを認知さ れることによって何らかの効果が生じる。\n観察者効果（observer/experimenter effect）：研究者の期待により被験者へ の対応が異なったり、被験者がその期待に添えるように行動すること"
  },
  {
    "objectID": "slide/intro_rct.html#データ",
    "href": "slide/intro_rct.html#データ",
    "title": "方法論特殊講義III",
    "section": "データ",
    "text": "データ\nこれまで紹介した例題\n\n労働市場と人種差別：intro_data1.dta\n\nMarianne Bertrand and Sendhil Mullainathan. 2004. “Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination,” American Economic Review, 94(4) pp. 991–1013\n\n処置効果の不均一性：intro_data2.csv\n\n架空データ\n\n\nLab Session用のデータ\n\n社会的圧力と投票参加：intro_data3.csv\n\nAlan S. Gerber, Donald P. Green, and Christopher W. Larimer. 2008. “Social Pressure and Voter Turnout: Evidence from a Large-Scale Field Experiment,” American Political Science Review, 102(1) pp. 33–48"
  },
  {
    "objectID": "slide/intro_rct.html#バランスチェック-1",
    "href": "slide/intro_rct.html#バランスチェック-1",
    "title": "方法論特殊講義III",
    "section": "バランスチェック",
    "text": "バランスチェック\n処置が複数の場合、組み合わせごとに標準化差分を計算"
  },
  {
    "objectID": "slide/intro_rct.html#処置効果の可視化",
    "href": "slide/intro_rct.html#処置効果の可視化",
    "title": "方法論特殊講義III",
    "section": "処置効果の可視化",
    "text": "処置効果の可視化"
  },
  {
    "objectID": "slide/intro_rct.html#実習内容",
    "href": "slide/intro_rct.html#実習内容",
    "title": "方法論特殊講義III",
    "section": "実習内容",
    "text": "実習内容\n\nRの基礎（プロジェクト管理、データの読み込みなど）\n記述統計量の計算\nバランスチェック\n処置効果の推定\n処置効果の報告\n\n\n\n\n\nhttps://www.jaysong.net/kobe-ci/"
  },
  {
    "objectID": "intro/file.html",
    "href": "intro/file.html",
    "title": "ファイル管理",
    "section": "",
    "text": "「ファイル・システム」も合わせて読もう！\n\n\n\n　本ページの内容を読む前に、ファイルシステムの詳細などを解説した「ファイル・システム」も合わせて読むことを強く推奨する。\nフォルダー/ファイルの管理はJupyterHub内でも、RStudio内でもできるが、ここではRStudio側で管理する方法を紹介する。RStudioを起動し、作業するプロジェクトを開き、Filesペインを確認しよう。RStudioを経由したフォルダー/ファイルの管理は全てFilesペイン上で行われる。",
    "crumbs": [
      "ファイル管理"
    ]
  },
  {
    "objectID": "intro/file.html#フォルダーの管理",
    "href": "intro/file.html#フォルダーの管理",
    "title": "ファイル管理",
    "section": "フォルダーの管理",
    "text": "フォルダーの管理\n　講義、または課題ごとのプロジェクトを作ったら、JupyterHubにプロジェクトのフォルダーが生成される。各プロジェクトごとにRスクリプト、Markdownファイル、出力物（図、文書など）が管理できるが、プロジェクト内のファイルが多くなる可能性もある。この場合、プロジェクト・フォルダー内に更に下位フォルダーを作成し、ファイルを管理した方が望ましい。\n\nフォルダーの作成\n手順1: 現在、Filesペインで表示されているフォルダーがプロジェクトの最上位フォルダーであることを確認する。「Home &gt; プロジェクト名」と表示されていれば問題ない。\n\n\n\n\n\n手順2: New Folderをクリックする。\n\n\n\n\n\n手順3: 作成するフォルダーの名前を入力する。ここではデータなどを集めておくDataという名のフォルダーを作成する。\n\n\n\n\n\n手順4: 正しくフォルダーが作成されているかを確認する。\n\n\n\n\n\n\n\n\n\n\n\nフォルダー名の付け方\n\n\n\nフォルダー名にはローマ字、数字のみを使おう。スペースもなるべく使わず、空白を入れたい場合はスペースの代わりにアンダースコア（_）を使おう。\n\n\n\n\n\n\n\n\nフォルダー in フォルダー\n\n\n\nフォルダー内に更にフォルダーを作成することもできる。一つのフォルダー内にファイルが多すぎる場合、更にフォルダー分けして管理した方が効率的だろう。\n\n\n\n\nフォルダーの削除\n\n\n\n\n\n\nフォルダーの削除は慎重に!\n\n\n\nフォルダーを削除するとフォルダー内のファイルも全て削除される。削除する前には慎重にフォルダー内のファイルを確認しておくこと。\n\n\n手順1: 削除するフォルダーの左にチェックを付け、Deleteをクリックする。\n\n\n\n\n\n手順2: Yesをクリックする。",
    "crumbs": [
      "ファイル管理"
    ]
  },
  {
    "objectID": "intro/file.html#ファイルの管理",
    "href": "intro/file.html#ファイルの管理",
    "title": "ファイル管理",
    "section": "ファイルの管理",
    "text": "ファイルの管理\n　分析に使用するデータセットを自分のPCにダウンロードしてもそのままJDCat分析ツールで使うことはできない。JDCat分析ツールで使用するためには、ファイルをアップロードする必要がある。これはデータだけでなく、本講義の課題用ファイルについても同様である。\n\nファイルのアップロード\n手順1: ファイルをアップロードしたいフォルダーへ移動する。\n\n下位フォルダーへの移動: フォルダー名をクリックする。\n上位フォルダーへの移動: 「..」をクリックするか、パスが表示されているバーで移動先をクリックする。\n\n手順2: ファイルのアップロード先が正しいかを確認し、Uploadをクリックする。\n\n以下の例はHomework_01プロジェクト・フォルダー内のDataフォルダーがアップロード先である。\n\n\n\n\n\n\n手順3: File to upload:でアップロードしたいファイルを選択する。\n\n\n\n\n\n\n\n\n\n\n\n複数のファイルをアップロードしたい場合\n\n\n\nRStudio上でファイルは一度の一つしかアップロードできない。複数のファイルを同時にアップロードしたい場合は、この作業を繰り返すか、JupyterHubのホーム画面でアップロードする必要がある。\n\n\n手順4: アップロードするファイルをダブルクリックする。\n\n以下ではPrev_Vote.csvというファイルをアップロードする例である。\n\n\n\n\n\n\n手順5: OKをクリックする。\n\n\n\n\n\n手順6: 正しくファイルがアップロードされているかを確認する。\n\n\n\n\n\n\n\nファイルのダウンロード\n　作成した図表をLaTex/Microsoft Word/Powerpoint/Pages/Keynoteなどで使うためには、その図表を自分のPCにダウンロードする必要がある。同様に、課題の出力物をLMSに提出するためにも、出力物を一旦自分のPCにダウンロードしてから提出する必要がある。\n\n\n\n\n\n\n複数ファイルのダウンロード\n\n\n\nアップロードは一度ごとに一つのファイルしかアップロードできないが、ダウンロードは複数のファイルを同時にダウンロードできる。ただし、個別のファイルがダウンロードされるのではなく、一つのファイルととして圧縮（zip形式）されてからダウンロードされる。ダウンロード後はファイルを解凍すること。\n\n\n手順1: ダウンロードするファイル名の左にチェックを付ける。\n\n以下ではMicro_HW01.htmlというファイルをダウンロードする例である。\n\n\n\n\n\n\n手順2: More &gt; Export…をクリックする。\n\n\n\n\n\n手順3: Downloadをクリックする。\n\n\n\n\n\n\n\n\n\n\n\n課題の出力物は提出する前に必ず確認を!!\n\n\n\nLMSで課題を提出するためには出力物を提出する必要があるが、提出する前にダウンロードしたファイルを必ず確認しよう。間違ったファイルを提出した場合でも提出期限内なら差し替え可能だが、期限が過ぎた場合、理由を問わず差し替えは認めない。また、間違ったファイルが提出されたことを宋が個別に知らせることもないため注意しよう。\n\n\n\n\nファイルの削除\nフォルダーの削除と同じ手順で削除できる。\n\n\n\n\n\n\nファイルの場所が分からない\n\n\n\nFileペインではファイルの一覧が確認できる。しかし、これらのファイルがどのフォルダーに入っているかが分からない場合もあろう。この場合、Fileペインの上段バーを確認すること。そこに現在表示されているファイルのパスが表示されている。「Home&gt;プロジェクト名」と表示されている場合、Fileペインに見えるファイルはプロジェクト・フォルダ―直に入っていることを意味する（右上のプロジェクト名とFileペインのプロジェクト名が一致しているか確認すること）。これらのファイルのパスは\"ファイル名\"のみで良い。上段バーのパスが「Home&gt;プロジェクト名&gt;Data」になっている場合、表示されているファイルはプロジェクト・フォルダー内のDataフォルダーに入っていることを意味する。これらのファイルのパスは\"Data/ファイル名\"となる。",
    "crumbs": [
      "ファイル管理"
    ]
  },
  {
    "objectID": "intro/packages.html",
    "href": "intro/packages.html",
    "title": "パッケージ",
    "section": "",
    "text": "Rには様々な関数（functions）が提供されている。算術平均値を求めるmean()、合計を求めるsum()、線形回帰分析を行うlm()、平均値の検定を行うt.test()などがあり、全てを列挙することはできない。しかし、データ分析の技術は日々発展し、Rがデフォルトで提供する関数では不可能ではないが、かなり長いコードが必要な分析を使わざる得ないケースもあろう。Rは開発元だけでなく、誰でも関数を作ることができる。通常なら数百行のコードが必要な分析を一行のコードで実行可能とする関数を多くのRユーザーが作ってきた。これらの関数を集めたのがパッケージである。Rにはグラフ作成に特化したパッケージ、機械学習に特化したパッケージ、テキスト分析に特化したパッケージなど、数千のパッケージが開発されている。このパッケージの豊富さがRの最大のメリットでもある。誰かが新しい分析手法を提案したら、数日内、あるいはその手法が論文として出版される前からRパッケージとして公開されるケースが多い。\n　Rの内蔵関数は料理における包丁のようなものである。包丁があれば理論上、食材を粉々にすることはできよう。料理の達人であれば、問題ないかも知れないが、我々のような一般人では時間もかかるし、途中でミスをおかすかも知れない。一方、ミキサーを使えばだれても簡単に食材を粉々にすることも出来るし、（ミキサーが不良でないなら）ミスの恐れもほぼない。このミキサーがRのパッケージのようなものだ。ミキサーとRパッケージの違いは、ミキサーの入手には金がかかる一方、Rパッケージは無料で入手できる点だ。",
    "crumbs": [
      "パッケージ"
    ]
  },
  {
    "objectID": "intro/packages.html#パッケージとは",
    "href": "intro/packages.html#パッケージとは",
    "title": "パッケージ",
    "section": "",
    "text": "Rには様々な関数（functions）が提供されている。算術平均値を求めるmean()、合計を求めるsum()、線形回帰分析を行うlm()、平均値の検定を行うt.test()などがあり、全てを列挙することはできない。しかし、データ分析の技術は日々発展し、Rがデフォルトで提供する関数では不可能ではないが、かなり長いコードが必要な分析を使わざる得ないケースもあろう。Rは開発元だけでなく、誰でも関数を作ることができる。通常なら数百行のコードが必要な分析を一行のコードで実行可能とする関数を多くのRユーザーが作ってきた。これらの関数を集めたのがパッケージである。Rにはグラフ作成に特化したパッケージ、機械学習に特化したパッケージ、テキスト分析に特化したパッケージなど、数千のパッケージが開発されている。このパッケージの豊富さがRの最大のメリットでもある。誰かが新しい分析手法を提案したら、数日内、あるいはその手法が論文として出版される前からRパッケージとして公開されるケースが多い。\n　Rの内蔵関数は料理における包丁のようなものである。包丁があれば理論上、食材を粉々にすることはできよう。料理の達人であれば、問題ないかも知れないが、我々のような一般人では時間もかかるし、途中でミスをおかすかも知れない。一方、ミキサーを使えばだれても簡単に食材を粉々にすることも出来るし、（ミキサーが不良でないなら）ミスの恐れもほぼない。このミキサーがRのパッケージのようなものだ。ミキサーとRパッケージの違いは、ミキサーの入手には金がかかる一方、Rパッケージは無料で入手できる点だ。",
    "crumbs": [
      "パッケージ"
    ]
  },
  {
    "objectID": "intro/packages.html#インストール",
    "href": "intro/packages.html#インストール",
    "title": "パッケージ",
    "section": "インストール",
    "text": "インストール\n　Rには数万以上のパッケージが存在し、Rをインストールするだけでも数十のパッケージが自動的にインストールされる。しかし、データ分析/ハンドリング/可視化の手法は日々発展しており、R内蔵パッケージだけでは対応が難しい (できないわけではない)。したがって、必要に応じて新しいパッケージを導入する必要があるが、パッケージのインストールするにはConsoleペインに以下のように入力する。\n\n\n\nCode 01\n\ninstall.packages(\"インストールするパッケージ名\")\n\n\n　前期の「ミクロ政治データ分析実習」では{tidyverse}パッケージのみ使用する予定である。ただし、本講義ようにセッティングされた環境を導入する場合、{tidyverse}は既に導入済みであるため、以下のコードは実行しなくても良い。\n\n\n\nCode 02\n\ninstall.packages(\"tidyverse\")",
    "crumbs": [
      "パッケージ"
    ]
  },
  {
    "objectID": "intro/packages.html#アップデート",
    "href": "intro/packages.html#アップデート",
    "title": "パッケージ",
    "section": "アップデート",
    "text": "アップデート\n　特定のパッケージをアップデートする方法はインストールと同じだが、一つ一つのパッケージが全て最新バージョンかどうかを確認するのは大変である。また、久々のアップデートで数十個のパッケージをアップデートする必要があるケースもあろう。この場合、RStudioの内蔵機能を使えば一瞬で更新可能なパッケージのリスト化、インストールができる。\n手順1: PackagesペインのUpdateをクリックする。\n\n\n\n\n\n手順2: アップデートしたいパッケージの左にチェックを付けるか、左下のSelect Allをクリックし、右下のInstall Updatesをクリックする。\n\n\n\n\n\n　インストール、またはアップデートの際、以下のようなメッセージが出力される場合がある。\n  There are binary versions available but the source versions\n  are later:\n      binary source needs_compilation\nterra 1.5-17 1.5-21              TRUE\nyaml   2.2.2  2.3.4              TRUE\n\nDo you want to install from sources the packages which need compilation? (Yes/no/cancel)\n　この場合、Consoleペイン上でYes、no、cancelのいずれかを入力してReturnキー (Enterキー)を押す必要がある。大文字と小文字は区別すること。どうしても最新のパッケージが欲しい場合はYesを入力すれば良いが、インストールに時間がかかる場合がある。一方、noを入力した場合は、若干古いバージョンがインストールされるが、インストールに必要な時間が短いため、基本的にはnoでも問題ないだろう。cancelを入力した場合はアップデートが全てキャンセルされる。\n\n\n\n\n\n\nインストールは1回でOK、読み込みは毎回必要\n\n\n\n　Rを削除して再インストールしたり、（クラウド版のRStudioなら）分析環境を新しく立ち上げない限り、パッケージのインストールは1回で十分だ。しかし、library()関数でパッケージを読み込む作業は、R（RStudio）を開く度に行う必要がある。つまり、読み込んだRパッケージはRを終了すると一旦外されることとなり、改めてRを開いたらもう一度読み込む必要がある。",
    "crumbs": [
      "パッケージ"
    ]
  },
  {
    "objectID": "intro/packages.html#教科書",
    "href": "intro/packages.html#教科書",
    "title": "パッケージ",
    "section": "教科書",
    "text": "教科書\n『私たちのR』の第5章「Rパッケージ」: https://www.jaysong.net/RBook/packages.html",
    "crumbs": [
      "パッケージ"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Causal Inference@Kobe",
    "section": "",
    "text": "JDCat分析ツールの起動（はじめての方は「Rの導入」を参照し、まず分析環境を作成してください。）\n\n\n本ウェブサイトは神戸大学法学研究科/法学部「方法論特殊講義III / プログラム講義計量政治学方法論I」のサポートページです。\n\n\n\n\n\n\nアイコン説明\n\n\n\n\n：JDCat分析ツールの起動\n\n初期設定が必要です。\n\n：Rの教科書（『私たちのR』）\n：本ウェブサイト内の検索\n\n\n\n\n\n\n\n\n\nページ情報\n\n\n\n\n最終更新日: 2024年08月15日\n開発環境\n\nmacOS Sonoma 14.5\nFirefox 129.0.1\nR version 4.4.1 (2024-06-14)\nRStudio 2024.04.2+764\nQuarto 1.5.56\nR package {quarto} 1.4.4"
  },
  {
    "objectID": "syllabus/syllabus.html",
    "href": "syllabus/syllabus.html",
    "title": "シラバス",
    "section": "",
    "text": "科目名：方法論特殊講義III（プログラム講義計量政治学方法論Ⅰ）\n講師：宋財泫（ソン ジェヒョン）\n所属：関西大学総合情報学部\n\nE-mail: songkansai-u.ac.jp\nHomepage: https://www.jaysong.net\n\n時間：2024年8月26〜30日 3〜5限目\n教室：フロンティア館 303教室",
    "crumbs": [
      "シラバス"
    ]
  },
  {
    "objectID": "syllabus/syllabus.html#概要",
    "href": "syllabus/syllabus.html#概要",
    "title": "シラバス",
    "section": "",
    "text": "科目名：方法論特殊講義III（プログラム講義計量政治学方法論Ⅰ）\n講師：宋財泫（ソン ジェヒョン）\n所属：関西大学総合情報学部\n\nE-mail: songkansai-u.ac.jp\nHomepage: https://www.jaysong.net\n\n時間：2024年8月26〜30日 3〜5限目\n教室：フロンティア館 303教室",
    "crumbs": [
      "シラバス"
    ]
  },
  {
    "objectID": "syllabus/syllabus.html#授業の内容",
    "href": "syllabus/syllabus.html#授業の内容",
    "title": "シラバス",
    "section": "授業の内容",
    "text": "授業の内容\n　本講義は、近年政治学において関心が高まっている「因果推論」を行うための諸手段を理解・習得することを目的とする。最初に、最良の因果推論とも称されるRCT（ランダム化比較試験）を説明し、RCT が不可能な際の手法としてマッチング、回帰不連続デザイン、差分の差などを紹介する。",
    "crumbs": [
      "シラバス"
    ]
  },
  {
    "objectID": "syllabus/syllabus.html#評価",
    "href": "syllabus/syllabus.html#評価",
    "title": "シラバス",
    "section": "評価",
    "text": "評価\n\n授業貢献度 30%100%\n\n授業への参加度、質問など\n\n期末レポート 70%\n\n期末レポートの内容は初回の授業で紹介する",
    "crumbs": [
      "シラバス"
    ]
  },
  {
    "objectID": "syllabus/syllabus.html#履修上の注意",
    "href": "syllabus/syllabus.html#履修上の注意",
    "title": "シラバス",
    "section": "履修上の注意",
    "text": "履修上の注意\n　統計学に関する基礎知識が必要である。目安は母平均の差の検定、および線形回帰分析が理解でき、統計ソフトウェアで実行・解釈が可能なレベルである。\n　本講義における共通言語はRである。Rの使い方に関しては既にインターネット上に膨大な情報がある。宋と矢内勇生(高知工科大学)が執筆中の以下の資料を参照することも1つの選択肢である。\n\n宋財泫・矢内勇生. 『私たちの R: ベストプラクティスの探究』\n\nRの導入方法は講義中、宋が解説する。\n\n\n　統計学および定量的分析、Rの使い方については以下の書籍を講義開始日までに読んでおくことを強く推奨する。\n\n浅野正彦・矢内勇生. 2019『Rによる計量政治学』オーム社.\n\n　R スクリプト作成の際、{tidyverse} というパッケージ群を積極的に活用する。この パッケージには {dplyr}、{ggplot2} などのパッケージが含まれている。各パッケージの 使い方を習得するには以下の教材を推奨する。\n\nWickham, Hadley and Grolemund, Garrett. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, O’Reilly. (邦訳あり/原著はインターネットから無料で閲覧可)\n松村優哉・湯谷啓明・紀ノ定保礼・前田和寛 . 2021. 『改訂2版 Rユーザのための RStudio[実践] 入門—tidyverseによるモダンな分析フローの世界—』技術評論社.",
    "crumbs": [
      "シラバス"
    ]
  },
  {
    "objectID": "syllabus/syllabus.html#教科書参考書",
    "href": "syllabus/syllabus.html#教科書参考書",
    "title": "シラバス",
    "section": "教科書・参考書",
    "text": "教科書・参考書\n　以下は本書の内容を（一部）カバーする書籍の目録である。必ずしも購入する必要はないが、予習・復習において適宜参照することを推奨する。\n\n因果推論の理論と実例\n\n【AP 2008】 Angrist, Joahua D., and Jorn-steffen Pischke. 2008. Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton University Press.\n\n『「ほとんど無害」な計量経済学―応用経済学のための実証分析ガイド』 (翻訳はかなり有害)\n\n【AP 2014】 Angrist, Joahua D., and Jorn-steffen Pischke. 2014. Mastering ’Metrics: The Path from Cause to Effect. Princeton University Press.\n【森田 2014】 森田果. 2014.『実証分析入門—データから「因果関係」を読み解く作法』日本評論社.\n【中室・津川 2017】 中室牧子・津川友介. 2017.『「原因と結果」の経済学—データから真実を見抜く思考法』ダイヤモンド社.\n【伊藤 2017】 伊藤公一郎. 2017.『データ分析の力—因果関係に迫る思考法』光文社新書.\n【松林 2021】 松林哲也. 2021.『政治学と因果推論』岩波書店.\n\n理論+R\n\n【星野・田中 2016】 星野匡郎・田中久稔. 2016.『Rによる実証分析—回帰分析から因果分析へ—』オーム社.\n【安井 2020】 安井翔太. 2020. 『効果検証入門—正しい比較のための因果推論/計量経済学の基礎』技術評論社.\n【Cunningham 2021】 Cunningham, Scott. 2021. Causal Inference: The Mixtape. Yale University Press.\n\n『因果推論入門〜ミックステープ：基礎から現代的アプローチまで』\n\n【高橋 2022】 高橋将宜. 2022. 『統計的因果推論の理論と実装』共立出版.\n\n\n\n本講義との関係\n\n\n\n\nIntro/RCT\nMatching\nDiff-in-Diff\nRDD\nIV\n\n\n\n\nAP 2008\nCh.2\nCh.3\nCh.5\nCh.6\nCh.4\n\n\nAP 2014\nCh.1-2\n\nCh.5\nCh.4\nCh.3\n\n\n森田 2014\n第16章\n\n第18章\n第22章\n第20章\n\n\n星野・田中 2016\n第1-8章\n第9章\n\n第10章\n第11章\n\n\n中室・津川 2017\n第1-3章\n第7-8章\n第4章\n第6章\n第5章\n\n\n伊藤 2017\n第1-2章\n\n第5章\n第3章\n\n\n\n安井 2020\n第1章\n第2-3章\n第4章\n第5章\n\n\n\nCunningham 2021\nCh.2-4\nCh.5\nCh.8-10\nCh.6\nCh.7\n\n\n松林 2021\n第1-5章\n\n第8章\n第6章\n第7章\n\n\n高橋 2022\n第1-3章\n第4-12章\n\n第15-18章\n第13-14章",
    "crumbs": [
      "シラバス"
    ]
  },
  {
    "objectID": "syllabus/syllabus.html#講義内容参考文献",
    "href": "syllabus/syllabus.html#講義内容参考文献",
    "title": "シラバス",
    "section": "講義内容・参考文献",
    "text": "講義内容・参考文献\n\n因果推論の考え方\n\nTextbook\n\nImbens, Guido W., and Donald B. Rubin. 2015. Causal Inference for Statistics, Social, and Biomedical Sciences. Cambridge University Press. (Ch. 1 and 2)\n\n『インベンス・ルービン　統計的因果推論（上）』（有斐閣）の第1・2章\n\nHernan, Miguel A., James M. Robins. 2020. Causal Inference. Chapman & Hall/CRC. (Ch. 1)\n\nArticle\n\nHolland, Paul W. 1986. “Statistics and Causal Inference.” Journal of the American Statistical Association, 81: 945–960.\nMarini, Margaret Mooney, and Burton Singer. 1988. “Causality in the Social Sciences.” Sociological Methodology, 18: 347–409.\n\nRubin, Donald B. 2005. “Causal Inference Using Potential Outcomes: Design, Modeling, Decisions.” Journal of the American Statistical Association, 100: 322–331.\n\nBrady, Henry E. 2008. “Causation and Explanation in Social Science.” In Janet M. BoxSteffensmeier, Henry E. Brady, and David Collier, eds. The Oxford Handbook of Political Methodology. Oxford University Press. (Ch. 10)\nKeele, Luke. 2015. “The Statistics of Causal Inference: A View from Political Methodology.” Political Analysis, 23: 313–335.\n\nMonograph\n\n岩波データサイエンス刊行委員会. 2016.『岩波データサイエンス Vol.3』岩波書店.\n\n\n\n\nRCT（Lab Session）\n履修者全員がRの操作に慣れていると判断した場合、Lab Sessionは省略し、最終日に操作変数法の講義を行う。\n\nTextbook (RCT)\n\nImbens, Guido W., and Donald B. Rubin. 2015. Causal Inference for Statistics, Social, and Biomedical Sciences. Cambridge University Press. (Part II)\n\n『インベンス・ルービン　統計的因果推論（上）』（有斐閣）の第2部\n\nHernan, Miguel A., James M. Robins. 2020. Causal Inference. Chapman & Hall/CRC. (Ch. 2)\n\nTextbook (R Language)\n\n飯田健. 2013.『計量政治学』共立出版\nLander, Jared P.. 2017. R for Everyone: Advanced Analytics and Graphics (2nd Edition). Addison-Wesley Professional.\n\n『みんなのR 第2版』\n\nImai, Kosuke. 2017. Quantitative Social Science: An Introduction. Princeton University Press.\n\n『社会科学のためのデータ分析入門 (上) / (下)』\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. O’Reilly Media.\n\n『Rではじめるデータサイエンス』\n\n高橋康介. 2018.『再現可能性のすゝめ―RStudioによるデータ解析とレポート作成』共立出版\n松村優哉・湯谷啓明・紀ノ定保礼・前田和寛. 2018.『RユーザのためのRStudio[実践]入門―tidyverseによるモダンな分析フローの世界―』技術評論社.\n\nArticle\n\nBertrand, Marianne, and Sendhil Mullainathan. 2004. “Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination.” American Economic Review, 94 (4): 991-1013.\nDruckman, James N., Donald P. Green, James H. Kuklinski, and Arthur Lupia. 2006. “The Growth and Development of Experimental Research in Political Science.” American Political Science Review, 100(4): 627-635.\nTomz, Michael. 2007. “Domestic Audience Costs in International Relations: An Experimental Approach.” International Organization, 61 (4): 821-840.\nGerber, Alan S., Donald P. Green, and Christopher W. Larimer. 2008. “Social Pressure and Voter Turnout: Evidence from a Large-Scale Field Experiment.” American Political Science Review, 102 (1): 33-48.\nImai, Kosuke, Gary King, and Elizabeth A. Stuart. 2008. “Misunderstandings between Experimentalists and Observationalists about Causal Inference.” Journal of the Royal Statistical Society. Series A, 171(2): 481-502.\nde Rooji, Eline A., Donald P. Green, and Alan S. Gerber. 2009. “Field Experiments on Political Behavior and Collective Action.” Annual Review of Political Science. 12: 389-395.\nPalfrey, Thomas R. 2009. “Laboratory Experiments in Political Economy.” Annual Review of Political Science, 12: 379-388.}\n\n谷口尚子. 2014. 「政治学における実験研究」『選挙研究』30 (1): 5-15.\n\n\nMonograph\n\n河野勝. 2007. 『社会科学の実験アプローチ』勁草書房.\n肥前洋一. 2016. 『実験政治学』勁草書房.\nBlais, Andre, Jean-Francois Laslier, and Karine Van der Straeten Ed. 2016. Voting Experiments. Springer.\n\nR Packages for Data Analysis\n\n{tidyverse}: Easily Install and Load the ‘Tidyverse’.\n\n{tidyverse}パッケージは{dplyr}、{ggplot2}、{haven}、{magrittr}、{purrr}、{readr}、{stringr}、{tibble}、{tidyr}などを含むパッケージ群である。\n\n\n\n\n\nマッチングとその応用\n\nTextbook\n\nRosenbaum. Paul R. 2002. Observational Studies, 2nd Ed. Springer.\n星野崇宏. 2009.『調査観察データの統計科学―因果推論・選択バイアス・データ融合―』岩波書店（第2・3・4章）\n\nArticle\n\nRosenbaum, Paul R., and Donald B. Rubin. 1983. “The Central Role of the Propensity Score in Observational Studies for Causal Effects.” Biometrika, 70 (1): 41-55.\nAbadie, Alberto and Javier Gardeazabal. 2003. “The Economic Costs of Conflict: A Case Study of the Basque Country.” American Economic Review. 93(1): 113-132.\nMorgan, Stephen L., and David J. Harding. 2006. “Matching Estimators of Causal Effects: Prospects and Pitfalls in Theory and Practice.” Sociological Methods & Research, 35(1): 3-60.\nHo, Daniel E., Kosuke Imai, Gary King, and Elizabeth A. Stuart. 2007. “Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference.” Political Analysis, 15: 199-236.\nSekhon, Jasjeet S. 2008. “The Neyman-Rubin Model of Causal Inference and Estimation via Matching Methods.” In Janet M. Box-Steffensmeier, Henry E. Brady, and David Collier, eds. The Oxford Handbook of Political Methodology, New York: Oxford University Press, Ch.11.\nStuart, Elizabeth A., and Donald B. Rubin. 2008. “Best Practice in Quasi-Experimental Designs: Matching Methods for Causal Inference.” In Jason W. Osborne, ed. Best Practices in Quantitative Methods, Thousand Oaks: Sage, Ch.11.\nSekhon, Jasjeet S. 2009. “Opiates for the Matches: Matching Methods for Causal Inference.” Annual Review of Political Science, 12: 487-508.\nAbadie, Alberto,Alexis Diamond, and Jens Hainmueller. 2010. “Synthetic Control Methods for Comparative Case Studies: Estimating the Effect of California’s Tobacco Control Program.” Journal of the American Statistical Association. 105 (490): 493-505.\nStuart, Elizabeth A. 2010. “Matching Methods for Causal Inference: A Review and a Look Forward.” Statistical Science, 25(1): 1-21.\nIacus, Stefano M., Gary King, and Giuseppe Porro. 2012. “Causal Inference without Balance Checking: Coarsened Exact Matching.” Political Analysis, 20: 1-24.\nAbadie, Alberto, Alexis Diamond, and Jens Hainmueller. 2014. “Comparative Politics and the Synthetic Control Method.” American Journal of Political Science. 59 (2): 495-510.\nBrodersen, Kay H., Fabian Gallusser, Jim Koehler, Nicolas Remy, and Steven L. Scott. 2015. “Inferring causal impact using Bayesian structural time-series models.” Annals of Applied Statistics. 9(1): 247-274.\n登藤直弥・小林哲郎・稲増一憲. 2016.「ソフトニュースへの接触は政治的関心を高めるか―一般化傾向スコアを用いた因果推論―」『行動計量学』43 (2): 129-141.\nSamii, Cyrus, Laura Paler, and Sarah Zukerman Daly. 2017. “Retrospective Causal Inference with Machine Learning Ensembles: An Application to Anti-recidivism Policies in Colombia.” Political Analysis, 24 (4): 434-456.\n\nR Package\n\n{Matching}: Multivariate and Propensity Score Matching with Balance Optimization\n{MatchIt}: Nonparametric Preprocessing for Parametric Causal Inference\n{WeightIt}: Weighting for Covariate Balance in Observational Studies\n{SuperLearner}: Super Learner Prediction\n\n\n\n\n差分の差分法\n\nArticle\n\nCard, David, and Alan B. Krueger. 1994. “Minimum Wages and Employment: A Case Study of the Fast Food Industry in New Jersey and Pennsylvania.” American Economic Review, 90 (5): 1397-1420.\nBertrand, Marianne, Esther Duflo, and Sendhil Mullainathan. 2004. “How Much Should We Trust Differences-In-Differences Estimates?” Quarterly Journal of Economics, 119(1): 249-275.\nDi Tella, Rafael, and Ernesto Schargrodsky. 2004. “Do Police Reduce Crime? Estimates Using the Allocation of Police Forces After a Terrorist Attack.” American Economic Review, 94 (1): 115-133.\nAbadie, Alberto. 2005. “Semiparametric Difference-in-Differences Estimators.” Review of Economic Studies, 72(1): 1-19.\nLyall, Jason. 2009. “Does Indiscriminate Violence Incite Insurgent Attacks? Evidence from Chechnya.” Journal of Conflict Resolution, 53(3): 331-362.\nLechner, Michael. 2010. “The Estimation of Causal Effects by Difference-in-Difference Methods.” Working paper.\nAsai, Yukiko, Ryo Kamibayashi, and Shintaro Yamaguchi. 2015. “Childcare availability, household structure, and maternal employment.” Journal of the Japanese and International Economies, 38: 172-192.\nFouirnaies, Alexander, and Hande Mutlu-Eren. 2015. “English Bacon: Copartisan Bias in Intergovernmental Grant Allocation in England.” Journal of Politics, 77(3): 805–817.\nXu, Yiqing. 2017. “Generalized Synthetic Control Method: Causal Inference with Interactive Fixed Effects Models,” Political Analysis, 25(1): 56-76.\n\nR Packages\n\n{estimatr}: Fast Estimators for Design-Based Inference\n{CausalImpact}: Inferring Causal Effects using Bayesian Structural Time-Series Models\n{Synth}: Synthetic Control Group Method for Comparative Case Studies\n{gsynth}: Generalized Synthetic Control Method\n\n\n\n\n回帰不連続デザイン\n\nTextbook\n\nCattaneo, Matias D. 2020. A Practical Introduction to Regression Discontinuity Designs, Cambridge University Press.\n\nArticle\n\nThistlethwaite, Donald L., and Donald T. Campbell. 1960. “Regression-discontinuity analysis: An alternative to the ex post facto experiment.” Journal of Educational Psychology, 51(6): 309-317.\nHahn, Jinyong, Petra Todd, and Wilbert Van der Klaauw. 2001. “Identification and Estimation of Treatment Effects with a Regression-Discontinuity Design.” Econometrica, 69 (1): 201-209.\nPoter, Jack. 2003. “Estimation in the Regression Discontinuity Model.” Working Paper.\nImbens, Guido W., and Thomas Lemieux. 2008. “Regression Discontinuity Designs: A Guide to Practice.” Journal of Econometrics, 142 (2): 615-635.\nLee, David S. 2008. “Randomized experiments from non-random selection in U.S. House elections.” Journal of Econometrics, 142 (2): 675-697.\nJustin McCrary. 2008. “Manipulation of the running variable in the regression discontinuity design: A density test.” Journal of Econometrics, 142 (2): 698-714.\nLee, David S., and Thomas Lemieux. 2010. “Regression Discontinuity Designs in Economics. Journal of Economic Literature, 48 (2): 281-355.\nLee, David S., and Thomas Lemieux. 2010. “Regression Discontinuity Designs in Economics.” Journal of Economic Literature, 48 (2): 281-355.\nImbens, Guido, and Karthik Kalyanaraman. 2011. “Optimal Bandwidth Choice for the Regression Discontinuity Estimator.” Review of Economic Studies, 79 (3): 933-959.\nHall, Andrew B. 2015. “What Happens When Extremists Win Primaries?,” American Political Science Review, 109 (1): 18-42.\nAriga, Kenichi, Yusaku Horiuchi, Roland Mansilla, and Michio Umeda. 2016. “No sorting, no advantage: Regression discontinuity estimates of incumbency advantage in Japan.” Electoral Studies, 43: 21-31.\nAndrew Gelman and Guido Imbens. 2019. “Why High-Order Polynomials Should Not Be Used in Regression Discontinuity Designs,” Journal of Business & Economic Statistics, 37(3): 447-456.\n\nMonograph\n\nCattaneo, Matias D., Nicolas Idrobo and Rocio Titiunik. 2018. A Practical Introduction to Regression Discontinuity Designs: Volume I. Cambridge University Press.\nCattaneo, Matias D., Nicol'as Idrobo and Roc'io Titiunik. 2018. A Practical Introduction to Regression Discontinuity Designs: Volume II. Cambridge University Press.\n\nR package\n\n{rdd}: Regression Discontinuity Estimation\n{rddtools}: Toolbox for Regression Discontinuity Design (‘RDD’)\n{rddapp}: Regression Discontinuity Design Application\n{rdrobust}: Robust Data-Driven Statistical Inference in Regression-Discontinuity Designs\n{rdmulti}: Analysis of RD Designs with Multiple Cutoffs or Scores\n{rdpower}: Power Calculations for RD Designs\n\n\n\n\n操作変数法\n　以下の内容はLab Sessionを行わない場合のみ、解説する。\n\nArticle\n\nAngrist, Joshua D. and Alan B. Krueger. 2001. “Instrumental Variables and the Search for Identification: From Supply and Demand to Natural Experiments,” Journal of Economic Perspectives, 15 (4): 69-85\nDunning, Thad. 2008. “Model Specification in Instrumental-Variables Regression.” Political Analysis, 16 (3): 290-302.\nKern, Holger Lutz and Jens Hainmueller. 2009. “Opium for the Masses: How Foreign Media Can Stabilize Authoritarian Regimes.” Political Analysis, 17 (4): 377-399.\nAllison J. Sovey and Donald P. Green. 2010. “Instrumental Variables Estimation in Political Science: A Readers’ Guide,” American Journal of Political Science, 55(1): 188-200.\nBollen, Kenneth A. 2012. “Instrumental Variables in Sociology and the Social Sciences,” Annual Review of Sociology, 38:37-72.\nAronow, Peter M. and Allison Carnegie. 2013. “Beyond LATE: Estimation of the Average Treatment Effect with an Instrumental Variable.” Political Analysis, 21 (4): 492-506.\n\nR packages\n\n{AER}: Applied Econometrics with R}\n{ivreg}: Instrumental-Variables Regression by ‘2SLS’, ‘2SM’, or ‘2SMM’, with Diagnostics}",
    "crumbs": [
      "シラバス"
    ]
  },
  {
    "objectID": "material/rdd.html",
    "href": "material/rdd.html",
    "title": "回帰不連続デザイン",
    "section": "",
    "text": "新しいタブで開く",
    "crumbs": [
      "回帰不連続デザイン"
    ]
  },
  {
    "objectID": "material/rdd.html#スライド",
    "href": "material/rdd.html#スライド",
    "title": "回帰不連続デザイン",
    "section": "",
    "text": "新しいタブで開く",
    "crumbs": [
      "回帰不連続デザイン"
    ]
  },
  {
    "objectID": "material/rdd.html#セットアップ",
    "href": "material/rdd.html#セットアップ",
    "title": "回帰不連続デザイン",
    "section": "セットアップ",
    "text": "セットアップ\n実習に必要なパッケージとデータセットを読み込む。\n\npacman::p_load(tidyverse, rdd, rdrobust, rddensity, \n               summarytools, BalanceR)\n\ndf &lt;- read_csv(\"data/rdd_data4.csv\")\n\ndf\n\n# A tibble: 1,266 × 7\n    year prefname outcome      rv total_cand en_cand total_votes\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;\n 1  2000 Hokkaido    34.6 -10.8            4    2.75      261382\n 2  2003 Hokkaido    40.8 -10.4            3    2.29      259740\n 3  2005 Hokkaido    36.8  -2.45           4    2.60      313909\n 4  2009 Hokkaido    31.1  -8.72           4    2.29      337445\n 5  2012 Hokkaido    39.6   1.09           5    4.17      276894\n 6  2000 Hokkaido    35.3   2.52           6    4.19      244655\n 7  2003 Hokkaido    44.5  -5.13           5    2.86      236430\n 8  2005 Hokkaido    30.8  -0.407          3    2.42      285519\n 9  2009 Hokkaido    35.0 -11.7            5    2.50      304810\n10  2012 Hokkaido    38.8   5.87           5    4.17      239023\n# ℹ 1,256 more rows\n\n\n分析に入る前に記述統計を確認する。\n\ndf |&gt;\n  descr(stats = c(\"mean\", \"sd\", \"min\", \"max\", \"n.valid\"),\n        transpose = TRUE, order = \"p\")\n\nDescriptive Statistics  \ndf  \nN: 1266  \n\n                         Mean    Std.Dev         Min         Max   N.Valid\n----------------- ----------- ---------- ----------- ----------- ---------\n             year     2006.18       4.20     2000.00     2012.00   1266.00\n          outcome       47.02      11.65       13.26       84.50   1266.00\n               rv        3.58      10.20      -23.76       36.31   1266.00\n       total_cand        3.76       0.95        2.00        9.00   1266.00\n          en_cand        2.55       0.59        1.37        5.35   1266.00\n      total_votes   214025.95   42366.82   104398.00   339780.00   1266.00",
    "crumbs": [
      "回帰不連続デザイン"
    ]
  },
  {
    "objectID": "material/rdd.html#処置効果の推定",
    "href": "material/rdd.html#処置効果の推定",
    "title": "回帰不連続デザイン",
    "section": "処置効果の推定",
    "text": "処置効果の推定\n　因果効果の推定は{rdd}パッケージのRDestimate()関数、あるいは{rdrobust}パッケージのrdrobust()を使う。機能面では{rdrobust}の方が優れているものの、パッケージの使いやすさとしては{rdd}の方が優れている。本講義では頑健な推定方法については紹介しなかったものの、近年は{rdrobust}がより使われているため、ここでも{rdrobust}を使用する。いずれのパッケージも自動的に最適バンド幅を設定し1、交差項が含まれた局所線形回帰分析を行った結果を返してくれる2。また、デフォルトのカーネルは三角 (triangular)カーネル関数だ。\n\nrdd_fit1 &lt;- rdrobust(y = df$outcome, x = df$rv, c = 0)\n\nsummary(rdd_fit1)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             318          381\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   8.064        8.064\nBW bias (b)                  12.613       12.613\nrho (h/b)                     0.639        0.639\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.725     1.580     0.459     0.646    [-2.371 , 3.820]     \n        Robust         -         -     0.528     0.598    [-2.692 , 4.677]     \n=============================================================================\n\n\n　最適バンド幅は8.064であり、処置効果は約0.725である。これは自民党候補者の投票率から非自民候補者の最高得票率を引いた値（rv）が-8.064から8.064までのデータを使うことを意味する。そして、これらのデータに対して交差項が含まれる線形回帰分析を行うことになる。また、閾値周辺に重みを付けるために三角カーネル関数による重み付けを行った。\n　結果として現職は新人に比べ、約72.5%ポイント得票率が高いという結果が得られたが、標準誤差はかなり大きく、必ずしも現職が新人より得票するとは言えないだろう（\\(p\\) = 0.646）。今回の推定結果から日本における現職効果について、統計的に有意な効果は確認できない。",
    "crumbs": [
      "回帰不連続デザイン"
    ]
  },
  {
    "objectID": "material/rdd.html#頑健性の確認",
    "href": "material/rdd.html#頑健性の確認",
    "title": "回帰不連続デザイン",
    "section": "頑健性の確認",
    "text": "頑健性の確認\n　RDDで（局所）処置効果を推定する際、分析する側はバンド幅、カーネル関数、モデル（一次関数か、二次関数かなど）を決める必要がある。これらは恣意的なものであるため、これらを少し変更しても推定値が安定しているか、つまりどれほど頑健かを確認する必要がある。\n\nバンド幅\n　rdrobust()の場合、基本的には最適バンド幅を使うことになるが、h引数を使って任意のバンド幅を指定することもできる。たとえば、既に得られた最適バンド幅8.064を使って推定してみよう。\n\nrdd_bw1 &lt;- rdrobust(y = df$outcome, x = df$rv, c = 0, h = 8.064)\n\nsummary(rdd_bw1)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                      Manual\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             318          381\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   8.064        8.064\nBW bias (b)                   8.064        8.064\nrho (h/b)                     1.000        1.000\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.725     1.580     0.459     0.646    [-2.371 , 3.820]     \n        Robust         -         -     0.013     0.990    [-4.461 , 4.521]     \n=============================================================================\n\n\n　先ほどと同じ結果が得られている（Robust行はこの講義では無視する。Robust推定値についてはCalonico et al. (2015)を参照されたい3。）。頑健性を報告する際は最適バンド幅における処置効果に加え、最適バンド幅を半分にした場合、2倍にした場合の結果も報告するケースが多い。それではhを8.064の半分、2倍にしたモデルも推定してみよう。\n\nrdd_bw2 &lt;- rdrobust(y = df$outcome, x = df$rv, c = 0, h = 8.064 / 2)\n\nsummary(rdd_bw2)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                      Manual\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             188          185\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   4.032        4.032\nBW bias (b)                   4.032        4.032\nrho (h/b)                     1.000        1.000\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.162     2.205     0.074     0.941    [-4.160 , 4.485]     \n        Robust         -         -     0.316     0.752    [-5.326 , 7.375]     \n=============================================================================\n\n\n\nrdd_bw3 &lt;- rdrobust(y = df$outcome, x = df$rv, c = 0, h = 8.064 * 2)\n\nsummary(rdd_bw3)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                      Manual\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             453          650\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                  16.128       16.128\nBW bias (b)                  16.128       16.128\nrho (h/b)                     1.000        1.000\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    -0.006     1.141    -0.005     0.996    [-2.242 , 2.229]     \n        Robust         -         -     0.580     0.562    [-2.309 , 4.250]     \n=============================================================================\n\n\n　いずれも統計的に有意な処置効果は得られない。これらの結果をまとめると以下のよるになる。\n\nbw_compare &lt;- tibble(Bandwidth = c(\"Half\", \"Optimal\", \"Double\"),\n                     LATE      = c(0.162, 0.725, -0.006),\n                     lower     = c(-4.160, -2.371, -2.242),\n                     upper     = c(4.485, 3.820, 2.2249))\n\nbw_compare\n\n# A tibble: 3 × 4\n  Bandwidth   LATE lower upper\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Half       0.162 -4.16  4.49\n2 Optimal    0.725 -2.37  3.82\n3 Double    -0.006 -2.24  2.22\n\n\n　これらをpoint-rangeプロットで可視化してみよう。\n\nbw_compare |&gt;\n  mutate(Bandwidth = fct_inorder(Bandwidth)) |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = Bandwidth, y = LATE, \n                      ymin = lower, ymax = upper)) +\n  theme_bw(base_size = 12) \n\n\n\n\n\n\n\n\n\n\nカーネル\n　カーネル関数はkernel引数で指定することができる。指定しない場合、既定値としてkernel = \"triangular\"になるが、他にも\"uniform\"と\"epanechnikov\"がある。\n\nrdd_kernel1 &lt;- rdrobust(y = df$outcome, x = df$rv, c = 0, \n                        kernel = \"triangular\")\nrdd_kernel2 &lt;- rdrobust(y = df$outcome, x = df$rv, c = 0, \n                        kernel = \"uniform\")\nrdd_kernel3 &lt;- rdrobust(y = df$outcome, x = df$rv, c = 0, \n                        kernel = \"epanechnikov\")\n\nsummary(rdd_kernel1)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             318          381\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   8.064        8.064\nBW bias (b)                  12.613       12.613\nrho (h/b)                     0.639        0.639\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.725     1.580     0.459     0.646    [-2.371 , 3.820]     \n        Robust         -         -     0.528     0.598    [-2.692 , 4.677]     \n=============================================================================\n\nsummary(rdd_kernel2)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                       mserd\nKernel                      Uniform\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             245          264\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   5.651        5.651\nBW bias (b)                  10.115       10.115\nrho (h/b)                     0.559        0.559\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.611     1.699     0.360     0.719    [-2.718 , 3.941]     \n        Robust         -         -     0.516     0.606    [-2.878 , 4.933]     \n=============================================================================\n\nsummary(rdd_kernel3)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                       mserd\nKernel                   Epanechnikov\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             298          349\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   7.420        7.420\nBW bias (b)                  12.211       12.211\nrho (h/b)                     0.608        0.608\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.722     1.586     0.455     0.649    [-2.387 , 3.832]     \n        Robust         -         -     0.560     0.575    [-2.633 , 4.740]     \n=============================================================================\n\n\n　以上の結果をまとめたものが以下である。\n\nkernel_compare &lt;- tibble(Kernel = c(\"Triangular\", \n                                    \"Unifrom\", \n                                    \"Epanechnikov\"),\n                         LATE   = c(0.725, 0.611, 0.722),\n                         lower  = c(-2.371, -2.718, -2.387),\n                         upper  = c(3.820, 3.941, 3.832))\n\nkernel_compare\n\n# A tibble: 3 × 4\n  Kernel        LATE lower upper\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Triangular   0.725 -2.37  3.82\n2 Unifrom      0.611 -2.72  3.94\n3 Epanechnikov 0.722 -2.39  3.83\n\nkernel_compare |&gt;\n  mutate(Kernel = fct_inorder(Kernel)) |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = Kernel, y = LATE, \n                      ymin = lower, ymax = upper)) +\n  theme_bw(base_size = 12) \n\n\n\n\n\n\n\n\n\n\n関数\n　パラメトリック推定、またはセミパラメトリック推定の場合、応答変数と強制変数間の関係をある関数として仮定する必要がある。セミパラメトリック推定は関数設定の影響力が比較的小さいが、バンド幅内のケース数が少なくなると、関数の形に影響を受けやすい。ここでは1次関数から4次関数までモデルを変えながら、推定値が安定しているかを確認してみよう。rdrobust()で関数の次数を指定するためにはp引数を使用する。既定値は1であるが、p次関数を使う場合はpを指定する必要がある。\n\nrdd_p1 &lt;- rdrobust(y = df$outcome, x = df$rv, c = 0, p = 1)\nrdd_p2 &lt;- rdrobust(y = df$outcome, x = df$rv, c = 0, p = 2)\nrdd_p3 &lt;- rdrobust(y = df$outcome, x = df$rv, c = 0, p = 3)\nrdd_p4 &lt;- rdrobust(y = df$outcome, x = df$rv, c = 0, p = 4)\n\nsummary(rdd_p1)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             318          381\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   8.064        8.064\nBW bias (b)                  12.613       12.613\nrho (h/b)                     0.639        0.639\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.725     1.580     0.459     0.646    [-2.371 , 3.820]     \n        Robust         -         -     0.528     0.598    [-2.692 , 4.677]     \n=============================================================================\n\nsummary(rdd_p2)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             358          433\nOrder est. (p)                    2            2\nOrder bias  (q)                   3            3\nBW est. (h)                   9.205        9.205\nBW bias (b)                  12.622       12.622\nrho (h/b)                     0.729        0.729\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.260     2.139     0.122     0.903    [-3.931 , 4.452]     \n        Robust         -         -    -0.030     0.976    [-4.804 , 4.661]     \n=============================================================================\n\nsummary(rdd_p3)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             379          476\nOrder est. (p)                    3            3\nOrder bias  (q)                   4            4\nBW est. (h)                  10.311       10.311\nBW bias (b)                  13.458       13.458\nrho (h/b)                     0.766        0.766\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    -0.389     2.676    -0.145     0.884    [-5.633 , 4.855]     \n        Robust         -         -    -0.240     0.811    [-6.462 , 5.055]     \n=============================================================================\n\nsummary(rdd_p4)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             420          567\nOrder est. (p)                    4            4\nOrder bias  (q)                   5            5\nBW est. (h)                  12.653       12.653\nBW bias (b)                  15.671       15.671\nrho (h/b)                     0.807        0.807\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    -0.472     3.002    -0.157     0.875    [-6.356 , 5.411]     \n        Robust         -         -    -0.124     0.902    [-6.776 , 5.972]     \n=============================================================================\n\n\n　以上の結果をまとめたものが以下である。\n\norder_compare &lt;- tibble(Order = 1:4,\n                        LATE  = c(0.725, 0.260, -0.389, -0.472),\n                        lower = c(-2.371, -3.931, -5.633, -6.356),\n                        upper = c(3.820, 4.452, 4.855, 5.411))\n\norder_compare\n\n# A tibble: 4 × 4\n  Order   LATE lower upper\n  &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1  0.725 -2.37  3.82\n2     2  0.26  -3.93  4.45\n3     3 -0.389 -5.63  4.86\n4     4 -0.472 -6.36  5.41\n\norder_compare |&gt;\n  ggplot() +\n  geom_hline(yintercept = 0) +\n  geom_pointrange(aes(x = Order, y = LATE, \n                      ymin = lower, ymax = upper)) +\n  labs(x = \"Order of Local Polynomial Regression\") +\n  theme_bw(base_size = 12) \n\n\n\n\n\n\n\n\n　結果は大きく変わらず、安定していることが分かる。",
    "crumbs": [
      "回帰不連続デザイン"
    ]
  },
  {
    "objectID": "material/rdd.html#可視化",
    "href": "material/rdd.html#可視化",
    "title": "回帰不連続デザイン",
    "section": "可視化",
    "text": "可視化\n　{rdrobust}パッケージには可視化に便利なrdplot()関数が用意されている。使い方はrdrobust()とほぼ同じで、yには応答変数を、xには強制変数、cには閾値を指定すれば良い。\n\nrdplot(y = df$outcome, x = df$rv, c = 0)\n\n\n\n\n\n\n\n\n　観測値が少ないように見えるが、これは強制変数を区間に分け、区間内の平均値を示したものである。通常のRDDはサンプルサイズが大きいため、散布図+回帰直線（曲線）だと線が見えなかったり、傾向が見にくくなる傾向がある。サンプルサイズが数百程度なら全観測値を見せても良いだろうが、今回は1200以上であり、このような見せ方が効果的である。\n　1つ注意すべき点は、表示される回帰直線（曲線）の場合、2次関数が使用される。1次関数にフィットさせるためには、rdrobust()同様、p = 1を指定すれば良い。\n\nrdplot(y = df$outcome, x = df$rv, c = 0, p = 1)\n\n\n\n\n\n\n\n\n　また、この回帰直線の場合、カーネル関数は矩形関数である。三角形関数にするためには、更にkernel = \"triangular\"を指定する。また、x.lab、y.lab、title引数でラベルを修正することもできる。\n\nrdplot(y = df$outcome, x = df$rv, c = 0, p = 1,\n       kernel = \"triangular\",\n       x.label = \"Vote Margin in Election t\",\n       y.label = \"Vote Share in Election t+1\",\n       title = \"\")\n\n\n\n\n\n\n\n\n　以上の例は、バンド幅を設定せず、全観測値を利用したものである。rdrobust()のようにバンド幅を指定することはできないため、subset引数を使って使用するデータを制限することができる。たとえば、rvが-15より大きく、15より小さいケースのみを使う場合、subset = (df$rv &gt; -15 & df$rv &lt; 15)と指定すれば良い。\n\nrdplot(y = df$outcome, x = df$rv, c = 0, p = 1,\n       kernel = \"triangular\", \n       subset = (df$rv &gt; -15 & df$rv &lt; 15),\n       x.label = \"Vote Margin in Election t\",\n       y.label = \"Vote Share in Election t+1\",\n       title = \"\")",
    "crumbs": [
      "回帰不連続デザイン"
    ]
  },
  {
    "objectID": "material/rdd.html#仮定の確認",
    "href": "material/rdd.html#仮定の確認",
    "title": "回帰不連続デザイン",
    "section": "仮定の確認",
    "text": "仮定の確認\n\n交絡要因の連続性\n　RDDの重要な仮定の一つとして、交絡要因の連続性がある。交絡要因として考えられる要因が、処置群に割り当てられることでジャンプした場合、観察される処置効果がが処置によるものか、交絡要因のジャンブによるものかが識別できないからだ。今回の例では処置効果が見られていないが、それでもこの仮定は確認する価値がある。処置による効果（\\(X \\rightarrow Y\\)）と交絡要因による効果（\\(Z \\rightarrow Y\\)）が両方存在するケースを考えてみよう。もしこの2つの効果の符号が逆である場合、処置効果（\\(X \\rightarrow Y\\)）が交絡要因による効果（\\(Z \\rightarrow Y\\)）に相殺される可能性もあるからだ。\n　確認する方法は簡単だ。もう一度RDDをするだけだ。ただし、応答変数が得票率（outcome）でなく、交絡要因に代わるだけだ。今回は候補者数（total_cand）、有効候補者数（en_cand）、得票数（total_votes）に対してRDDを行ってみよう。\n\nassumption_fit1 &lt;- rdrobust(y = df$total_cand, x = df$rv)\nassumption_fit2 &lt;- rdrobust(y = df$en_cand, x = df$rv)\nassumption_fit3 &lt;- rdrobust(y = df$total_votes, x = df$rv)\n\n\nsummary(assumption_fit1)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             243          261\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   5.547        5.547\nBW bias (b)                   8.621        8.621\nrho (h/b)                     0.643        0.643\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional    -0.066     0.209    -0.315     0.753    [-0.475 , 0.344]     \n        Robust         -         -    -0.415     0.678    [-0.593 , 0.385]     \n=============================================================================\n\n\n\nsummary(assumption_fit2)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             280          314\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   6.629        6.629\nBW bias (b)                  10.114       10.114\nrho (h/b)                     0.655        0.655\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.032     0.111     0.289     0.772    [-0.186 , 0.251]     \n        Robust         -         -     0.149     0.881    [-0.242 , 0.282]     \n=============================================================================\n\n\n\nsummary(assumption_fit3)\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1266\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  479          787\nEff. Number of Obs.             291          341\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                   7.131        7.131\nBW bias (b)                  11.445       11.445\nrho (h/b)                     0.623        0.623\nUnique Obs.                     479          787\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional  1222.634  7020.544     0.174     0.862[-12537.380 , 14982.648] \n        Robust         -         -     0.042     0.967[-16145.541 , 16846.362] \n=============================================================================\n\n\n　いずれも統計的に有意なジャンプは見られない。以上の検定結果から「仮定は満たされている」ことは主張できないものの、「仮定が満たされていないとは言えない」までは主張できるはずだ。\n\n\nバランスチェック\n　ノンパラメトリックRDDの場合、バンド幅内であれば、処置群と統制群の性質はほぼ同じであると仮定する。つまり、処置変数を除く共変量が処置群と統制群の間において均質であることを意味する。それでは{BalanceR}を使って、候補者数（total_cand）、有効候補者数（en_cand）、得票数（total_votes）が処置群と統制群の間に差があるかを確認してみよう。\n\ndf |&gt;\n  # 処置の有無を示す treat 変数を作成\n  mutate(treat = if_else(rv &gt; 0, \"yes\", \"no\")) |&gt;\n  BalanceR(group = treat,\n           cov = total_cand:total_votes) |&gt;\n  plot(abs = TRUE) +\n  scale_y_discrete(label = c(\"total_cand\" = \"Total number of candidates\",\n                             \"en_cand\" = \"Effective number of candidates\",\n                             \"total_votes\" = \"Total votes\"))\n\n\n\n\n\n\n\n\n　得票数（total_votes）の場合、標準化差分が非常に大きいことが分かる。それではバンド幅内のサンプルに限定すればどうだろうか。filter()を使ってrvが-8.064より大きく、8.064より小さいサンプルに絞っってバランスチェックをしてみよう。\n\ndf |&gt;\n  mutate(treat = if_else(rv &gt; 0, \"yes\", \"no\")) |&gt;\n  filter(rv &gt; -8.064 & rv &lt; 8.064) |&gt;\n  BalanceR(group = treat,\n           cov = total_cand:total_votes) |&gt;\n  plot(abs = TRUE) +\n  scale_y_discrete(label = c(\"total_cand\" = \"Total number of candidates\",\n                             \"en_cand\" = \"Effective number of candidates\",\n                             \"total_votes\" = \"Total votes\"))\n\n\n\n\n\n\n\n\n　有効候補者数（en_cand）のバランスがむしろ悪くなったものの、他の2つの変数のバランスは改善されていることが分かる。\n\n\n強制変数の操作可能性\n　RDDのもう一つの重要な仮定として、閾値周辺において強制変数の操作が行われてはいけない。得票率の差を操作することは極めて困難なので、今回は問題はないと考えられるが、たとえばフランス地方議会選挙のように人口によって制度が変わる場合、特定の選挙制度を採用するために人口を操作することは不可能ではないだろう。\n　この仮定を確認、検定する手法がMcCrayの密度検定 (density test)だ (McCray 2006)4。簡単に説明すると、強制変数の密度関数が閾値周辺においてジャンプしているか否かを確認する方法である。もし、操作が行われているとしたら、密度関数が断絶するだろう。\n　密度検定は{rdd}のDCdensity()で簡単に行うことができる。第一引数は強制変数を、cutpointには閾値を指定する（既定値は0であるため、今回は省略可能）。\n\nDCdensity(df$rv, cutpoint = 0)\n\n\n\n\n\n\n\n\n[1] 0.3002424\n\n\n　図と長さ1のnumeric型ベクトルが出力されるが5、図は密度分布を可視化したものであり、数値は「密度関数は連続している」という帰無仮説に対する\\(p\\)値である。これが\\(\\alpha\\)（通常、\\(\\alpha = 0.05\\)）を下回る場合、帰無仮説は棄却され、密度関数が断絶していると判断できる。つまり、RDDの仮定を満たしていないことを意味する。\n　{rdd}のDCdensity()以外にも、密度検定専用のパッケージ{rddenstiy}のrddensity()を使うことも可能だ。検定方法は基本的に同じだが、検定の際に使用するパラメーターや標準誤差計算のアルゴリズムが異なるため、結果はやや異なる。使い方はXに強制変数を、cに閾値を指定すれば良い。他にも十数種類のパラメーターが指定できるが詳細はコンソール上で?rddensityを入力し、ヘルプを参照すること。\n\nDensity_Test &lt;- rddensity(X = df$rv, c = 0)\nsummary(Density_Test)\n\n\nManipulation testing using local polynomial density estimation.\n\nNumber of obs =       1266\nModel =               unrestricted\nKernel =              triangular\nBW method =           estimated\nVCE method =          jackknife\n\nc = 0                 Left of c           Right of c          \nNumber of obs         479                 787                 \nEff. Number of obs    259                 289                 \nOrder est. (p)        2                   2                   \nOrder bias (q)        3                   3                   \nBW est. (h)           6.112               6.078               \n\nMethod                T                   P &gt; |T|             \nRobust                -0.818              0.4134              \n\n\nP-values of binomial tests (H0: p=0.5).\n\nWindow Length / 2          &lt;c     &gt;=c    P&gt;|T|\n0.448                      20      24    0.6516\n0.896                      41      41    1.0000\n1.343                      65      59    0.6536\n1.791                      89      79    0.4876\n2.239                     108      98    0.5307\n2.687                     129     116    0.4434\n3.134                     151     135    0.3751\n3.582                     168     163    0.8260\n4.030                     188     185    0.9175\n4.478                     200     204    0.8814\n\n\n　密度検定の結果（\\(p\\)値）は中間辺りにある# Robust行の0.4134だ。ここでも帰無仮説は棄却されず、強制変数の操作が行われているとは言えない。これらの結果を可視化の際はrdplotdensity()関数を使う。第一引数はrddensity()から得られたオブジェクト名を指定し、Xには強制変数を指定する。その他の引数についてはヘルプ（コンソール上で?rdplotdensity）を参照すること。\n\nDensity_Plot &lt;- rdplotdensity(Density_Test, X = df$rv, \n                              type = \"both\", lwd = 1, pwd = 3, pty = 19)\n\n\n\n\n\n\n\n\n　また、要約結果の下段にあるBinomial testsは密度分布に代わるもう一つの検定手法だ。1行目はケースが20個入る範囲と、その中での処置群と統制群の大きさ、そしてその差の検定である。ここでは0.215だが、これはrvが-0.215から0.215の間に20個のケースがあるということを意味する。統制群は7ケース、処置群は13ケースである。もし、強制変数の操作が行われなかったのであれば、処置群の割合は0.5になるはずである。右のP&gt;|T|列は、\\(p = 0.5\\)を帰無仮説とした二項検定における\\(p\\)値である。もし、この値が\\(\\alpha\\)を下回ると、閾値周辺において何らかの操作が行われた可能性があることを示唆する。\n　2行目は1行目の幅を2倍に、3行目は1行目の幅を3倍に、…したものである。いずれも\\(p\\)値は0.05以上であり、強制変数の操作が行われたとは言えない。",
    "crumbs": [
      "回帰不連続デザイン"
    ]
  },
  {
    "objectID": "material/rdd.html#footnotes",
    "href": "material/rdd.html#footnotes",
    "title": "回帰不連続デザイン",
    "section": "脚注",
    "text": "脚注\n\n\nもし、自分でバンド幅を指定したい場合、bw = ...の引数を加える。↩︎\n閾値のデフォルトは0だ。もし、閾値が0ではない場合、cutpoint = ...の引数を設定する。↩︎\nCalonico, S., M. D. Cattaneo, and R. Titiunik. 2015b. “rdrobust: An R Package for Robust Nonparametric Inference in Regression-Discontinuity Designs,” R Journal, 7(1): 38-51.↩︎\nMcCray, Justin. 2008. “Manipulation of the running variable in the regression discontinuity design: A density test,” Journal of Econometrics, 142(2): 698-714.↩︎\n図が不要ならplot = FALSEを指定する。↩︎",
    "crumbs": [
      "回帰不連続デザイン"
    ]
  },
  {
    "objectID": "material/matching.html",
    "href": "material/matching.html",
    "title": "マッチング",
    "section": "",
    "text": "新しいタブで開く",
    "crumbs": [
      "マッチング"
    ]
  },
  {
    "objectID": "material/matching.html#スライド",
    "href": "material/matching.html#スライド",
    "title": "マッチング",
    "section": "",
    "text": "新しいタブで開く",
    "crumbs": [
      "マッチング"
    ]
  },
  {
    "objectID": "material/matching.html#セットアップ",
    "href": "material/matching.html#セットアップ",
    "title": "マッチング",
    "section": "セットアップ",
    "text": "セットアップ\n　本日の実習で使用するパッケージを読み込む。\n\npacman::p_load(tidyverse, \n               broom,\n               MatchIt, \n               WeightIt, \n               cobalt, \n               summarytools,\n               modelsummary,\n               fastDummies)\npacman::p_load_gh(\"JaehyunSong/BalanceR\")\n\n　マッチングにおける古典的なデータセット、lalondeを読み込む。data(lalonde, package = \"cobalt\")を入力するだけで、{cobalt}パッケージ内のlaondeという名前のデータフレームが作業環境内にlalondeという名で格納される1。このデータをla_dfという名のオブジェクトとして改めて保存しておこう。ただし、lalondeデータセットの形式はdata.frameである。このままでも全く問題ないが、data.frameの拡張版であるtibble形式の方がより読みやすいので、格納する前にlalondeのデータ構造をdata.frameからtibbleへ変更しておこう（as_tibble()関数を使う）。\n\n# cobaltパッケージが提供するデータセットの読み込み\ndata(\"lalonde\", package = \"cobalt\")\n\nla_df &lt;- as_tibble(lalonde)\n\n　それでは、データの中身を確認してみよう。\n\nla_df\n\n# A tibble: 614 × 9\n   treat   age  educ race   married nodegree  re74  re75   re78\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt;    &lt;int&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1    37    11 black        1        1     0     0  9930.\n 2     1    22     9 hispan       0        1     0     0  3596.\n 3     1    30    12 black        0        0     0     0 24909.\n 4     1    27    11 black        0        1     0     0  7506.\n 5     1    33     8 black        0        1     0     0   290.\n 6     1    22     9 black        0        1     0     0  4056.\n 7     1    23    12 black        0        0     0     0     0 \n 8     1    32    11 black        0        1     0     0  8472.\n 9     1    22    16 black        0        0     0     0  2164.\n10     1    33    12 white        1        0     0     0 12418.\n# ℹ 604 more rows\n\n\n　分析に入る前に、名目変数である人種（race）をダミー変数に変換する。raceは3種類の値で構成されているため、生成するダミー変数も3つとなる。ダミー化には{fastDummies}パッケージのdummy_cols()関数を使用する。\n\nla_df &lt;- la_df |&gt;\n  dummy_cols(select_columns = \"race\")\n\nla_df\n\n# A tibble: 614 × 12\n   treat   age  educ race   married nodegree  re74  re75   re78 race_black\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt;    &lt;int&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;      &lt;int&gt;\n 1     1    37    11 black        1        1     0     0  9930.          1\n 2     1    22     9 hispan       0        1     0     0  3596.          0\n 3     1    30    12 black        0        0     0     0 24909.          1\n 4     1    27    11 black        0        1     0     0  7506.          1\n 5     1    33     8 black        0        1     0     0   290.          1\n 6     1    22     9 black        0        1     0     0  4056.          1\n 7     1    23    12 black        0        0     0     0     0           1\n 8     1    32    11 black        0        1     0     0  8472.          1\n 9     1    22    16 black        0        0     0     0  2164.          1\n10     1    33    12 white        1        0     0     0 12418.          0\n# ℹ 604 more rows\n# ℹ 2 more variables: race_hispan &lt;int&gt;, race_white &lt;int&gt;\n\n\n　このまま記述統計を見たり、分析に入っても良いが、もう少しデータを加工してみよう。まずrace_で始まる3つのダミー変数の位置をraceの前へ変更する。また、race変数は不要なので、race変数を除外する。最後に、race_で始まるダミー変数の名前を変更してみよう。変数の位置変更はrelocate()関数を使用する。\n\nla_df &lt;- la_df |&gt;\n  relocate(starts_with(\"race_\"), .before = race) |&gt;\n  select(-race) |&gt;\n  rename(\"black\"    = \"race_black\",\n         \"hispanic\" = \"race_hispan\",\n         \"white\"    = \"race_white\")\n\nla_df\n\n# A tibble: 614 × 11\n   treat   age  educ black hispanic white married nodegree  re74  re75   re78\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt;   &lt;int&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1    37    11     1        0     0       1        1     0     0  9930.\n 2     1    22     9     0        1     0       0        1     0     0  3596.\n 3     1    30    12     1        0     0       0        0     0     0 24909.\n 4     1    27    11     1        0     0       0        1     0     0  7506.\n 5     1    33     8     1        0     0       0        1     0     0   290.\n 6     1    22     9     1        0     0       0        1     0     0  4056.\n 7     1    23    12     1        0     0       0        0     0     0     0 \n 8     1    32    11     1        0     0       0        1     0     0  8472.\n 9     1    22    16     1        0     0       0        0     0     0  2164.\n10     1    33    12     0        0     1       1        0     0     0 12418.\n# ℹ 604 more rows\n\n\n　それでは記述統計量を確認してみよう。\n\ndescr(la_df,\n      stats = c(\"mean\", \"sd\", \"min\", \"max\"),\n      transpose = TRUE,\n      order = \"p\")\n\n\n\n\n\n \nMean\nStd.Dev\nMin\nMax\n\n\n\n\ntreat\n0.30\n0.46\n0.00\n1.00\n\n\nage\n27.36\n9.88\n16.00\n55.00\n\n\neduc\n10.27\n2.63\n0.00\n18.00\n\n\nblack\n0.40\n0.49\n0.00\n1.00\n\n\nhispanic\n0.12\n0.32\n0.00\n1.00\n\n\nwhite\n0.49\n0.50\n0.00\n1.00\n\n\nmarried\n0.42\n0.49\n0.00\n1.00\n\n\nnodegree\n0.63\n0.48\n0.00\n1.00\n\n\nre74\n4557.55\n6477.96\n0.00\n35040.07\n\n\nre75\n2184.94\n3295.68\n0.00\n25142.24\n\n\nre78\n6792.83\n7470.73\n0.00\n60307.93",
    "crumbs": [
      "マッチング"
    ]
  },
  {
    "objectID": "material/matching.html#回帰分析",
    "href": "material/matching.html#回帰分析",
    "title": "マッチング",
    "section": "回帰分析",
    "text": "回帰分析\n\nDiM推定量\n　処置効果を確認するために、まずはグループごとの応答変数の差分（Difference-in-Means; DiM）を計算してみよう。処置変数はtreatであり、職業訓練を受けた回答者は1、受けなかった回答者は0となる。応答変数re78は1978年における回答者の収入である。\n\nDiff_Mean_df &lt;- la_df |&gt; \n    group_by(treat) |&gt;\n    summarise(Outcome = mean(re78),\n              .groups = \"drop\")\n\nDiff_Mean_df\n\n# A tibble: 2 × 2\n  treat Outcome\n  &lt;int&gt;   &lt;dbl&gt;\n1     0   6984.\n2     1   6349.\n\n\n　この結果を可視化する必要はあまり無いかも知れないが、以下のようなコードで可視化することもできる。\n\nDiff_Mean_df |&gt;\n  ggplot() +\n  geom_bar(aes(x = treat, y = Outcome), \n           stat = \"identity\", width = 0.5) +\n  geom_label(aes(x = treat, y = Outcome,\n                 label = round(Outcome, 3))) +\n  labs(x = \"Treatment\",\n       y = \"Outcome (US Dollars)\") +\n  # scale_x_continuous()を使って0/1をControl/Treatmentに置換する\n  # 目盛りはX軸上の0と1、各目盛りのラベルはControlとTreatmentに\n  scale_x_continuous(breaks = c(0, 1), labels = c(\"Control\", \"Treatment\")) +\n  coord_cartesian(xlim = c(-0.5, 1.5))\n\n\n\n\n\n\n\n\n　treat == 0の回答者、つまり職業訓練を受けていない回答者の平均所得は約6984ドル、treat == 1の回答者、つまり職業訓練を受けた回答者の平均所得は約6394ドルだ。その差は約-650ドルだが、職業訓練を受けた回答者の方が低所得になっている。これは直感的に納得できる結果ではないだろう。むろん、実際、職業訓練が所得を減らす可能性もあるが、今回の結果はより詳しく分析してみる価値があろう。\n　ちなみに、以上の結果は単回帰分析からも確認できる (ただし、統計的に有意ではない)。\n\nDiM_fit &lt;- lm(re78 ~ treat, data = la_df)\nmodelsummary(DiM_fit,\n             # 係数の点推定値と95%信頼区間を示す場合\n             estimate   = \"{estimate} [{conf.low}, {conf.high}]\",\n             statistic  = NULL,\n             conf_level = 0.95,\n             # ケース数、決定係数、調整済み決定係数を出力\n             gof_map    = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  6984.170 [6275.791, 7692.549]\n                \n                \n                  treat      \n                  -635.026 [-1925.544, 655.492]\n                \n                \n                  Num.Obs.   \n                  614                          \n                \n                \n                  R2         \n                  0.002                        \n                \n                \n                  R2 Adj.    \n                  0.000                        \n                \n        \n      \n    \n\n\n\n　この直感的でない結果は、もしかしたらセレクションバイアスが原因かも知れない。職業訓練の対象が元々非常に所得が低い回答者になっている可能性がある。たとえば、下の図のように職業訓練の有無が教育水準や人種、これまでの所得などと関係しているとしよう。これらの要因は回答者の現在所得にも関係していると考えられる。この場合、処置有無と所得の間には内生性が存在することになる。\n\n\n作図用のコード\npacman::p_load(ggdag)\ndagify(Income ~ Race + Training + Educ,\n       Training ~ Race + Educ,\n       exposure = \"Training\",\n       outcome  = \"Income\",\n       coords   = list(\n         x = c(Race = 1.5, Educ = 2.5, Training = 1, Income = 3),\n         y = c(Race = 2,   Educ = 2,   Training = 1, Income = 1)\n       )\n       ) |&gt;\n  tidy_dagitty() |&gt;\n  ggdag(confounder_triangle(), node_size = 20) +\n  coord_cartesian(xlim = c(0.8, 3.2), ylim = c(0.8, 2.2)) +\n  theme_dag_blank()\n\n\n\n\n\n\n\n\n\n　本当にそうなのかを、共変量のバランスチェックをしてみよう。もし、処置有無によって回答者の社会経済的要因に大きな差があれば、内生性が存在する証拠になろう。ここでは誰かが作成しました{BalanceR}パッケージを使ってみよう。\n\nblc_chk &lt;- la_df |&gt;\n  BalanceR(group = treat, cov = age:re75)\n\n　{BalanceR}パッケージで共変量を指定する際、:演算子が使える。age:re75は、データセットのageからre75変数までをすべて指定することを意味する。names(la_df)で変数がどの順番で並んでいるかが分かる。\n\nnames(la_df)\n\n [1] \"treat\"    \"age\"      \"educ\"     \"black\"    \"hispanic\" \"white\"   \n [7] \"married\"  \"nodegree\" \"re74\"     \"re75\"     \"re78\"    \n\n\n　それではバランスチェックの結果を確認してみよう。\n\nblc_chk\n\n  Covariate   Mean:0     SD:0   Mean:1     SD:1   SB:0-1\n1       age   28.030   10.787   25.816    7.155   24.190\n2      educ   10.235    2.855   10.346    2.011   -4.476\n3     black    0.203    0.403    0.843    0.365 -167.083\n4  hispanic    0.142    0.350    0.059    0.237   27.740\n5     white    0.655    0.476    0.097    0.297  140.799\n6   married    0.513    0.500    0.189    0.393   72.076\n7  nodegree    0.597    0.491    0.708    0.456  -23.549\n8      re74 5619.237 6788.751 2095.574 4886.620   59.575\n9      re75 2466.484 3291.996 1532.055 3219.251   28.700\n\n\n　アンバランスと判定する標準化差分（標準化バイアス）の閾値には決まった値が無いが、最も緩い基準でも25程度である（計算時に100を掛けないのであれば0.25）。しかし、いくつか怪しい箇所がある。たとえば、treat == 0の回答者において黒人の割合は約20%だが、treat == 1のそれは約85%だ。つまり、黒人ほどより職業訓練を受ける傾向があることを意味する。また、人種は所得にも影響を与えると考えられる。これは処置と応答変数の間に交絡要因があることを意味する。実際、標準化バイアスは-167という、非常に大きい数値を示している。この結果を図としてまとめてみましょう。\n\n# 絶対値変換。SB = 25に破線\nplot(blc_chk, abs = TRUE, vline = 25) +\n  # 縦軸目盛りラベルの修正\n  scale_y_discrete(labels = c(\"age\"      = \"Age\",\n                              \"educ\"     = \"Education\",\n                              \"black\"    = \"Race (Black)\",\n                              \"hispanic\" = \"Race (Hispanic)\",\n                              \"white\"    = \"Race (White)\",\n                              \"married\"  = \"Married\",\n                              \"nodegree\" = \"No Degree\",\n                              \"re74\"     = \"Revenue (1974)\",\n                              \"re75\"     = \"Revenue (1975)\")) +\n  # 凡例の削除\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n　かなり緩めの基準である25を採用しても、人種、結婚有無、74・75年の所得のバランスが非常に悪く、内生性（=自己選択バイアス）があると判断して良いだろう。以下ではこの内生性に対処する様々な方法を紹介する。\n\n\n重回帰分析\n　まずは、重回帰分析からだ。用いる共変量は年齢、教育水準、黒人ダミー、ヒスパニックダミー2、既婚ダミー、学位なしダミー、74・75年の所得だ。lm()関数で78年の所得をこちらの変数に回帰させてみよう。\n\\[\n\\begin{align}\n\\widehat{\\mbox{re78}} = & \\beta_0 + \\beta_1 \\mbox{treat} + \\beta_2 \\mbox{age} + \\beta_3 \\mbox{educ} + \\\\\n& \\beta_4 \\mbox{black} + \\beta_5 \\mbox{hispanic} + \\beta_6 \\mbox{married} + \\beta_7 \\mbox{nodegree} + \\beta_8 \\mbox{re74} + \\beta_9 \\mbox{re75}.\n\\end{align}\n\\]\n\nmlm_fit &lt;- lm(re78 ~ treat + age + educ + black + hispanic + married + \n                   nodegree + re74 + re75, data = la_df)\n\nmodelsummary(list(\"単回帰分析\" = DiM_fit, \"重回帰分析\" = mlm_fit), \n             estimate  = \"{estimate} ({std.error})\",\n             statistic = NULL,\n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                単回帰分析\n                重回帰分析\n              \n        \n        \n        \n                \n                  (Intercept)\n                  6984.170 (360.710)\n                  66.515 (2436.746)  \n                \n                \n                  treat      \n                  -635.026 (657.137)\n                  1548.244 (781.279) \n                \n                \n                  age        \n                                    \n                  12.978 (32.489)    \n                \n                \n                  educ       \n                                    \n                  403.941 (158.906)  \n                \n                \n                  black      \n                                    \n                  -1240.644 (768.764)\n                \n                \n                  hispanic   \n                                    \n                  498.897 (941.943)  \n                \n                \n                  married    \n                                    \n                  406.621 (695.472)  \n                \n                \n                  nodegree   \n                                    \n                  259.817 (847.442)  \n                \n                \n                  re74       \n                                    \n                  0.296 (0.058)      \n                \n                \n                  re75       \n                                    \n                  0.232 (0.105)      \n                \n                \n                  Num.Obs.   \n                  614               \n                  614                \n                \n                \n                  R2         \n                  0.002             \n                  0.148              \n                \n                \n                  R2 Adj.    \n                  0.000             \n                  0.135              \n                \n        \n      \n    \n\n\n\n　共変量を統制したら処置変数の係数は約1548.244ドルだ。単回帰分析の結果とは違って、統計的に有意な正の効果が確認されている。ますます分からなくなってしまう。",
    "crumbs": [
      "マッチング"
    ]
  },
  {
    "objectID": "material/matching.html#マッチング",
    "href": "material/matching.html#マッチング",
    "title": "マッチング",
    "section": "マッチング",
    "text": "マッチング\n\n最近傍マッチング\n　重回帰分析は非常にシンプルで便利な分析方法ですが、いくつかの欠点がある。まず、重回帰分析は変数間の関係（線形結合）および誤差項の分布（平均0の正規分布）などを仮定したパラメトリック分析ということだ。この場合、同じ共変量を持たないケースであっても、勝手に予測を行うこととなる。重回帰分析における処置変数の解釈は「他の共変量がすべて同じ」場合の処置効果である。これは、共変量がすべて同じ場合における（最初に見た）単純差分のようなものである。しかし、「他の共変量がすべて同じ」ケースが存在しない可能性があろう。特に、共変量が多く、連続変数の場合、共変量がすべて同じことは実質あり得ないか、非常に少ないケースに限定されることもある。一方、マッチングを行うと、「他の共変量がすべて同じ」、または「非常に似ている」ケース間で比較を行うことになる。\n　本資料では以下の3つのマッチング手法の実装方法について解説する。\n\n最近傍マッチング（マハラノビス距離）\n最近傍マッチング（傾向スコア）\nCoarsened Exact Matching (CEM)\n\n　まずは、マハラノビス距離を用いた最近傍マッチングから始めよう。だいたいのマッチング手法は{MatchIt}パッケージで解決できる。マッチングデータセットを作成する関数はmatchit()関数であり、使い方は以下の通りである。\n\nmatchit(処置変数 ~ 共変量1 + ... + 共変量k, \n            data = データフレーム名, estimand = \"ATT\",\n            method = \"nearest\", distance = \"mahalanobis\")\n\n　method = \"nearest\"は最近傍マッチングを、distance = \"mahalanobis\"はマハラノビス距離を意味する。estimand = \"ATT\"はATTを推定することを意味する。{MatchIt}の最近傍マッチングの場合、\"ATT\"、または\"ATC\"のみ指定可能である（後で紹介するCEMでは\"ATE\"も指定可能）。早速やってみよう。\n\nmh_mat1 &lt;- matchit(treat ~ age + educ + black + hispanic + married + \n                     nodegree + re74 + re75, \n                   data = la_df, estimand = \"ATT\",\n                   method = \"nearest\", distance = \"mahalanobis\")\n\n　マッチング後のデータでバランスが取れているかを確認するためにはいくつかの方法があるが、ここでは{cobalt}パッケージを使って、標準化差分を確認してみよう。\n\nlove.plot(mh_mat1, thresholds = 0.25, abs = TRUE)\n\n\n\n\n\n\n\n\n　thresholds引数は垂直線（破線）の位置、absは標準化差分を絶対値で示すことを意味する。マッチング後の標準化差分（Adjusted; 赤い点）が0.25より左側に位置している場合、バランスしていると判断できる3。むろん、より厳格な基準として0.03、0.05、0.1を使うこともできる。他にもマッチング後の標準化差分がマッチング前（Unadjusted; 青い点）より改善されるいるか否かも判断できる。今回の例だと、大幅にバランスが改善されている。0.25を基準とした場合、blackはまだバランスが取れていないが、それでも大幅に改善されていることが分かる。\n　それではATTを推定してみよう。推定方法としてはノンパラメトリックな方法とパラメトリック方法があるが、結果は変わらない。ノンパラメトリックな方法はペアごとの差分を計算し、その平均値を求める方法だが、マッチング済みのデータに対し、処置変数を結果変数を回帰させることも、結果的には同じことを行うことになる。したがって、もっと簡単なパラメトリック方法、つまり単回帰分析でATTを推定しよう。\n　回帰分析を行うためにはデータが必要だ。つまり、マッチングされないケースをデータから除去する必要がある。ここではmatch.data()関数を使ったマッチングされたケースのみを抽出してみよう。抽出したデータはmh_data1と名付ける。\n\nmh_data1 &lt;- match.data(mh_mat1)\n\nマッチングデータが取れたら、その中身を確認してみましょう。\n\nmh_data1\n\n# A tibble: 370 × 13\n   treat   age  educ black hispanic white married nodegree  re74  re75   re78\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt;   &lt;int&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1    37    11     1        0     0       1        1     0     0  9930.\n 2     1    22     9     0        1     0       0        1     0     0  3596.\n 3     1    30    12     1        0     0       0        0     0     0 24909.\n 4     1    27    11     1        0     0       0        1     0     0  7506.\n 5     1    33     8     1        0     0       0        1     0     0   290.\n 6     1    22     9     1        0     0       0        1     0     0  4056.\n 7     1    23    12     1        0     0       0        0     0     0     0 \n 8     1    32    11     1        0     0       0        1     0     0  8472.\n 9     1    22    16     1        0     0       0        0     0     0  2164.\n10     1    33    12     0        0     1       1        0     0     0 12418.\n# ℹ 360 more rows\n# ℹ 2 more variables: weights &lt;dbl&gt;, subclass &lt;fct&gt;\n\n\n　データのサイズは370行14列であり、この370行には意味がある。それは処置群の大きさの2倍という点だ。多くの場合、マッチングから計算される処置効果はATEではなく、ATTである。したがって、処置群のデータを100%活用し、共変量（のマハラノビス距離）が最も近いケースを統制群から抽出&マッチングすることになる。だから、マッチング後のサンプルサイズは処置群のサイズの2倍になる。\n　それでは職業訓練のATTを推定してみよう。方法は簡単だ。マッチング後のデータ（mh_data1）を用い、単回帰分析を行うだけである。\n\nmh_fit1 &lt;- lm(re78 ~ treat, data = mh_data1)\n\nmodelsummary(mh_fit1)\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                (1)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  5832.507 \n                \n                \n                             \n                  (527.987)\n                \n                \n                  treat      \n                  516.637  \n                \n                \n                             \n                  (746.686)\n                \n                \n                  Num.Obs.   \n                  370      \n                \n                \n                  R2         \n                  0.001    \n                \n                \n                  R2 Adj.    \n                  -0.001   \n                \n                \n                  AIC        \n                  7624.7   \n                \n                \n                  BIC        \n                  7636.4   \n                \n                \n                  Log.Lik.   \n                  -3809.327\n                \n                \n                  F          \n                  0.479    \n                \n                \n                  RMSE       \n                  7161.96  \n                \n        \n      \n    \n\n\nmodelsummary(list(\"単回帰・非復元\" = mh_fit1), \n             estimate  = \"{estimate} ({std.error})\",\n             statistic = NULL,\n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                単回帰・非復元\n              \n        \n        \n        \n                \n                  (Intercept)\n                  5832.507 (527.987)\n                \n                \n                  treat      \n                  516.637 (746.686) \n                \n                \n                  Num.Obs.   \n                  370               \n                \n                \n                  R2         \n                  0.001             \n                \n                \n                  R2 Adj.    \n                  -0.001            \n                \n        \n      \n    \n\n\n\n　処置効果は約516.637ドルである。今回の結果は重回帰分析よりも推定値が低めであり、統計的に有意に職業訓練の効果があったとは言えないという結果が得られましたね。また、マッチング後のデータを使って重回帰分析を行うこともできる。マッチング後のデータを見ると、黒人ダミーのバランスは大幅に改善されたが、それでもまだアンバランスしていると言える。他にも、74・75年の所得や年齢もそれなりに標準化差分が大きい。このような場合、もう一度共変量を投入して分析を行うこともできる。\n\nmh_fit2 &lt;- lm(re78 ~ treat + age + educ + black + hispanic + married + \n                   nodegree + re74 + re75, data = mh_data1)\n\nmodelsummary(list(\"単回帰・非復元\" = mh_fit1,\n                  \"重回帰・非復元\" = mh_fit2), \n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                単回帰・非復元\n                重回帰・非復元\n              \n        \n        \n        \n                \n                  (Intercept)\n                  5832.507 \n                  -453.365  \n                \n                \n                             \n                  (527.987)\n                  (3546.028)\n                \n                \n                  treat      \n                  516.637  \n                  1239.696  \n                \n                \n                             \n                  (746.686)\n                  (812.039) \n                \n                \n                  age        \n                           \n                  15.112    \n                \n                \n                             \n                           \n                  (45.720)  \n                \n                \n                  educ       \n                           \n                  533.042   \n                \n                \n                             \n                           \n                  (243.621) \n                \n                \n                  black      \n                           \n                  -1158.148 \n                \n                \n                             \n                           \n                  (906.948) \n                \n                \n                  hispanic   \n                           \n                  1120.562  \n                \n                \n                             \n                           \n                  (1676.953)\n                \n                \n                  married    \n                           \n                  653.748   \n                \n                \n                             \n                           \n                  (984.773) \n                \n                \n                  nodegree   \n                           \n                  -170.705  \n                \n                \n                             \n                           \n                  (1116.240)\n                \n                \n                  re74       \n                           \n                  0.071     \n                \n                \n                             \n                           \n                  (0.098)   \n                \n                \n                  re75       \n                           \n                  0.272     \n                \n                \n                             \n                           \n                  (0.155)   \n                \n                \n                  Num.Obs.   \n                  370      \n                  370       \n                \n                \n                  R2         \n                  0.001    \n                  0.076     \n                \n                \n                  R2 Adj.    \n                  -0.001   \n                  0.053     \n                \n        \n      \n    \n\n\n\n　ちなみに、{MatchIt}パッケージを使った最近傍マッチングのの結果は行う度に変化することがある。{MatchIt}パッケージを使った最近傍マッチングの場合、処置群 (統制群)から一つのケースを選択し、最も近い統制群 (処置群)とマッチングする。マッチングされたケースは次のステップからはマッチング対象から除外されることになる4。また、1:1マッチングの場合5、同距離に複数のマッチング対象があると、ランダムに1つのみを選択する。最近傍マッチングを用いる際は、複数推定を行い、推定が安定するかを確認し、不安定な場合は他の手法を使うか、k-最近傍マッチングなどを使ってみよう。\n　ここでは復元マッチングの例を紹介しよう。やり方はmatchit()内にreplace = TRUEを追加するだけだ。\n\nmh_mat2 &lt;- matchit(treat ~ age + educ + black + hispanic + married + \n                     nodegree + re74 + re75, \n                   data = la_df, estimand = \"ATT\", replace = TRUE,\n                   method = \"nearest\", distance = \"mahalanobis\")\nmh_data2 &lt;- match.data(mh_mat2)\n\n　マッチング後のデータを確認する前に、バランスチェックをしてみよう。\n\nlove.plot(mh_mat2, thresholds = 0.25, abs = TRUE)\n\n\n\n\n\n\n\n\n　復元マッチングのメリットは非復元マッチングに比べ、バランス改善の程度が大きいという点だ。非復元マッチングの場合、マッチングに使われた統制群は二度と使われないため、場合によっては近いマッチングケースがあるにも関わらず、マッチングできないからだ。ただし、復元マッチングにもデメリットはある。たとえば、有効サンプルサイズ（Effective Sample Size; ESS）が小さくなり、精度が悪くなる点、場合によっては特殊な標準誤差6を使う必要があるといった欠点もある。\n　それではマッチング後のデータを確認してみよう。\n\nmh_data2\n\n# A tibble: 260 × 12\n   treat   age  educ black hispanic white married nodegree  re74  re75   re78\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt;   &lt;int&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1    37    11     1        0     0       1        1     0     0  9930.\n 2     1    22     9     0        1     0       0        1     0     0  3596.\n 3     1    30    12     1        0     0       0        0     0     0 24909.\n 4     1    27    11     1        0     0       0        1     0     0  7506.\n 5     1    33     8     1        0     0       0        1     0     0   290.\n 6     1    22     9     1        0     0       0        1     0     0  4056.\n 7     1    23    12     1        0     0       0        0     0     0     0 \n 8     1    32    11     1        0     0       0        1     0     0  8472.\n 9     1    22    16     1        0     0       0        0     0     0  2164.\n10     1    33    12     0        0     1       1        0     0     0 12418.\n# ℹ 250 more rows\n# ℹ 1 more variable: weights &lt;dbl&gt;\n\n\n　今回は370行ではないことが分かる。なぜなら統制群のケースが複数マッチングされることもあるからだ。処置群は100%使われるので、マッチングに使われた統制群のケースは260-185=75ケースである。この特徴により推定の際は一点、注意が必要である。推定のやり方自体はほぼ同じである。しかし、非復元マッチングの場合、統制群からマッチングされたケースは1回のみ使われるため、一つ一つのケースの重みは同じである。match.data()から得られーたデータにはweights列が含まれており、mh_data1のweights列を見ると全ての重みが1だということが分かる。\n\nmh_data1$weights\n\n  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n 81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n181 182 183 184 185 186 190 191 192 193 195 200 202 203 205 208 209 212 226 228 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n231 233 244 254 257 271 273 274 275 276 278 279 280 281 282 283 284 285 288 290 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n295 296 297 303 306 312 319 322 323 325 327 335 339 342 343 344 352 353 356 358 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n362 363 364 365 367 368 369 370 372 374 376 378 381 384 387 390 393 394 398 399 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n402 403 405 409 411 413 414 415 416 419 420 422 423 427 430 432 436 438 441 443 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n445 446 450 451 453 454 455 457 458 459 462 463 465 466 467 470 474 475 476 478 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n485 493 499 500 501 507 508 510 511 512 515 516 518 520 522 524 525 526 527 530 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n536 537 538 539 540 541 542 544 546 551 552 553 555 556 557 558 559 560 561 562 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n563 565 566 567 571 572 573 574 576 577 578 580 581 582 583 584 585 586 591 592 \n  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n593 594 596 597 601 604 607 608 610 613 \n  1   1   1   1   1   1   1   1   1   1 \n\n\n　一方、復元マッチングの場合、一つのケースが複数回マッチングされる場合もある。たとえば、191番目のケースは統制群であるが、重みが1.2162162だ。この意味は191番目のケースは計3回（\\(1.2162162\\times\\frac{185}{75}\\)）マッチングに使われたことを意味する。\n\nmh_data2$weights\n\n        1         2         3         4         5         6         7         8 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n        9        10        11        12        13        14        15        16 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       17        18        19        20        21        22        23        24 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       25        26        27        28        29        30        31        32 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       33        34        35        36        37        38        39        40 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       41        42        43        44        45        46        47        48 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       49        50        51        52        53        54        55        56 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       57        58        59        60        61        62        63        64 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       65        66        67        68        69        70        71        72 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       73        74        75        76        77        78        79        80 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       81        82        83        84        85        86        87        88 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       89        90        91        92        93        94        95        96 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n       97        98        99       100       101       102       103       104 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      105       106       107       108       109       110       111       112 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      113       114       115       116       117       118       119       120 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      121       122       123       124       125       126       127       128 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      129       130       131       132       133       134       135       136 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      137       138       139       140       141       142       143       144 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      145       146       147       148       149       150       151       152 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      153       154       155       156       157       158       159       160 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      161       162       163       164       165       166       167       168 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      169       170       171       172       173       174       175       176 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      177       178       179       180       181       182       183       184 \n1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 \n      185       191       202       244       257       280       281       282 \n1.0000000 1.2162162 0.4054054 0.4054054 0.4054054 0.4054054 0.4054054 0.4054054 \n      284       295       297       303       312       319       325       335 \n1.6216216 0.8108108 0.4054054 3.6486486 0.4054054 1.6216216 2.4324324 0.4054054 \n      343       344       353       362       364       384       387       403 \n0.4054054 0.8108108 0.4054054 0.4054054 0.8108108 0.4054054 0.4054054 0.8108108 \n      405       409       411       413       420       422       423       432 \n0.4054054 0.4054054 2.0270270 0.8108108 0.4054054 0.4054054 0.4054054 0.4054054 \n      438       450       451       454       463       475       476       493 \n1.6216216 0.4054054 0.8108108 1.2162162 0.4054054 0.4054054 0.4054054 1.2162162 \n      507       511       512       515       516       518       520       524 \n0.4054054 0.4054054 0.4054054 0.4054054 0.8108108 0.8108108 0.8108108 0.4054054 \n      526       530       537       538       539       540       546       551 \n0.4054054 0.4054054 3.2432432 0.8108108 0.4054054 0.8108108 0.4054054 0.4054054 \n      552       553       557       558       559       561       565       566 \n1.6216216 5.2702703 0.8108108 2.8378378 1.2162162 1.6216216 0.4054054 0.4054054 \n      573       576       577       578       584       585       592       597 \n2.4324324 0.4054054 1.6216216 0.4054054 1.2162162 1.2162162 0.8108108 0.8108108 \n      601       604       608       613 \n1.2162162 0.4054054 7.2972973 0.4054054 \n\n\n　したがって、復元マッチングの場合、lm()内にweights引数を必ず指定する必要がある。\n\nmh_fit3 &lt;- lm(re78 ~ treat, \n              data = mh_data2, weights = weights)\nmh_fit4 &lt;- lm(re78 ~ treat + age + educ + black + hispanic + married + \n                   nodegree + re74 + re75, \n              data = mh_data2, weights = weights)\n\nmodelsummary(list(\"単回帰・非復元\" = mh_fit1,\n                  \"重回帰・非復元\" = mh_fit2,\n                  \"単回帰・復元\"   = mh_fit3,\n                  \"重回帰・復元\"   = mh_fit4), \n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                単回帰・非復元\n                重回帰・非復元\n                単回帰・復元\n                重回帰・復元\n              \n        \n        \n        \n                \n                  (Intercept)\n                  5832.507 \n                  -453.365  \n                  5744.482  \n                  1371.865  \n                \n                \n                             \n                  (527.987)\n                  (3546.028)\n                  (854.641) \n                  (4808.980)\n                \n                \n                  treat      \n                  516.637  \n                  1239.696  \n                  604.661   \n                  524.037   \n                \n                \n                             \n                  (746.686)\n                  (812.039) \n                  (1013.175)\n                  (1011.417)\n                \n                \n                  age        \n                           \n                  15.112    \n                            \n                  8.365     \n                \n                \n                             \n                           \n                  (45.720)  \n                            \n                  (64.228)  \n                \n                \n                  educ       \n                           \n                  533.042   \n                            \n                  476.666   \n                \n                \n                             \n                           \n                  (243.621) \n                            \n                  (319.397) \n                \n                \n                  black      \n                           \n                  -1158.148 \n                            \n                  -1562.414 \n                \n                \n                             \n                           \n                  (906.948) \n                            \n                  (1568.526)\n                \n                \n                  hispanic   \n                           \n                  1120.562  \n                            \n                  -17.586   \n                \n                \n                             \n                           \n                  (1676.953)\n                            \n                  (2423.801)\n                \n                \n                  married    \n                           \n                  653.748   \n                            \n                  330.704   \n                \n                \n                             \n                           \n                  (984.773) \n                            \n                  (1285.183)\n                \n                \n                  nodegree   \n                           \n                  -170.705  \n                            \n                  106.692   \n                \n                \n                             \n                           \n                  (1116.240)\n                            \n                  (1421.140)\n                \n                \n                  re74       \n                           \n                  0.071     \n                            \n                  0.091     \n                \n                \n                             \n                           \n                  (0.098)   \n                            \n                  (0.134)   \n                \n                \n                  re75       \n                           \n                  0.272     \n                            \n                  0.193     \n                \n                \n                             \n                           \n                  (0.155)   \n                            \n                  (0.208)   \n                \n                \n                  Num.Obs.   \n                  370      \n                  370       \n                  260       \n                  260       \n                \n                \n                  R2         \n                  0.001    \n                  0.076     \n                  0.001     \n                  0.041     \n                \n                \n                  R2 Adj.    \n                  -0.001   \n                  0.053     \n                  -0.002    \n                  0.007     \n                \n        \n      \n    \n\n\n\n　推定の結果は、いずれも正であり、職業訓練は所得に正の影響を与えるという結果が得られている。しかし、いずれも標準誤差が非常に大きく、統計的に有意な結果は得られていない。\n\n\n傾向スコア\n　傾向スコアマッチングも、これまでのコードとほぼ同じだ。マハラノビス最近傍マッチングのコマンドからdistance = ...引数を抜けば、傾向スコアマッチングができる7。ここでもreplace = TRUEを指定し、復元マッチングをやってみよう。\n\nps_mat &lt;- matchit(treat ~ age + educ + black + hispanic + married + \n                    nodegree + re74 + re75, \n                  data = la_df, replace = TRUE,\n                  method = \"nearest\", estimand = \"ATT\")\n\n　続いて、バランスチェックをしよう。\n\nlove.plot(ps_mat, thresholds = 0.25, abs = TRUE)\n\n\n\n\n\n\n\n\n　バランスが大幅に改善されていることが分かる。ちなみに最上段のdistanceは傾向スコアを意味する。\n　それでは、ATT推定のためにマッチング後のデータを抽出しよう。\n\n# 傾向スコアマッチング後のデータセットを抽出\nps_data &lt;- match.data(ps_mat)\n\n　傾向スコアを用いたATTをの推定もこれまでと同様、回帰分析を使用する。ここでも共変量なしの単回帰とありの重回帰を行い、マハラノビス距離最近傍マッチング（復元）と結果を比べてみよう。。\n\n# 処置効果の推定\nps_fit1 &lt;- lm(re78 ~ treat, \n             data = ps_data, weights = weights)\nps_fit2 &lt;- lm(re78 ~ treat + age + educ + black + hispanic + \n                married + nodegree + re74 + re75, \n             data = ps_data, weights = weights)\n\nmodelsummary(list(\"MH (単回帰)\"   = mh_fit3,\n                  \"MH (重回帰)\"   = mh_fit4,\n                  \"PS (単回帰)\"   = ps_fit1,\n                  \"PS (重回帰)\"   = ps_fit2), \n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                MH (単回帰)\n                MH (重回帰)\n                PS (単回帰)\n                PS (重回帰)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  5744.482  \n                  1371.865  \n                  4357.528 \n                  -1268.481 \n                \n                \n                             \n                  (854.641) \n                  (4808.980)\n                  (798.432)\n                  (4329.104)\n                \n                \n                  treat      \n                  604.661   \n                  524.037   \n                  1991.615 \n                  1926.426  \n                \n                \n                             \n                  (1013.175)\n                  (1011.417)\n                  (959.197)\n                  (962.213) \n                \n                \n                  age        \n                            \n                  8.365     \n                           \n                  43.983    \n                \n                \n                             \n                            \n                  (64.228)  \n                           \n                  (59.595)  \n                \n                \n                  educ       \n                            \n                  476.666   \n                           \n                  462.507   \n                \n                \n                             \n                            \n                  (319.397) \n                           \n                  (275.406) \n                \n                \n                  black      \n                            \n                  -1562.414 \n                           \n                  -892.421  \n                \n                \n                             \n                            \n                  (1568.526)\n                           \n                  (1526.070)\n                \n                \n                  hispanic   \n                            \n                  -17.586   \n                           \n                  -171.481  \n                \n                \n                             \n                            \n                  (2423.801)\n                           \n                  (2323.016)\n                \n                \n                  married    \n                            \n                  330.704   \n                           \n                  282.877   \n                \n                \n                             \n                            \n                  (1285.183)\n                           \n                  (1282.599)\n                \n                \n                  nodegree   \n                            \n                  106.692   \n                           \n                  159.611   \n                \n                \n                             \n                            \n                  (1421.140)\n                           \n                  (1367.608)\n                \n                \n                  re74       \n                            \n                  0.091     \n                           \n                  0.056     \n                \n                \n                             \n                            \n                  (0.134)   \n                           \n                  (0.121)   \n                \n                \n                  re75       \n                            \n                  0.193     \n                           \n                  0.163     \n                \n                \n                             \n                            \n                  (0.208)   \n                           \n                  (0.198)   \n                \n                \n                  Num.Obs.   \n                  260       \n                  260       \n                  267      \n                  267       \n                \n                \n                  R2         \n                  0.001     \n                  0.041     \n                  0.016    \n                  0.053     \n                \n                \n                  R2 Adj.    \n                  -0.002    \n                  0.007     \n                  0.012    \n                  0.020     \n                \n        \n      \n    \n\n\n\n　傾向スコアマッチングでも正の処置効果（ATT）が確認され、今回は統計的に有意な結果が得られている。\n\n\nCEM\n　Coarsened Exact Matching（CEM）はマハラノビス最近傍マッチング同様、matchit()関数を使うが、事前に{cem}パッケージをインストールしておく必要がある（install.pacakges(\"cem\")）。\n　CEMのようなExact Matching類の手法は距離を図る必要がないので、distance引数は不要である。マッチング方法を指定するmethod引数はこれまで使ってきた\"nearest\"（最近傍）でなく、\"cem\"に替えよう。推定可能な処置効果はATE（最近傍マッチングでは指定できなかったもの）、ATT、ATCであるが、ここではATTを推定してみよう。\n　マッチングをしたらmatch.data()でマッチングされたデータを抽出する。\n\ncem_mat &lt;- matchit(treat ~ age + educ + black + hispanic + married + \n                     nodegree + re74 + re75, data = la_df,\n                   method = \"cem\", estimand = \"ATT\")\n\n　つづいて、{cobalt}のlove.plot()を使用して、バランスチェックを行う。\n\nlove.plot(cem_mat, thresholds = 0.25, abs = TRUE)\n\n\n\n\n\n\n\n\n　CEMの場合、（非復元）最近傍マッチングよりもバランスが大きく改善されることが分かる。その理由は簡単だ。最近傍マッチングの場合、最も近いケースであれば、どれほど離れていてもマッチングされる。一方、CEMは正確マッチングの一種であるため、ある程度離れているケースを捨ててしまうため、結局は共変量が非常に近いケースのみを残すことになります。\n　それでは、match.data()関数を使ってマッチング後のデータを抽出してみよう。\n\ncem_data &lt;- match.data(cem_mat)\n\ncem_data\n\n# A tibble: 140 × 13\n   treat   age  educ black hispanic white married nodegree  re74  re75   re78\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;int&gt;   &lt;int&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1    22     9     0        1     0       0        1     0     0  3596.\n 2     1    27    11     1        0     0       0        1     0     0  7506.\n 3     1    22     9     1        0     0       0        1     0     0  4056.\n 4     1    23    12     1        0     0       0        0     0     0     0 \n 5     1    22    16     1        0     0       0        0     0     0  2164.\n 6     1    19     9     1        0     0       0        1     0     0  8174.\n 7     1    21    13     1        0     0       0        0     0     0 17095.\n 8     1    18     8     1        0     0       0        1     0     0     0 \n 9     1    17     7     1        0     0       0        1     0     0  3024.\n10     1    19    10     1        0     0       0        1     0     0  3229.\n# ℹ 130 more rows\n# ℹ 2 more variables: weights &lt;dbl&gt;, subclass &lt;fct&gt;\n\n\n　CEMの場合、マッチングされないブロックは捨てられるため、マハラノビス距離最近傍マッチングよりもサンプルサイズが小さくなりやすい。マッチング相手がなければ、たとえ処置群だとしても除外される。また、処置群と統制群のサンプルサイズも不均衡になる。マッチング結果を見ると、処置群からは65ケース、統制群からは75サンプルのみ残っている。\n\ncem_data |&gt;\n  count(treat)\n\n# A tibble: 2 × 2\n  treat     n\n  &lt;int&gt; &lt;int&gt;\n1     0    75\n2     1    65\n\n\n　処置効果はこれまでの復元マッチングと同様、重み付き回帰分析で推定するｙ。ここでも共変量ありとなし、2パターンで推定してみよう。\n\ncem_fit1 &lt;- lm(re78 ~ treat, \n               data = cem_data, weights = weights)\ncem_fit2 &lt;- lm(re78 ~ treat + age + educ + black + hispanic +\n                 married + nodegree + re74 + re75, \n               data = cem_data, weights = weights)\n\nmodelsummary(list(\"MH (単回帰)\"   = mh_fit3,\n                  \"MH (重回帰)\"   = mh_fit4,\n                  \"PS (単回帰)\"   = ps_fit1,\n                  \"PS (重回帰)\"   = ps_fit2,\n                  \"CEM (単回帰)\"  = cem_fit1,\n                  \"CEM (重回帰)\"  = cem_fit2), \n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                MH (単回帰)\n                MH (重回帰)\n                PS (単回帰)\n                PS (重回帰)\n                CEM (単回帰)\n                CEM (重回帰)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  5744.482  \n                  1371.865  \n                  4357.528 \n                  -1268.481 \n                  5265.785  \n                  -7253.717 \n                \n                \n                             \n                  (854.641) \n                  (4808.980)\n                  (798.432)\n                  (4329.104)\n                  (850.457) \n                  (7031.576)\n                \n                \n                  treat      \n                  604.661   \n                  524.037   \n                  1991.615 \n                  1926.426  \n                  1070.907  \n                  1207.183  \n                \n                \n                             \n                  (1013.175)\n                  (1011.417)\n                  (959.197)\n                  (962.213) \n                  (1248.129)\n                  (1245.959)\n                \n                \n                  age        \n                            \n                  8.365     \n                           \n                  43.983    \n                            \n                  147.970   \n                \n                \n                             \n                            \n                  (64.228)  \n                           \n                  (59.595)  \n                            \n                  (107.716) \n                \n                \n                  educ       \n                            \n                  476.666   \n                           \n                  462.507   \n                            \n                  879.978   \n                \n                \n                             \n                            \n                  (319.397) \n                           \n                  (275.406) \n                            \n                  (472.982) \n                \n                \n                  black      \n                            \n                  -1562.414 \n                           \n                  -892.421  \n                            \n                  -1941.465 \n                \n                \n                             \n                            \n                  (1568.526)\n                           \n                  (1526.070)\n                            \n                  (2485.215)\n                \n                \n                  hispanic   \n                            \n                  -17.586   \n                           \n                  -171.481  \n                            \n                  437.208   \n                \n                \n                             \n                            \n                  (2423.801)\n                           \n                  (2323.016)\n                            \n                  (4223.958)\n                \n                \n                  married    \n                            \n                  330.704   \n                           \n                  282.877   \n                            \n                  -3213.470 \n                \n                \n                             \n                            \n                  (1285.183)\n                           \n                  (1282.599)\n                            \n                  (4445.151)\n                \n                \n                  nodegree   \n                            \n                  106.692   \n                           \n                  159.611   \n                            \n                  1779.900  \n                \n                \n                             \n                            \n                  (1421.140)\n                           \n                  (1367.608)\n                            \n                  (2019.035)\n                \n                \n                  re74       \n                            \n                  0.091     \n                           \n                  0.056     \n                            \n                  -0.262    \n                \n                \n                             \n                            \n                  (0.134)   \n                           \n                  (0.121)   \n                            \n                  (0.601)   \n                \n                \n                  re75       \n                            \n                  0.193     \n                           \n                  0.163     \n                            \n                  2.034     \n                \n                \n                             \n                            \n                  (0.208)   \n                           \n                  (0.198)   \n                            \n                  (0.883)   \n                \n                \n                  Num.Obs.   \n                  260       \n                  260       \n                  267      \n                  267       \n                  140       \n                  140       \n                \n                \n                  R2         \n                  0.001     \n                  0.041     \n                  0.016    \n                  0.053     \n                  0.005     \n                  0.079     \n                \n                \n                  R2 Adj.    \n                  -0.002    \n                  0.007     \n                  0.012    \n                  0.020     \n                  -0.002    \n                  0.015     \n                \n        \n      \n    \n\n\n\n　推定の結果は、いずれも正であり、職業訓練は所得に正の影響を与えるという結果が得られている。しかし、いずれも標準誤差が非常に大きく、統計的に有意な結果は得られていない。",
    "crumbs": [
      "マッチング"
    ]
  },
  {
    "objectID": "material/matching.html#ipw",
    "href": "material/matching.html#ipw",
    "title": "マッチング",
    "section": "IPW",
    "text": "IPW\n　最後に、{WeightIt}パッケージを使ってIPW推定を行ってみよう。このパッケージはこれまで使ってた{MatchIt}パッケージと非常に似ている。まず、第一引数として処置変数を結果変数、処置有無に影響を与えると考えられる共変量を説明変数とした回帰式を入れる。続いて、データ（data）、IPW算出の方法（method）、推定の対象（estimand）を指定する。データはdata = la_dfとし、傾向スコアからIPWを算出するためmethod = \"ps\"を指定、最後にATT推定のためにestimand = \"ATT\"を指定する。今回はIPW算出のために今回は傾向スコアを使うが、「処置を受ける確率」が計算できるなら何でも良い。たとえば、Imai and Ratkovic (2014)8が推奨しているCovariate Balancing Propensity Score (CBPS) を使用する場合は\"ps\"の代わりに\"cbps\"を、複数の推定を組み合わせるスーパーラーニングをする場合は\"super\"9などが使える。他にもエントロピーバランシングなど様々なオプションが提供されている。\n\nipw_data &lt;- weightit(treat ~ age + educ + black + hispanic + \n                       married + nodegree + re74 + re75, \n                     data = la_df, method = \"ps\", estimand = \"ATT\")\n\n　matchit()とは違って、別途match.data()などの関数は不要である。weightit()パッケージを使うと、IPW推定のための重み変数を返してくれる。また、weightit()から得られたデータは{cobalt}でバランスチェックもできる。\n\nlove.plot(ipw_data, thresholds = 0.25, abs = TRUE)\n\n\n\n\n\n\n\n\n　読み方は最近傍マッチング（傾向スコア）と同じである。ここでもバランスが大幅に改善されていることが分かる。\n　それではIPW推定量を計算してみよう。ここで一つ注意が必要だ。それはdataをipw_dataでなく、元のデータであるla_dfを使うという点だ。また、重み変数はla_dfには含まれていないため、ipw_data$weightsを使う必要がある。\n\nipw_fit1 &lt;- lm(re78 ~ treat, \n               data = la_df, weights = ipw_data$weights)\nipw_fit2 &lt;- lm(re78 ~ treat + age + educ + black + hispanic + \n                       married + nodegree + re74 + re75, \n               data = la_df, weights = ipw_data$weights)\n\nmodelsummary(list(\"MH (単)\"   = mh_fit3,\n                  \"MH (重)\"   = mh_fit4,\n                  \"PS (単)\"   = ps_fit1,\n                  \"PS (重)\"   = ps_fit2,\n                  \"CEM (単)\"  = cem_fit1,\n                  \"CEM (重)\"  = cem_fit2,\n                  \"IPW (単)\"  = ipw_fit1,\n                  \"IPW (重)\"  = ipw_fit2), \n             gof_map   = c(\"nobs\", \"r.squared\", \"adj.r.squared\"))\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                MH (単)\n                MH (重)\n                PS (単)\n                PS (重)\n                CEM (単)\n                CEM (重)\n                IPW (単)\n                IPW (重)\n              \n        \n        \n        \n                \n                  (Intercept)\n                  5744.482  \n                  1371.865  \n                  4357.528 \n                  -1268.481 \n                  5265.785  \n                  -7253.717 \n                  5135.072 \n                  853.666   \n                \n                \n                             \n                  (854.641) \n                  (4808.980)\n                  (798.432)\n                  (4329.104)\n                  (850.457) \n                  (7031.576)\n                  (401.194)\n                  (2708.329)\n                \n                \n                  treat      \n                  604.661   \n                  524.037   \n                  1991.615 \n                  1926.426  \n                  1070.907  \n                  1207.183  \n                  1214.071 \n                  1237.405  \n                \n                \n                             \n                  (1013.175)\n                  (1011.417)\n                  (959.197)\n                  (962.213) \n                  (1248.129)\n                  (1245.959)\n                  (568.904)\n                  (554.929) \n                \n                \n                  age        \n                            \n                  8.365     \n                           \n                  43.983    \n                            \n                  147.970   \n                           \n                  -17.562   \n                \n                \n                             \n                            \n                  (64.228)  \n                           \n                  (59.595)  \n                            \n                  (107.716) \n                           \n                  (33.570)  \n                \n                \n                  educ       \n                            \n                  476.666   \n                           \n                  462.507   \n                            \n                  879.978   \n                           \n                  489.248   \n                \n                \n                             \n                            \n                  (319.397) \n                           \n                  (275.406) \n                            \n                  (472.982) \n                           \n                  (172.550) \n                \n                \n                  black      \n                            \n                  -1562.414 \n                           \n                  -892.421  \n                            \n                  -1941.465 \n                           \n                  -1149.368 \n                \n                \n                             \n                            \n                  (1568.526)\n                           \n                  (1526.070)\n                            \n                  (2485.215)\n                           \n                  (950.708) \n                \n                \n                  hispanic   \n                            \n                  -17.586   \n                           \n                  -171.481  \n                            \n                  437.208   \n                           \n                  202.126   \n                \n                \n                             \n                            \n                  (2423.801)\n                           \n                  (2323.016)\n                            \n                  (4223.958)\n                           \n                  (1463.378)\n                \n                \n                  married    \n                            \n                  330.704   \n                           \n                  282.877   \n                            \n                  -3213.470 \n                           \n                  424.461   \n                \n                \n                             \n                            \n                  (1285.183)\n                           \n                  (1282.599)\n                            \n                  (4445.151)\n                           \n                  (807.171) \n                \n                \n                  nodegree   \n                            \n                  106.692   \n                           \n                  159.611   \n                            \n                  1779.900  \n                           \n                  -92.470   \n                \n                \n                             \n                            \n                  (1421.140)\n                           \n                  (1367.608)\n                            \n                  (2019.035)\n                           \n                  (844.246) \n                \n                \n                  re74       \n                            \n                  0.091     \n                           \n                  0.056     \n                            \n                  -0.262    \n                           \n                  0.050     \n                \n                \n                             \n                            \n                  (0.134)   \n                           \n                  (0.121)   \n                            \n                  (0.601)   \n                           \n                  (0.078)   \n                \n                \n                  re75       \n                            \n                  0.193     \n                           \n                  0.163     \n                            \n                  2.034     \n                           \n                  0.318     \n                \n                \n                             \n                            \n                  (0.208)   \n                           \n                  (0.198)   \n                            \n                  (0.883)   \n                           \n                  (0.121)   \n                \n                \n                  Num.Obs.   \n                  260       \n                  260       \n                  267      \n                  267       \n                  140       \n                  140       \n                  614      \n                  614       \n                \n                \n                  R2         \n                  0.001     \n                  0.041     \n                  0.016    \n                  0.053     \n                  0.005     \n                  0.079     \n                  0.007    \n                  0.071     \n                \n                \n                  R2 Adj.    \n                  -0.002    \n                  0.007     \n                  0.012    \n                  0.020     \n                  -0.002    \n                  0.015     \n                  0.006    \n                  0.057     \n                \n        \n      \n    \n\n\n\n　IPWの場合、正の処置効果（ATT）が確認され、今回は統計的に有意な結果が得られた。",
    "crumbs": [
      "マッチング"
    ]
  },
  {
    "objectID": "material/matching.html#バランスチェック",
    "href": "material/matching.html#バランスチェック",
    "title": "マッチング",
    "section": "バランスチェック",
    "text": "バランスチェック\n　ここでは標準化差分以外のバランスチェック方法について紹介する。まず、特定の共変量の分布をヒストグラムを用い、マッチング前後で比較する方法だ。これもまた{coblat}パッケージを使用するが、今回はlove.plot()でなく、bal.plot()を使う。\n　第1引数はmatchit()から得られたオブジェクト名、続いてvar.nameにはバランスをチェックする共変量名（傾向スコアの場合は\"distance\"）、他は以下のコードの通りに打てばよい。\n\nbal.plot(ps_mat, var.name = \"distance\", which = \"both\",\n         type = \"histogram\", mirror = TRUE)\n\n\n\n\n\n\n\n\n　左がマッチング前、右が後である。また、上部の赤いヒストグラムは統制群、下部の青は処置群を意味する。もし、傾向スコアのバランスが取れているならヒストグラムは上下対称となる。マッチング前だと統制群は傾向スコアの値が小さく、処置群のそれは大きい傾向があったが、マッチング後はほぼ上下対称となっていることからバランスが改善されたことが分かる。\n　ちなみに、ヒストグラムが作成できないダミー変数の場合、棒グラフが表示される。読み方は同じであるが、今回は上下対称ではなく、赤い棒と青い棒の高さが一致すればバランスが取れていると確認できる。\n\nbal.plot(ps_mat, var.name = \"black\", which = \"both\",\n         type = \"histogram\", mirror = TRUE)\n\n\n\n\n\n\n\n\n　このようにヒストグラム（棒グラフ）を使うと、一つ一つの変数の図が必要となってくるので、実際の論文には掲載しにくい。それでも分析の段階では一つ一つのバランスを詳細に見ることは重要である。たとえば、傾向スコアマッチングの場合、回答者の年齢（age）のバランスは改善されている。本当にそうだろうか。ageのバランスを確認してみよう。\n\nbal.plot(ps_mat, var.name = \"age\", which = \"both\",\n         type = \"histogram\", mirror = TRUE)\n\n\n\n\n\n\n\n\n　改善ところか、改悪されているとも読み取れる。標準化差分は平均値と標準誤差のみに依存するため、分布の情報までは分からない。このような場合は、処置効果の推定の際、共変量を投入して更に調整が必要であることを示唆する。",
    "crumbs": [
      "マッチング"
    ]
  },
  {
    "objectID": "material/matching.html#推定値の比較",
    "href": "material/matching.html#推定値の比較",
    "title": "マッチング",
    "section": "推定値の比較",
    "text": "推定値の比較\n　これまで見てきたように、同じく「マッチング」とは言っても手法によって結果のばらつきが大きいことが分かる。また、同じ手法であっても復元か、非復元か、1:1マッチングか、1:nマッチングか、CEMならレイヤーをどれほど細かくするかなどによっても結果は大きく変わる。\n　ここまで得られた多くの結果から自分にとって都合の良い結果のみを報告するのは、あるいみ研究不正に近い。なぜなら、これを逆にいうと自分にとって都合の悪い結果を隠蔽しているものだからだ。したがって、実際の論文にはそれぞれの結果を報告・比較し、その結果を慎重に解釈する必要がある。ここではこれまで推定してきたマッチングの結果を一つの図としてまとめてみよう。\n　まずは、{broom}パッケージのtidy()関数で回帰分析の結果を表でまとめ、bind_rows()を使って一つに統合する。tidy()内にconf.int = TRUEを入れておくと、95%信頼区間も出してくれるので、今の段階で入れておこう。\n\natt_df &lt;- bind_rows(list(\"単回帰_最近傍（マハラノビス）\" = tidy(mh_fit3, conf.int = TRUE),\n                         \"重回帰_最近傍（マハラノビス）\" = tidy(mh_fit4, conf.int = TRUE),\n                         \"単回帰_最近傍（傾向スコア）\"   = tidy(ps_fit1, conf.int = TRUE),\n                         \"重回帰_最近傍（傾向スコア）\"   = tidy(ps_fit2, conf.int = TRUE),\n                         \"単回帰_CEM\" = tidy(cem_fit1, conf.int = TRUE),\n                         \"重回帰_CEM\" = tidy(cem_fit2, conf.int = TRUE),\n                         \"単回帰_IPW\" = tidy(ipw_fit1, conf.int = TRUE),\n                         \"重回帰_IPW\" = tidy(ipw_fit2, conf.int = TRUE)),\n                    .id = \"Model\")\n\natt_df\n\n# A tibble: 48 × 8\n   Model          term  estimate std.error statistic  p.value conf.low conf.high\n   &lt;chr&gt;          &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 単回帰_最近傍… (Int…  5744.       855.    6.72    1.15e-10    4062.     7427.\n 2 単回帰_最近傍… treat   605.      1013.    0.597   5.51e- 1   -1390.     2600.\n 3 重回帰_最近傍… (Int…  1372.      4809.    0.285   7.76e- 1   -8099.    10843.\n 4 重回帰_最近傍… treat   524.      1011.    0.518   6.05e- 1   -1468.     2516.\n 5 重回帰_最近傍… age       8.36      64.2   0.130   8.96e- 1    -118.      135.\n 6 重回帰_最近傍… educ    477.       319.    1.49    1.37e- 1    -152.     1106.\n 7 重回帰_最近傍… black -1562.      1569.   -0.996   3.20e- 1   -4652.     1527.\n 8 重回帰_最近傍… hisp…   -17.6     2424.   -0.00726 9.94e- 1   -4791.     4756.\n 9 重回帰_最近傍… marr…   331.      1285.    0.257   7.97e- 1   -2200.     2862.\n10 重回帰_最近傍… node…   107.      1421.    0.0751  9.40e- 1   -2692.     2906.\n# ℹ 38 more rows\n\n\n　続いて、処置効果（ATT）を意味する行のみを残す。termの値が\"treat\"と一致する行が処置効果である。\n\natt_df &lt;- att_df |&gt;\n  filter(term == \"treat\")\n\natt_df\n\n# A tibble: 8 × 8\n  Model            term  estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;            &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 単回帰_最近傍（… treat     605.     1013.     0.597  0.551   -1390.      2600.\n2 重回帰_最近傍（… treat     524.     1011.     0.518  0.605   -1468.      2516.\n3 単回帰_最近傍（… treat    1992.      959.     2.08   0.0388    103.      3880.\n4 重回帰_最近傍（… treat    1926.      962.     2.00   0.0463     31.6     3821.\n5 単回帰_CEM       treat    1071.     1248.     0.858  0.392   -1397.      3539.\n6 重回帰_CEM       treat    1207.     1246.     0.969  0.334   -1258.      3672.\n7 単回帰_IPW       treat    1214.      569.     2.13   0.0332     96.8     2331.\n8 重回帰_IPW       treat    1237.      555.     2.23   0.0261    148.      2327.\n\n\n　ここでは新しく登場した関数を使用する。separate()関数は文字列で構成されている列を、特定の文字を基準に列分割する関数である。Model行のそれぞれの値は回帰モデル_マッチングモデルで構成され、これを_文字を基準にRegressionとMethod列に分割する。分割する列名はcol、分割後の列名はinto、分割の基準となる文字はsepに指定する。\n\natt_df &lt;- att_df |&gt;\n  separate(col  = Model,\n           into = c(\"Regression\", \"Method\"),\n           sep  = \"_\")\n\natt_df\n\n# A tibble: 8 × 9\n  Regression Method          term  estimate std.error statistic p.value conf.low\n  &lt;chr&gt;      &lt;chr&gt;           &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 単回帰     最近傍（マハラ… treat     605.     1013.     0.597  0.551   -1390. \n2 重回帰     最近傍（マハラ… treat     524.     1011.     0.518  0.605   -1468. \n3 単回帰     最近傍（傾向ス… treat    1992.      959.     2.08   0.0388    103. \n4 重回帰     最近傍（傾向ス… treat    1926.      962.     2.00   0.0463     31.6\n5 単回帰     CEM             treat    1071.     1248.     0.858  0.392   -1397. \n6 重回帰     CEM             treat    1207.     1246.     0.969  0.334   -1258. \n7 単回帰     IPW             treat    1214.      569.     2.13   0.0332     96.8\n8 重回帰     IPW             treat    1237.      555.     2.23   0.0261    148. \n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\n　後はこのデータを使って作図するだけである。データをggplot()に渡す前にRegressionとMethod列をfactor化しておこう。\n\natt_df |&gt;\n  mutate(Regression = fct_inorder(Regression),\n         Method     = fct_inorder(Method)) |&gt;\n  ggplot() +\n  geom_pointrange(aes(x = estimate, y = Method,\n                      xmin = conf.low, xmax = conf.high,\n                      color = Regression),\n                  position = position_dodge2(1/2)) +\n  labs(x = \"処置群における処置効果（ATT）\", y = \"\", color = \"モデル\",\n       caption = \"注: マッチングの場合、復元マッチングを行った。\") +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n\n　もし、縦軸の順番を逆にしたい場合は、fct_rev()関数で要素の順番を逆にする。\n\natt_df |&gt;\n  mutate(Regression = fct_inorder(Regression),\n         Method     = fct_inorder(Method),\n         Method     = fct_rev(Method)) |&gt;\n  ggplot() +\n  geom_vline(xintercept = 0) +\n  geom_pointrange(aes(x = estimate, y = Method,\n                      xmin = conf.low, xmax = conf.high,\n                      color = Regression),\n                  position = position_dodge2(1/2)) +\n  labs(x = \"処置群における処置効果（ATT）\", y = \"\", color = \"モデル\",\n       caption = \"注: マッチングの場合、復元マッチングを行った。\") +\n  theme_bw(base_size = 12)",
    "crumbs": [
      "マッチング"
    ]
  },
  {
    "objectID": "material/matching.html#footnotes",
    "href": "material/matching.html#footnotes",
    "title": "マッチング",
    "section": "脚注",
    "text": "脚注\n\n\nlalondeデータセットを提供するパッケージは複数あり、それぞれデータセットの構成に違いがある。どれを使っても実習には問題ないが、本資料の内容を再現される場合はdata()内にpackage = \"cobalt\"を指定しよう。↩︎\n人種のダミーは3つであるが、全てを投入する場合、多重共線性により、推定ができない（Rだと勝手に一つ落としてくれる）。必ず、一つは抜く必要があり、ここでは白人ダミー（white）を除外して。除外された変数をベースカテゴリ、参照カテゴリと呼ぶ。↩︎\nここでは基準としている標準化差分0.25は{BalanceR}の25と同じである。↩︎\nこれはmatchit()内にreplacement = TRUEを指定することで防ぐことができる。既定値はFALSEだが、TRUEを指定すれば、マッチングされた統制群ケースを2回以上マッチングすることができる。どちらが正しいということはないが、非復元（FALSE）が一般的だという意見もある（Lanza et al. 2013）。↩︎\nこれはmatchit()内にratio引数を指定することで防ぐことができる。既定値は1であり、この場合は1:1マッチングを意味する。↩︎\nAustin, Peter C., and Guy Cafri. 2020. “Variance Estimation When Using Propensity-Score Matching with Replacement with Survival or Time-to-Event Outcomes.” Statistics in Medicine, 39 (11): 1623–40.↩︎\n実はnearest = \"logit\"が省略されている。つまり、ロジスティック回帰分析から得られた傾向スコアの距離に基づくマッチングを意味する。↩︎\nImai, Kosuke and Marc Ratkovic. 2014. “Covariate Balancing Propensity Score.” Journal of the Royal Statistical Society, Series B, Vol. 76, No. 1, pp. 243-246.↩︎\nSuper Learnerを使った例は「Cyrus, Samii, Laura Paler, and Sarah Zukerman Daly. 2016. “Retrospective Causal Inference with Machine Learning Ensembles: An Application to Anti-recidivism Policies in Colombia.” Political Analysis, 22 (4) pp. 434-456」を、日本語による解説は誰かの報告スライドを参照して下さい。↩︎",
    "crumbs": [
      "マッチング"
    ]
  },
  {
    "objectID": "slide/matching.html",
    "href": "slide/matching.html",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "内生性: 処置変数と誤差項間の相関関係\n\n内生性は因果推論の敵\n例\n\n処置変数 = ソンさんの講義を履修するか否か\n結果変数 = 10年後の年収\nもし、やる気のある学生が履修する傾向があるとしたら?\nやる気のある学生は履修の有無と関係なく、高所得者になりやすい。\n\\(\\rightarrow\\) 「やる気」は処置と結果、両方と連関している\n\n\n\n\n内生性を除去する最良の手法 \\(\\rightarrow\\) RCT\n\n\n\n\n\n高費用\n\n数万〜数億円\n\n倫理的な問題による実行不可能性\n\n喫煙と健康\nPhilip Zimbardo. 2008. The Lucifer Effect: How Good People Turn Evil. Rider.\n\n外的妥当性の問題\n\nMichael G. Findley, Kyosuke Kikuta, and Michael Denly. 2021. “External Validity,” Annual Review of Political Science, 24:365-393.\n\n回顧的因果推論には不向き\n\n主に介入 (intervention)の効果が推定対象\n\n\n\n\n\nもし、\\(X\\)をしたら（did）\\(Y\\)はどうなった（would）だろうか\n\n過去を対象にRCTを行うことは不可能\n過去に収集された観察データを使用した因果推論が必要\nマッチング、回帰不連続デザイン、差分の差分法、操作変数法など\n\n\n割当メカニズム (assignment mechanism)\n\nユニットが処置を受けるか否かを規定するメカニズム\n例) 「やる気」が「履修」を規定\n無作為割当なら無作為に処置を受けるか否かが決まるため、考える必要がない。\n\n\n\n\nmatching_data1.csvの例（架空データ; 30行 \\(\\times\\) 4列）\n\n明らかに「やる気」と「履修」は連関\n履修有無による平均年収の差は約265.333万円\n\n\n\n\n\n\n\n\n# A tibble: 10 × 4\n      ID Income Yaruki Rishu\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1     1    659      0     1\n 2     2    587      1     1\n 3     3    628      1     1\n 4     4    563      1     1\n 5     5    531      1     1\n 6     6     79      0     0\n 7     7    356      0     1\n 8     8    176      0     0\n 9     9    339      0     0\n10    10    520      1     1\n\n\n\n\n# A tibble: 10 × 4\n      ID Income Yaruki Rishu\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1    11    239      0     0\n 2    12    276      1     0\n 3    13    609      1     1\n 4    14    254      0     0\n 5    15    423      0     1\n 6    16    172      0     1\n 7    17     20      0     0\n 8    18    447      1     0\n 9    19    498      1     1\n10    20    648      1     1\n\n\n\n\n# A tibble: 10 × 4\n      ID Income Yaruki Rishu\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1    21    155      0     0\n 2    22    768      1     1\n 3    23    463      1     0\n 4    24    309      1     0\n 5    25    304      0     0\n 6    26    408      1     1\n 7    27    259      0     0\n 8    28    516      1     1\n 9    29    476      1     0\n10    30    110      0     0\n\n\n\n\n\n\n\n方法：処置変数と結果変数に影響を与える要因（交絡要因）を揃える\n\n「やる気」のない学生（Yaruki == 0）だけに絞ってみる\n履修有無による平均年収の差は209万円\n\n\n\n\ndf1 |&gt;\n  filter(Yaruki == 0) |&gt;\n  group_by(Rishu) |&gt;\n  summarise(Inc = mean(Income)) |&gt;\n  pull(Inc)\n\n[1] 193.5 402.5\n\n\n\n402.5 - 193.5\n\n[1] 209\n\n\n\n\n\n\n\n\n\n\n\nID\n所得\nやる気\n履修\n　\nID\n所得\nやる気\n履修\n\n\n\n\n1\n659\n0\n1\n\n6\n79\n0\n0\n\n\n7\n356\n0\n1\n\n8\n176\n0\n0\n\n\n15\n423\n0\n1\n\n9\n339\n0\n0\n\n\n16\n172\n0\n1\n\n11\n239\n0\n0\n\n\n\n\n\n\n\n14\n254\n0\n0\n\n\n\n\n\n\n\n17\n20\n0\n0\n\n\n\n\n\n\n\n21\n155\n0\n0\n\n\n\n\n\n\n\n25\n304\n0\n0\n\n\n\n\n\n\n\n27\n259\n0\n0\n\n\n\n\n\n\n\n30\n110\n0\n0\n\n\nMean\n402.5\n\n\n\nMean\n193.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n方法: 処置変数と結果変数に影響を与える要因(交絡要因)を揃える\n\n「やる気」のある学生（Yaruki == 1）だけに絞ってみる\n履修有無による平均年収の差は176.3万円\n\n\n\n\ndf1 |&gt;\n  filter(Yaruki == 1) |&gt;\n  group_by(Rishu) |&gt;\n  summarise(Inc = mean(Income)) |&gt;\n  pull(Inc)\n\n[1] 394.2000 570.5455\n\n\n\n570.5455 - 394.2000\n\n[1] 176.3455\n\n\n\n\n\n\n\n\n\n\n\nID\n所得\nやる気\n履修\n　\nID\n所得\nやる気\n履修\n\n\n\n\n2\n587\n1\n1\n\n12\n276\n1\n0\n\n\n3\n628\n1\n1\n\n18\n447\n1\n0\n\n\n4\n563\n1\n1\n\n23\n463\n1\n0\n\n\n5\n531\n1\n1\n\n24\n309\n1\n0\n\n\n10\n520\n1\n1\n\n29\n476\n1\n0\n\n\n13\n609\n1\n1\n\n\n\n\n\n\n\n19\n498\n1\n1\n\n\n\n\n\n\n\n20\n648\n1\n1\n\n\n\n\n\n\n\n22\n768\n1\n1\n\n\n\n\n\n\n\n26\n408\n1\n1\n\n\n\n\n\n\n\n28\n516\n1\n1\n\n\n\n\n\n\n\nMean\n570.5\n\n\n\nMean\n394.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nやる気なし\n\n\n\n\n\n\n履修 (T)\n平均年収 (Y)\n\n\n\n\n1\n402.5\n\n\n0\n193.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nやる気あり\n\n\n\n\n\n\n履修 (T)\n平均年収 (Y)\n\n\n\n\n1\n570.5\n\n\n0\n394.2\n\n\n\n\n\n\n\n\n\n\nやる気のある（ない）被験者を一人の被験者として考える場合、差分はITEと解釈可能。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID (i)\nN\nやる気 (Zi)\nYi(Ti = 1)\nYi(Ti = 0)\nITEi\n\n\n\n\n1\n14\n0\n402.5\n193.5\n209.0\n\n\n2\n16\n1\n570.5\n394.2\n176.3\n\n\n\n\n\n\n\n\nITEの加重平均 \\(\\rightarrow\\) 講義履修の因果効果 \\(\\rightarrow\\) 約191.6万円\n\n\nweighted.mean(c(209.0, 176.3), w = c(14, 16))\n\n[1] 191.56\n\n\n\n\n\n割当メカニズムを想定し、交絡要因が同じユニット同士を比較\n\n交絡要因: 処置変数と結果変数、両方と関係のある変数\n以下の条件が満たされる場合、マッチングで因果効果の推定が可能\n条件付き独立の仮定 (Conditional Independece Assumption; CIA)\n\n\\(\\{Y_i(T_i = 1),Y_i(T_i = 0)\\} \\perp T_i∣X_i\\)\n\\(T_i\\) : 学生 \\(i\\) の履修有無、 \\(X_i\\) : 学生 \\(i\\) のやる気\nやる気(=交絡要因)が同じ場合、学生 \\(i\\) がソンさんの講義を履修するか否か(=処置変数)は彼(女)の将来収入(=結果変数)と関係なく決まる\n\\(\\rightarrow\\) 処置変数を外生変数として扱うことが可能に\n\nCIAが満たされるためには、割当メカニズム上のすべての交絡要因が必要\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID (i)\nZi\nTi\nY0, i\nY1, i\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nY0\nY1\n\n\n\n\nT = 0\n\n0.429\n\n\n0.429\n\n\n\nT = 1\n\n0.538\n\n\n0.538\n\n\n\n\n\n\n\n\n\n処置効果は0.538 − 0.429 = 0.109\nもし、統制群と処置群が同質なら\nA = C、そしてB = Dのはず\n処置群がもし統制群になっても、今の統制群と同じ\n\\(\\Rightarrow\\) 交換可能性が成立せず\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID (i)\nZi\nTi\nY0, i\nY1, i\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\n\n\n\\(Z\\) で条件づけた場合 ( \\(Z = 0\\) )\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nY0\nY1\n\n\n\n\nT = 0\n\n0.250\n\n\n0.250\n\n\n\nT = 1\n\n0.250\n\n\n0.250\n\n\n\n\n\n\n\n\n\n処置効果は0.250 − 0.250 = 0.000\nもし、統制群と処置群が同質なら\nA = C、そしてB = Dが成立\n\\(\\Rightarrow\\) 交換可能性が成立\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID (i)\nZi\nTi\nY0, i\nY1, i\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\n\n\n\\(Z\\) で条件づけた場合 ( \\(Z = 1\\) )\n\n\n\n\n\n\n\n\n\n\n\n\n\nX\nY0\nY1\n\n\n\n\nT = 0\n\n0.667\n\n\n0.667\n\n\n\nT = 1\n\n0.667\n\n\n0.667\n\n\n\n\n\n\n\n\n\n処置効果は0.667 − 0.667 = 0.000\nもし、統制群と処置群が同質なら\nA = C、そしてB = Dが成立\n\\(\\Rightarrow\\) 交換可能性が成立\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID (i)\nZi\nTi\nY0, i\nY1, i\n\n\n\n\n1\n0\n0\n0\n1\n\n\n2\n0\n0\n1\n0\n\n\n3\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n\n\n5\n0\n1\n0\n0\n\n\n6\n0\n1\n1\n0\n\n\n7\n0\n1\n0\n0\n\n\n8\n0\n1\n0\n1\n\n\n9\n1\n0\n1\n1\n\n\n10\n1\n0\n1\n0\n\n\n11\n1\n0\n0\n1\n\n\n12\n1\n1\n1\n1\n\n\n13\n1\n1\n1\n1\n\n\n14\n1\n1\n0\n1\n\n\n15\n1\n1\n0\n1\n\n\n16\n1\n1\n0\n1\n\n\n17\n1\n1\n1\n1\n\n\n18\n1\n1\n1\n0\n\n\n19\n1\n1\n1\n0\n\n\n20\n1\n1\n1\n0\n\n\n\n\n\n\n\n\n\n\n条件付き独立が成立するということは\n\n交換可能性が成立\n処置群を統制群に、統制群を処置群にしても同じ結果が得られること\n\n\n\n\n\n\n重回帰分析における回帰係数の解釈\n\n他の変数すべてが同じ場合、ある変数が1単位変化する時の応答変数の変化量\nマッチングと同じ?\n\n重回帰分析とマッチングの結果が近似することも \\(\\bigcirc\\)\n\n参考）手計算マッチングの結果：約191.6万円\n\n計算時に小数点を切り捨てたため誤差あり\n\n\n\n\n\n# df1 は matching_data1.csv\n# 単回帰分析\nFit1 &lt;- lm(Income ~ Rishu, data = df1)\n# 重回帰分析\nFit2 &lt;- lm(Income ~ Rishu + Yaruki, data = df1)\n\n\n\n\n\n\n    \n\n    \n    \n      \n        \n        \n              \n                 \n                単回帰分析\n                重回帰分析\n              \n        \n        \n        \n                \n                  (Intercept)\n                  260.400 (36.459)\n                  198.595 (32.737)\n                \n                \n                  Rishu      \n                  265.333 (51.561)\n                  191.167 (44.915)\n                \n                \n                  Yaruki     \n                                  \n                  185.415 (45.015)\n                \n                \n                  Num.Obs.   \n                  30              \n                  30              \n                \n                \n                  R2         \n                  0.486           \n                  0.684           \n                \n        \n      \n    \n\n\n\n\n\n\n\n\n実質的にマッチングと回帰分析は同じという見解も (Angrist and Pischke 2009)\n\n具体的に言えば、回帰分析はマッチングの特殊な形態\n\n強い仮定を置いたマッチング\n回帰分析は \\(Y = \\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k\\) の関数型を仮定 (parametric)\n\n回帰分析において誤差項の平均値は必ず0を仮定 ( \\(\\mathbb{E}(\\varepsilon|T, X) = 0\\) )\n\nマッチングの場合、( \\(\\mathbb{E}(\\varepsilon|T = 0, X) = \\mathbb{E}(\\varepsilon|T = 1, X)\\) )\n\n回帰分析はオーバーラップ条件を無視する\n\nマッチングされないケースでも、線形関数によって予測されてしまう\nマッチングはオーバーラップされないケースを分析から除外する\n\n結論: 回帰分析より柔軟、拡張性がある\n\n\n\n\n3種類の因果効果\n\nATE (Average Treatment Effect): 平均処置効果\nATT (ATE for the Treated): 処置群における平均処置効果\n\n潜在結果: 処置群が処置を受けなかった場合の応答変数\n\nATC (ATE for the Control): 統制群における平均処置効果\n\n潜在結果: 統制群が処置を受けた場合の応答変数\n\n\n\n\n因果効果は一般的に母集団ではなく、サンプルから推定されるため、「SATE/SATT/SATC」と呼ばれる場合も\n他にもRIE (Retrospective Intervention Effect) なども (Samii et al. 2016)\nRCTでは主にATEが推定対象（マッチングでは区分するケースが多い）\n統計ソフトウェアによってはATTを因果効果の推定値として表示する場合もある。\n\n\n\n\n\n処置群の潜在的結果を統制群から割り当てる。\n処置群は \\(Y_i(T_i = 1)\\) が観察済みであり、潜在的結果は \\(Y_i(T_i = 0)\\)\nやる気のない学生の \\(Y_i(T_i = 0)\\) は193.5、ある学生は394.2\n\n\n\n\n\n\n\n\n\nID (i)\nYarukii\nYi(Ti = 1)\nYi(Ti = 0)\nITEi\n\n\n\n\n1\n0\n659\n193.5\n465.5\n\n\n2\n1\n587\n394.2\n192.8\n\n\n3\n1\n628\n394.2\n233.8\n\n\n4\n1\n563\n394.2\n168.8\n\n\n5\n1\n531\n394.2\n136.8\n\n\n7\n0\n356\n193.5\n162.5\n\n\n...\n...\n...\n...\n...\n\n\n20\n1\n648\n394.2\n253.8\n\n\n22\n1\n768\n394.2\n373.8\n\n\n26\n1\n408\n394.2\n13.8\n\n\n28\n1\n516\n394.2\n121.8\n\n\n平均\n\n\n\n185.1\n\n\n\n\n\n\n\n\n\n\n\n統制群の潜在的結果を処置群から割り当てる。\n統制群は \\(Y_i(T_i = 0)\\) が観察済みであり、潜在的結果は \\(Y_i(T_i = 1)\\)\nやる気のない学生の \\(Y_i(T_i = 1)\\) は402.5、ある学生は570.5\n\n\n\n\n\n\n\n\n\nID (i)\nYarukii\nYi(Ti = 1)\nYi(Ti = 0)\nITEi\n\n\n\n\n6\n0\n402.5\n79\n323.5\n\n\n8\n0\n402.5\n176\n226.5\n\n\n9\n0\n402.5\n339\n63.5\n\n\n11\n0\n402.5\n239\n163.5\n\n\n12\n1\n570.5\n276\n294.5\n\n\n14\n0\n402.5\n254\n148.5\n\n\n...\n...\n...\n...\n...\n\n\n25\n0\n402.5\n304\n98.5\n\n\n27\n0\n402.5\n259\n143.5\n\n\n29\n1\n570.5\n476\n94.5\n\n\n30\n0\n402.5\n110\n292.5\n\n\n平均\n\n\n\n198.1\n\n\n\n\n\n\n\n\n\n\n\nATTとATCの加重平均\n今回は処置群と統制群が15:15 \\(\\rightarrow\\) 単純平均でOK\n\n\\(\\frac{1}{2}(185.1 + 198.1) = 191.6\\)\n手計算マッチングとと同じ結果\n\n\n\\[\\text{ATE} = \\frac{N_{\\text{treated}}}{N_{\\text{all}}} \\text{ATT} + \\frac{N_{\\text{controlled}}}{N_{\\text{all}}} \\text{ATC}.\\]"
  },
  {
    "objectID": "slide/did.html",
    "href": "slide/did.html",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "条件付き独立の仮定 (Conditional Independent Assumption; CIA)\n\n処置変数（\\(T\\)）と応答変数（\\(Y\\)）の間に存在する交絡要因（\\(W\\)）が全て観察されている場合\n\n\\({Y_i (T_i = 1), Y_i (T_i = 0) \\perp T_i | W_i}\\)\n\\(\\rightarrow\\) 交絡変数を共変量として統制する場合、観察データからも因果効果の推定が可能\n\nしかし、全ての交絡要因がデータに含まれる場合もほぼゼロ\n\n\\(\\rightarrow\\) 仮定としては強すぎるため、（回帰分析を含む）マッチングによる厳密な因果推論は困難\nただし、単純に処置変数と応答変数の単回帰分析よりは望ましい。\n\nより緩い仮定の下で可能な因果推論の手法\n\n\\(\\rightarrow\\) 自然実験（Natural Experiment）\n\n\n\n\n\nRCTの3つの特徴（Freedman, Pisani, and Purves 2007）\n\nThe response of experimental subjects assigned to receive a treatment is compared to the response of subjects assigned to a control group.\nThe assignment of subjects to treatment and control groups is done at random, through a randomizing device such as a coin flip.\nThe manipulation of the treatment—also known as the intervention—is under the control of an experimental researcher.\n\n\n自然実験は（Dunning 2012）\n\n同じ\n処置の有無は無作為のように決まる（as-if random）。\n処置内容などを研究者が操作することは不可能\n\n2と3は自然、制度などによって影響を受ける。\n\n\n\n\n\n処置を受けるか否かが自然、制度、偶然などによって規定される\n\n多数代表制と比例代表制\n\n人口3500未満なら多数代表制、以上なら比例代表制を採用（フランス地方選挙）\n\n軍の経験と所得\n\nベトナム戦争時、徴兵対象がくじによって決まる（アメリカ）\n\n最低賃金の効果\n\n隣接するペンシルベニア州とニュージャージー州の最低賃金の格差\n\n現職効果\n\n惜敗・辛勝の場合、候補者間の質には大差ないはず\n\n選挙区定数の効果\n\n人口によって選挙区定数が決まる\n\nその他\n\n\n\n\n本講義では1と2を解説\n\n差分の差分法（Difference-in-Difference; Diff-in-Diff/DID/DD）\n回帰不連続デザイン (Regression Discontinuity Design; RDD)\n\n中断時系列デザイン（Interrupted Time-series Design; ITS）\n\nRDDの時系列版であるが、自己相関などの対処が必要であるため本講義では省略\n\n\n操作変数（Instrumental Variable; IV）\n集積分析（Bunching Analysis）など"
  },
  {
    "objectID": "slide/intro_rct.html",
    "href": "slide/intro_rct.html",
    "title": "方法論特殊講義III",
    "section": "",
    "text": "LINEスタンプ絶賛販売中!\n\n\n\n\n\n\n宋(そん)  財泫(じぇひょん) (SONG JAEHYUN)\n\n関西大学総合情報学部 准教授\n博士（政治学）\n\n専門は政治行動論、選挙研究、政治学方法論\n趣味はゲームとラーメン屋巡り\n\n好きなラーメンは家系と二郎インスパイア、汁なし全般\n最近やっているゲームはFF XIV\n\n\n\n\n song@kansai-u.ac.jp\n https://www.jaysong.net\n\n\n\n\n\n\n各講義は以下の内容に関する理論と実習を5:5で行う予定。また、履修者の理解・進捗状況に応じて変更の可能性がある。\n\n1日目：8月17日（木）\n\n因果推論の考え方\nランダム化比較試験\n\n2日目：8月18日（金）\n\nLab Session: R の使い方\n2日目にLab Sessionを行わない場合は、以下の内容を繰り上げ、5日目は操作変数を解説\n\n3日目：8月21日（月）\n\n回帰分析とマッチング、その応用\n\n4日目：8月22日（火）\n\n差分の差分法とその応用\n\n5日目：8月23日（水）\n\n回帰不連続デザイン\n\n\n\n\n\n実習はRで行う。1・2日目はRの導入および使い方についても解説（復習レベル）する。\n\n本講義の分析はExcel, SPSS, Stata, Julia, Pythonなどでも可能\nJared P. Lander. 2017. R for Everyone: Advanced Analytics and Graphics (2nd Edition), Addison-Wesley Professional.（邦訳有り）\n宋財泫・矢内勇生.『私たちのR: ベストプラクティスの探究』Web-book\n\n無料のR入門書: Rを広く、深く勉強したい人におすすめ\n\n\n\n\n\n\n\nmacOS 14.6.1 “Ventura”\nR version 4.4.1 (2024-06-14)\n\nR &gt; 4.1ならOK\n\nRStudio 2024.04.2+764\nスライド、サポートページ、実習用資料の執筆環境\n\nQuarto 1.5.56\nR package {quarto} 1.4.4\n\n\n\n\n\n\n\n\n\n\n\n\n計量政治学とR\n\n浅野正彦・矢内勇生. 2019『Rによる計量政治学』オーム社.\n飯田健. 2013.『計量政治分析』共立出版.\nKosuke Imai. 2017. Quantitative Social Science: An Introduction, Princeton University Press. (邦訳あり[上/下])\n\nR全般\n\nWickham, Hadley and Grolemund, Garrett. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data, O’Reilly. (邦訳あり/原著はインターネットから無料で閲覧可)\n松村優哉 他. 2021. 『改訂2版 Rユーザのための RStudio[実践] 入門—tidyverseによるモダンな分析フローの世界—』技術評論社.\nWickham, Hadley. 2019. Advanced R (Second Edition), O’Reilly. (邦訳あり/原著はインターネットから無料で閲覧可)\n\n\n\n\n\nDiscordに登録し、Discordを起動する（アプリ版、Web版、どちらでも良い）。\n宋をフレンドとして追加\n\n宋のIDとタグは_jaysong_（前後にアンダースコア「_」あり） \n\n自分の学籍番号と氏名をDiscordメッセージで伝える。\n宋からの招待が届けば、サーバーに登録する。\n\nDiscord上の表示名（ニックネーム）は宋が実名へ変更する。任意の表示名に変更しないこと。\n\n\n\n\n\n平常点と期末レポート\n\n平常点: 30%\n\n授業への参加度（質問/発言）\nDiscordでの参加度も含む\n\n期末レポート: 70%\n\n提出方法、期限は講義最終日に告知\n\n\n\n\n\n研究のプロポーザル\n\n本講義で紹介した手法を用いた分析のプロポーザルを作成\n実現可能性（予算、倫理など）があること\n\n架空の予算は100万円を上限とする\n\n提出期限は8月31日（木）13時（締切厳守!）\n分量の制限（下限/上限）なし\n\n\n\n\n\n\n自分で計算できなくても、結果の読み方が分かるレベル\n\n仮説検定\n統計的有意性検定\n回帰分析\n\n\n\n\n\nデータクリーニング、回帰分析、可視化などができるならベスト\n2日目にRの解説は行うが、深入りはしない（できない）\n\n全員が以下の資料レベルの内容を知っていれば2日目の内容を省略し、代わりに操作変数法について解説\nhttps://www.jaysong.net/r4ps/\n\n『私たちのR』を読もう！"
  }
]